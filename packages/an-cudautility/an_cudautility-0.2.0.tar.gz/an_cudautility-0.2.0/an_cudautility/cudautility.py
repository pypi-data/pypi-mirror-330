# -*- coding: utf-8 -*-
"""CUDU_20250224_00.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L56UkZr80htFW8LwCUcbwafrAEv59yjo

# CudaUtility
 Cudaサポートユーティリティ


```
2025/02/24 0.1.0 完成
2025/02/27 0.2.0 check_gpu追加。
```

# CudaUtility

## 1. GDrive接続
"""

from google.colab import drive
drive.mount('/content/drive')

"""## 2. モジュール定義"""

# @title a. CudaUtility 定義
import os
import torch

class CudaUtility:
    def __init__(self):
        pass
        # GPUの状態や情報を格納するメンバ変数
        self.gpu_available = False
        self.gpu_info = None

    def check_status( self ):
        print( "1️⃣ CUDA関連パッケージインストール状況" )
        get_ipython().system("dpkg -l | grep cuda")
        get_ipython().system("dpkg -l | grep libcudnn")

        print( "2️⃣ CUDAファイル残存状況確認" )
        get_ipython().system("ls -l /usr/local | grep cuda")
        get_ipython().system("ls -l /usr/lib | grep cuda")
        get_ipython().system("ls -l /usr/lib64 | grep cuda")

        print( "3️⃣ 環境変数の影響を確認" )
        get_ipython().system("echo $PATH")
        get_ipython().system("echo $LD_LIBRARY_PATH")

    # 旧称 get_cuda_version_symbol
    def version_symbol(self, cuda_version: str) -> str:
        """
        CUDAのバージョン番号 (例: "11.8", "12.4") を
        CUDAのシンボル (例: "CU118", "CU124") に変換する。

        :param cuda_version: CUDAのバージョン番号 (例: "11.8", "12.4")
        :return: 変換されたシンボル (例: "CU118", "CU124")
        """
        try:
            # バージョン番号を小数点で分割
            major, minor = cuda_version.split('.')
            # シンボル形式に変換
            return f"CU{major}{minor}"
        except ValueError:
            raise ValueError(f"Invalid CUDA version format: {cuda_version}")

    def check_gpu(self):
        """
        GPUが有効ならTrue、無効ならFalseを返す。
        まずtorch.cuda.is_available()で確認し、Falseの場合は /proc/driver/nvidia/version をチェックする。
        """
        try:
            # PyTorchでGPUが利用可能かどうかチェック
            available = torch.cuda.is_available()
        except Exception as e:
            available = False

        if available:
            self.gpu_available = True
            self.gpu_info = "torch.cuda.is_available() returned True"
            return True
        else:
            # torchがFalseを返した場合、低レベルな方法として /proc/driver/nvidia/version を確認
            if os.path.exists("/proc/driver/nvidia/version"):
                try:
                    with open("/proc/driver/nvidia/version", "r") as f:
                        version_info = f.read().strip()
                    self.gpu_available = True
                    self.gpu_info = version_info
                    return True
                except Exception as e:
                    self.gpu_available = False
                    self.gpu_info = f"Error reading /proc/driver/nvidia/version: {e}"
                    return False
            else:
                self.gpu_available = False
                self.gpu_info = "GPU is not available (torch reports False and /proc/driver/nvidia/version not found)"
                return False

"""## 3. 実行"""

# @title a. 実行
if __name__ == "__main__":
    cudautility = CudaUtility()
    cudautility.check_status()
    print(cudautility.version_symbol("11.8"))

# 使用例
if __name__ == "__main__":
    cudau = CudaUtility()
    if cudau.check_gpu():
        print("GPUは有効です。")
        print("GPU情報:")
        print(cudau.gpu_info)
    else:
        print("GPUは無効です。")
        print("詳細:")
        print(cudau.gpu_info)