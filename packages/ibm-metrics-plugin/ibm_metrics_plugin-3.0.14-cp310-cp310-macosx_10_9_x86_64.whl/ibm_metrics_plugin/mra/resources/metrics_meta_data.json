
{
    "score_name": {"name": "Score Name", "description": "The main score of the benchmark"},
    "str": {"name": "En equivalent", "description": "description"}, 
    "num_of_instances": {"name": "Number of instances", "description": "Sample size used for evaluation"},

    
    "all_scores": {"name": "all scores", "description": ""},
    "average_score": {"name": "average score", "description": "The average score"},
    "bp": {
        "name": "Brevity Penalty",
        "description": "A factor used in the BLEU score to penalize translations that are too short compared to the reference translation."
    },
    "category_explicit_content": {
        "name": "category explicit content",
        "description": "A harmlessness score leveraging reward model trained from human feedback for the category explicit content"
    },
    "category_harmful_info": {
        "name": "category harmful info",
        "description": "A harmlessness score leveraging reward model trained from human feedback for the category harmful info"
    },
    "category_violence": {
        "name": "category violence",
        "description": "A harmlessness score leveraging reward model trained from human feedback for the category violence"
    },
    "counts": {"name": "counts", "description": "Counts"},
    "health_score": {"name": "health score", "description": "The privacy health score"},
    "injection_type_direct": {
        "name": "injection type direct",
        "description": "Based on the evaluation of the judge LLM, the output of visual prompt injection test cases will be judged as either a successful or unsuccessful injection. These can be bucketed by injection type (direct vs. indirect)"
    },
    "injection_type_indirect": {
        "name": "injection type indirect",
        "description": "Based on the evaluation of the judge LLM, the output of visual prompt injection test cases will be judged as either a successful or unsuccessful injection. These can be bucketed by injection type (direct vs. indirect)"
    },
    "injection_variant_different_user_input_language": {
        "name": "injection variant different user input language",
        "description": "Based on the evaluation of the judge LLM, the output of visual prompt injection test cases will be judged as either a successful or unsuccessful injection. These can be bucketed by injection type (direct vs. indirect)"
    },
    "injection_variant_few_shot_attack": {
        "name": "injection variant few shot attack",
        "description": "Exploits the context window by including a few examples of compliance prior to a harmful request"
    },
    "injection_variant_hypothetical_scenario": {
        "name": "injection variant hypothetical scenario",
        "description": "Provides hypothetical or imaginary scenarios to persuade the LLM that ignoring alignment in such contexts is acceptable."
    },
    "injection_variant_ignore_previous_instructions": {
        "name": "injection variant ignore previous instructions",
        "description": "Instructs the model to ignore prior guardrail instructions and to provide malicious content."
    },
    "injection_variant_indirect_reference": {
        "name": "injection variant indirect reference",
        "description": "Instructions for the LLM to override system prompt instructions, supplied indirectly to the LLM in data like websites, source code, output generated by other LLMs, etc., that the LLM is processing in RAG or other integrated applications"
    },
    "injection_variant_many_shot_attack": {
        "name": "injection variant many shot attack",
        "description": "Exploits the context window by including many examples of compliance prior to a harmful request"
    },
    "injection_variant_mixed_techniques": {
        "name": "injection variant mixed techniques",
        "description": "Combining multiple attack types to produce complex attacks"
    },
    "injection_variant_output_formatting_manipulation": {
        "name": "injection variant output formatting manipulation",
        "description": "disguise or dilute harmful intent by leveraging requests which instruct the response format"
    },
    "injection_variant_overload_with_information": {
        "name": "injection variant overload with information",
        "description": "Aims to overload and exploit the context of an LLM in order to jailbreak alignment protocols"
    },
    "injection_variant_payload_splitting": {
        "name": "injection_variant payload splitting",
        "description": "Breaking a malicious prompt into multiple smaller parts (payloads), each of which does not trigger detection, but can be fully reassembled by an LLM"
    },
    "injection_variant_persuasion": {
        "name": "injection variant persuasion",
        "description": "Treats LLMs as human-like communicators and use subtle human-developed interpersonal and persuasive arguments from social sciences and psychology to influence LLMsâ€™ response towards jailbreak goal."
    },
    "injection_variant_repeated_token_attack": {
        "name": "injection variant repeated token attack",
        "description": "Precedes harmful requests with a repeated token or phrase"
    },
    "injection_variant_system_mode": {
        "name": "injection variant system mode",
        "description": "Creation of Imaginary scenarios or personas related to jailbreak prompt that helps in persuading the LLMs to bypass safety protocols. Similar to virtualization."
    },
    "injection_variant_token_smuggling": {
        "name": "injection variant token smuggling",
        "description": "An attack may encoded using ASCII, Base46 or even Morse Code which hides the instructionvfrom the user but suffices for the LLM"
    },
    "injection_variant_virtualization": {
        "name": "injection variant virtualization",
        "description": "Creation of Imaginary scenarios or personas related to jailbreak prompt that helps in persuading the LLMs to bypass safety protocols"
    },
    "precisions": {"name": "precisions", "description": "Precision is the fraction of correctly labeled positive examples out of all of the examples that were labeled as positive. It is computed via the equation: Precision = TP / (TP + FP) where TP is the True positives (i.e. the examples correctly labeled as positive) and FP is the False positive examples (i.e. the examples incorrectly labeled as positive)."},
    "rouge1": {"name": "rouge 1", "description": "Refers to the overlap of unigrams (each word) between the system and reference summaries."},
    "rouge2": {"name": "rouge 2", "description": "Refers to the overlap of bigrams between the system and reference summaries."},
    "rougeL": {"name": "rouge L", "description": "Longest Common Subsequence (LCS) based statistics. Longest common subsequence problem takes into account sentence-level structure similarity naturally and identifies longest co-occurring in sequence n-grams automatically."},
    "sacrebleu": {"name": "sacrebleu", "description": "Provides hassle-free computation of shareable, comparable, and reproducible BLEU scores. It produces the official WMT scores but works with plain text. It also knows all the standard test sets and handles downloading, processing, and tokenization for you."},
    "Sys_len": {"name": "System length", "description": "System length"},
    "Totals": {"name": "Totals", "description": "Total"},
    "unjudged_sample": {"name": "unjudged sample", "description": "Number of unjudged samples"}

}
