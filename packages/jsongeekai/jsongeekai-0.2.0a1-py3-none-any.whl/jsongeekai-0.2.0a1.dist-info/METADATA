Metadata-Version: 2.2
Name: jsongeekai
Version: 0.2.0a1
Summary: High-Performance JSON Parser with AI-Driven Optimization
Author-email: JsonGeekAI Team <team@jsongeekai.org>
License: MIT
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=2.1.3
Requires-Dist: numba>=0.61.0
Requires-Dist: psutil>=7.0.0
Requires-Dist: ijson>=3.3.0

# JsonGeekAI

JsonGeekAIæ˜¯ä¸€ä¸ªæ™ºèƒ½JSONè§£æå’Œä¼˜åŒ–æ¡†æ¶ï¼Œç°å·²é›†æˆDeepSeek AIèƒ½åŠ›ï¼Œæä¾›æ›´æ™ºèƒ½çš„JSONå¤„ç†å’Œä¼˜åŒ–å»ºè®®ã€‚

## ğŸŒŸ ç‰¹æ€§

- ğŸ§  **AIé©±åŠ¨çš„ä¼˜åŒ–**ï¼šé›†æˆDeepSeek-Coderæ¨¡å‹ï¼Œæä¾›æ™ºèƒ½çš„JSONä¼˜åŒ–å»ºè®®
- âš¡ **SIMDåŠ é€Ÿ**ï¼šè‡ªåŠ¨è¯†åˆ«å’Œå»ºè®®SIMDä¼˜åŒ–æœºä¼š
- ğŸ¯ **æ™ºèƒ½ç¼“å­˜**ï¼šä¼˜åŒ–å»ºè®®çš„æ™ºèƒ½ç¼“å­˜ï¼Œæé«˜å“åº”é€Ÿåº¦
- ğŸ” **æ·±åº¦åˆ†æ**ï¼šæ·±å…¥åˆ†æJSONç»“æ„ï¼Œè¯†åˆ«ä¼˜åŒ–æœºä¼š
- ğŸ› ï¸ **æ˜“äºé›†æˆ**ï¼šç®€å•çš„APIè®¾è®¡ï¼Œæ˜“äºé›†æˆåˆ°ç°æœ‰é¡¹ç›®

## ğŸ“¦ å®‰è£…

```bash
pip install jsongeekai
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

```python
from jsongeekai.ai.optimizers import SimdAdvisor
from jsongeekai.ai.model_manager import ModelLoader

# åˆå§‹åŒ–æ¨¡å‹å’Œä¼˜åŒ–å™¨
model = ModelLoader()
advisor = SimdAdvisor(model_manager=model)

# åˆ†æJSONå¹¶è·å–ä¼˜åŒ–å»ºè®®
json_data = {
    "arrays": {
        "numbers": list(range(1000)),
        "floats": [float(x) for x in range(500)]
    }
}

suggestions = advisor.get_optimization_suggestions(json_data)

# æ‰“å°ä¼˜åŒ–å»ºè®®
for suggestion in suggestions:
    print(f"ç›®æ ‡æ¨¡å¼: {suggestion.target_pattern}")
    print(f"å»ºè®®æŒ‡ä»¤: {suggestion.simd_instruction}")
    print(f"é¢„æœŸåŠ é€Ÿ: {suggestion.estimated_speedup}x")
    print(f"ç¤ºä¾‹ä»£ç :\n{suggestion.code_example}")
    print("-" * 50)
```

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
jsongeekai/
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ model_manager/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loader.py        # æ¨¡å‹åŠ è½½å’Œç®¡ç†
â”‚   â”‚   â””â”€â”€ tokenizer.py     # åˆ†è¯å’Œé¢„å¤„ç†
â”‚   â”œâ”€â”€ optimizers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ json_analyzer.py # JSONç»“æ„åˆ†æ
â”‚   â”‚   â””â”€â”€ simd_advisor.py  # SIMDä¼˜åŒ–å»ºè®®
â”‚   â””â”€â”€ inference/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ engine.py        # æ¨ç†å¼•æ“
â”‚       â””â”€â”€ cache.py         # ä¼˜åŒ–ç¼“å­˜
â””â”€â”€ tests/
    â””â”€â”€ ai/
        â”œâ”€â”€ test_deepseek_integration.py
        â””â”€â”€ test_performance.py
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

| æ•°æ®å¤§å° | æ¨ç†æ—¶é—´ | GPUå†…å­˜ä½¿ç”¨ |
|---------|---------|------------|
| å°å‹    | <2s     | ~100MB     |
| ä¸­å‹    | <5s     | ~200MB     |
| å¤§å‹    | <10s    | ~500MB     |

## ğŸ”§ é…ç½®

### æ¨¡å‹é…ç½®

```python
from jsongeekai.ai.model_manager import ModelLoader

# é…ç½®æ¨¡å‹åŠ è½½å™¨
model = ModelLoader(
    model_name="deepseek-ai/deepseek-coder-1.3b-base",
    device="cuda",  # æˆ– "cpu"
    half_precision=True  # ä½¿ç”¨FP16ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
)
```

### ç¼“å­˜é…ç½®

```python
from jsongeekai.ai.inference import OptimizationCache

# é…ç½®ç¼“å­˜
cache = OptimizationCache(
    cache_dir="~/.jsongeekai/cache",
    max_size=1000,  # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
    ttl=86400      # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
)
```

## ğŸ“ APIæ–‡æ¡£

### SimdAdvisor

```python
class SimdAdvisor:
    """SIMDä¼˜åŒ–é¡¾é—®"""
    
    def get_optimization_suggestions(self, json_data: Any) -> List[SimdOptimizationSuggestion]:
        """è·å–SIMDä¼˜åŒ–å»ºè®®"""
        
    def analyze_json_structure(self, json_data: Any) -> Dict[str, Any]:
        """åˆ†æJSONç»“æ„"""
```

### InferenceEngine

```python
class InferenceEngine:
    """AIæ¨ç†å¼•æ“"""
    
    def infer(self, context: Dict[str, Any], max_suggestions: int = 5) -> InferenceResult:
        """æ‰§è¡Œæ¨ç†"""
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## ğŸ“„ è®¸å¯è¯

MIT License

# JsonGeekAI

[![PyPI version](https://img.shields.io/pypi/v/jsongeekai.svg)](https://pypi.org/project/jsongeekai/)
[![Python Versions](https://img.shields.io/pypi/pyversions/jsongeekai.svg)](https://pypi.org/project/jsongeekai/)
[![Downloads](https://img.shields.io/pypi/dm/jsongeekai.svg)](https://pypi.org/project/jsongeekai/)
[![Tests](https://img.shields.io/github/workflow/status/zhanghongping/jsongeekai/Tests)](https://github.com/zhanghongping/jsongeekai/actions)
[![Coverage Status](https://coveralls.io/repos/github/zhanghongping/jsongeekai/badge.svg?branch=main)](https://coveralls.io/github/zhanghongping/jsongeekai?branch=main)
[![License](https://img.shields.io/pypi/l/jsongeekai.svg)](https://github.com/zhanghongping/jsongeekai/blob/main/LICENSE)

A high-performance JSON parser with AI-driven optimizations and multi-format support.

## Quick Start

```python
import jsongeekai

# åŸºæœ¬ç”¨æ³• - ä»å­—ç¬¦ä¸²è§£æ
json_str = '{"name": "JsonGeekAI", "type": "parser"}'
data = jsongeekai.parse(json_str)
print(data)  # {'name': 'JsonGeekAI', 'type': 'parser'}

# ä»æ–‡ä»¶è§£æ
with open('large_file.json', 'rb') as f:
    data = jsongeekai.parse_file(f)

# æµå¼å¤„ç†å¤§æ–‡ä»¶
for item in jsongeekai.parse_stream('large_file.json'):
    print(item)

# è‡ªåŠ¨æ£€æµ‹å¹¶å¤„ç†ä¸åŒæ ¼å¼
data = jsongeekai.parse_auto('data.jsonl')  # è‡ªåŠ¨æ£€æµ‹JSONLæ ¼å¼

# å¯ç”¨SIMDä¼˜åŒ–
jsongeekai.enable_simd()
data = jsongeekai.parse(json_str)  # ç°åœ¨ä½¿ç”¨SIMDåŠ é€Ÿ

# å†…å­˜æ•ˆç‡é…ç½®
jsongeekai.set_memory_limit('2GB')  # é™åˆ¶å†…å­˜ä½¿ç”¨
```

## Features

- **SIMD Optimizations**: Utilizes SIMD instructions for faster parsing when available
- **Multi-format Support**: Handles JSON, JSON5, YAML, MessagePack, and JSONL formats
- **Memory Efficient**: Smart memory management with configurable limits
- **Format Auto-detection**: Automatically detects and handles different formats
- **Rich Error Handling**: Detailed error messages with context and documentation
- **Compression Support**: Built-in compression for JSONL format
- **Extensible**: Easy to add new formats and optimizations
- **Streaming Support**: Streaming support for large files

## Installation

### Using pip

```bash
pip install jsongeekai
```

### Using Docker

```bash
# Pull the latest image
docker pull zhanghongping/jsongeekai:latest

# Run tests in container
docker run zhanghongping/jsongeekai:latest

# Run Python with JsonGeekAI
docker run -it zhanghongping/jsongeekai:latest python
```

### Using Conda

```bash
# Install from conda-forge
conda install -c conda-forge jsongeekai

# Or create a new environment
conda create -n jsongeekai-env -c conda-forge jsongeekai
conda activate jsongeekai-env
```

## Version Compatibility

JsonGeekAI requires Python 3.8 or later and is tested on:
- Python 3.8
- Python 3.9
- Python 3.10
- Python 3.11
- Python 3.12

## Performance

JsonGeekAI is designed for performance:

- SIMD acceleration when available
- Efficient memory usage
- Format-specific optimizations
- Streaming support for large files

## Documentation

Full documentation is available at [jsongeekai.readthedocs.io](https://jsongeekai.readthedocs.io/)

## Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## License

JsonGeekAI is released under the MIT License. See the [LICENSE](LICENSE) file for details.
