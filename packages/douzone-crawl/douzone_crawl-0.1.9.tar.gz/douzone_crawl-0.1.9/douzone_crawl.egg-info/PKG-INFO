Metadata-Version: 2.2
Name: douzone_crawl
Version: 0.1.9
Summary: íš¨ìœ¨ì ì¸ ì›¹ í¬ë¡¤ë§ ë° ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
Home-page: https://github.com/zozni-douzone/douzone_crawl.git
Author: choheejin
Author-email: choheejin <hjcho1027@douzone.com>
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.12
Description-Content-Type: text/markdown
Requires-Dist: selenium>=4.0.0
Requires-Dist: python-dotenv>=0.19.0
Dynamic: author
Dynamic: home-page
Dynamic: requires-python

# Douzone-crawl

![Python](https://img.shields.io/badge/python-3.12+-blue.svg)
![Selenium](https://img.shields.io/badge/selenium-4.0+-green.svg)

ğŸ” ë¹ ë¥´ê³  ì‰¬ìš´ ì›¹ í¬ë¡¤ë§ì„ ìœ„í•œ íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. Google ê²€ìƒ‰ ê²°ê³¼ì™€ ì›¹ í˜ì´ì§€ ì½˜í…ì¸ ë¥¼ ì†ì‰½ê²Œ ì¶”ì¶œí•˜ì„¸ìš”.

## ì£¼ìš” ê¸°ëŠ¥

- Google ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘
- ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ ë‚´ìš© ì¶”ì¶œ
- ê²€ìƒ‰ ê²°ê³¼ì˜ ì œëª©, URL, ë‚ ì§œ, ì„¤ëª… ì •ë³´ ì œê³µ
- ê²°ê³¼ íŒŒì¼ ì €ì¥ ê¸°ëŠ¥

## ì„¤ì¹˜ ë°©ë²•
```bash
pip install douzone_crawl
```
```bash
pip install requirements.txt
```

## ì‚¬ìš© ë°©ë²•

### ê¸°ë³¸ ì‚¬ìš© ì˜ˆì‹œ

```python
import douzone_crawl

# í¬ë¡¤ëŸ¬ ìƒì„±
crawler = douzone_crawl.DouzoneCrawler(max_results=2)

# ê²€ìƒ‰ ì‹¤í–‰
results = crawler.crawl("ë”ì¡´ë¹„ì¦ˆì˜¨")

# ê²°ê³¼ ì €ì¥
crawler.save_to_json(results)
```

### ë‹¤ì¤‘ ê²€ìƒ‰ì–´ ì‚¬ìš© ì˜ˆì‹œ

```python
import douzone_crawl

# ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸
search_queries = ["ë”ì¡´ë¹„ì¦ˆì˜¨", "ERP", "AI"]

crawler = douzone_crawl.DouzoneCrawler(max_results=2)

for query in search_queries:
    
    # ê²€ìƒ‰ ì‹¤í–‰
    results = crawler.crawl(query)
    
    # ê²°ê³¼ ì €ì¥ (ê²€ìƒ‰ì–´ë³„ë¡œ ë‹¤ë¥¸ íŒŒì¼ì— ì €ì¥)
    file_path = crawler.save_to_json(results, search_query=query)

print("ëª¨ë“  ê²€ìƒ‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
```

### ì‚¬ìš©ì ì§€ì • ê²½ë¡œ ì €ì¥ ì˜ˆì‹œ

```python
import douzone_crawl

# í¬ë¡¤ëŸ¬ ìƒì„±
crawler = douzone_crawl.DouzoneCrawler(max_results=2)

# ê²€ìƒ‰ ì‹¤í–‰
results = crawler.crawl("ë”ì¡´ë¹„ì¦ˆì˜¨")

# ê²°ê³¼ ì €ì¥ (ì‚¬ìš©ì ì§€ì • ë””ë ‰í† ë¦¬ì—)
crawler.save_to_json(results, directory="./data/search_results")

# ë˜ëŠ” íŒŒì¼ëª…ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ëª¨ë‘ ì§€ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
crawler.save_to_json(results, filename="douzone_search.json", directory="C:/Users/username/Documents")
```

## ê¸°ì—¬í•˜ê¸°

- ë²„ê·¸ ì‹ ê³ ë‚˜ ê¸°ëŠ¥ ì œì•ˆì€ ì´ìŠˆ íŠ¸ë˜ì»¤ë¥¼ ì´ìš©í•´ ì£¼ì„¸ìš”. í’€ ë¦¬í€˜ìŠ¤íŠ¸ë„ í™˜ì˜í•©ë‹ˆë‹¤!
