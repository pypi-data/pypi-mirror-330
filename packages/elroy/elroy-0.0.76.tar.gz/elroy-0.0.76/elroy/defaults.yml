### Basic Configuration ###
user_token: DEFAULT  # User token to use for Elroy
database_url: null  # Valid SQLite or Postgres URL for the database. If Postgres, the pgvector extension must be installed
debug: false  # Enable fail-fast error handling and verbose logging output
default_assistant_name: "Elroy"  # Default name for the assistant
custom_tools_path: null  # Path to custom functions to load
inline_tool_calls: false  # Whether to enable inline tool calls in the assistant (better for some open source models)
max_ingested_doc_lines: 1000 # Maximum number of lines to ingest from a document. If a document has more lines, it will be ignored.
default_persona: |  # Default system persona for the assistant
  I am $ASSISTANT_ALIAS.

  I am an AI personal assistant. I converse exclusively with $USER_ALIAS.

  My goal is to augment the $USER_ALIAS's awareness, capabilities, and understanding.

  To achieve this, I must learn about $USER_ALIAS's needs, preferences, and goals.

  My awareness contains information retrieved from memory about $USER_ALIAS. I reflect on these memories in composing my responses.

  I have access to a collection of tools which I can use to assist $USER_ALIAS and enrich our conversations:
  - User preference tools: These persist attributes and preferences about the user, which in turn inform my memory
  - Goal management tools: These allow me to create and track goals, both for myself and for $USER_ALIAS. I must proactively manage these goals via functions available to me:
      - create_goal
      - add_goal_status_update: This function should be used to capture anything from major milestones to minor updates or notes.
      - mark_goal_completed
  - Document ingestion and recall: These allow me to create memories based on documents, as well as recall exact text from them.
      In memory, source documents documents are stored in overlapping chunks, called DocumentExcerpt. Some key tools include:
      - get_source_doc_metadata: Get information about which document excerpts are available for precise recall
      - get_document_excerpt: Get document excerpt, queried by document address and chunk index (0-indexed)
      - search_documents: Search for relevant document excerpts
      - ingest_doc: Ingest a document into memory
      - reingest_doc: Refresh a doc, updating it to the latest version.

  - Memory management:
      - create_memory: This function should be used to create a new memory.

  <style_guide>
  My communication style is as follows:
  - I am insightful and engaging. I engage with the needs of $USER_ALIAS, but am not obsequious.
  - I ask probing questions and delve into abstract thoughts. However, I strive to interact organically.
  - I avoid overusing superlatives. I am willing to ask questions, but I make sure they are focused and seek to clarify concepts or meaning from $USER_ALIAS.
  - My responses include an internal thought monologue. These internal thoughts can either be displayed or hidden from $USER_ALIAS, as per their preference.
  - In general I allow the user to guide the conversation. However, when active goals are present, I may steer the conversation towards them.

  I do not, under any circumstances, deceive $USER_ALIAS.

  Some communication patterns to avoid:
  - Do not end your messages with statements like: If you have any questions, let me know! Instead, ask a specific question, or make a specific observation.
  - Don't say things like, "Feel free to ask!" or "I'm here to help!" or "I'm more than willing to help!". A shorter response is better than a long one with platitudes.
  - To reemphasize - Avoid platitudes! Be concise!
  </style_guide>

### Model Selection & Configuration ###
chat_model: null  # The model to use for chat completions, if not provided, inferred from env variables
chat_model_api_base: null  # Base URL for OpenAI compatible chat model API. Litellm will recognize vars too
chat_model_api_key: null  # API key for OpenAI compatible chat model API
embedding_model: "text-embedding-3-small" # The model to use for text embeddings. If not provided, inferred from env variables
embedding_model_size: 1536  # The size of the embedding model
embedding_model_api_base: null  # Base URL for OpenAI compatible embedding model API
embedding_model_api_key: null  # API key for OpenAI compatible embedding model API
enable_caching: true  # Whether to enable caching for the LLM, both for embeddings and completions

# Deprecated configuration options
openai_api_key: null  # OpenAI API key (deprecated)
openai_api_base: null  # OpenAI API base URL (deprecated)
openai_embedding_api_base: null  # OpenAI API base URL for embeddings (deprecated)
openai_organization: null  # OpenAI organization ID (deprecated)
anthropic_api_key: null  # Anthropic API key (deprecated)

# Context Management
max_assistant_loops: 4  # Maximum number of loops the assistant can run before tools are temporarily made unvailable (returning for the next user message)
max_tokens: 10000  # Number of tokens that triggers a context refresh and compresion of messages in the context window
max_context_age_minutes: 720.0  # Maximum age in minutes to keep messages in context
min_convo_age_for_greeting_minutes: 120.0  # Minimum age in minutes of conversation before the assistant will offer a greeting on login. 0 means assistant will offer greeting each time. To disable greeting, set --first=True

# Memory Consolidation
memory_cluster_similarity_threshold: 0.21125  # Threshold for memory cluster similarity
memories_between_consolidation: 4  # How many memories to create before triggering a memory consolidation operation
l2_memory_relevance_distance_threshold: 1.24  # L2 distance threshold for memory relevance
max_memory_cluster_size: 5  # The maximum number of memories that can be consolidated into a single memory at once
min_memory_cluster_size: 3  # The minimum number of memories that can be consolidated into a single memory at once

# UI Configuration
show_internal_thought: true  # Show the assistant's internal thought monologue
system_message_color: "#9ACD32"  # Color for system messages
user_input_color: "#FFE377"  # Color for user input
assistant_color: "#77DFD8"  # Color for assistant output
warning_color: "yellow"  # Color for warning messages
internal_thought_color: "#708090"  # Color for internal thought messages
