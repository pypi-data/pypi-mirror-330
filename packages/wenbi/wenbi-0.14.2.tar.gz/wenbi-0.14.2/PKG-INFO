Metadata-Version: 2.3
Name: wenbi
Version: 0.14.2
Summary: A simple tool to make the video, audio, subtitle and video-url (especially youtube) content into a written markdown files with the ability to rewritten the oral expression into written ones, or translating the content into a target language by using LLM. 
Author-email: Ephrem Yuan <areopagusworkshop@gmail.com>
License: Apache-2.0
Requires-Python: >=3.9
Requires-Dist: dspy>=2.6.6
Requires-Dist: fasttext>=0.9.3
Requires-Dist: gradio>=5.18.0
Requires-Dist: moviepy>=2.1.2
Requires-Dist: openai-whisper>=20240930
Requires-Dist: pandas>=2.2.3
Requires-Dist: pip>=25.0.1
Requires-Dist: pyannote-audio>=3.3.2
Requires-Dist: pydub>=0.25.1
Requires-Dist: spacy>=3.8.4
Requires-Dist: yt-dlp>=2025.2.19
Description-Content-Type: text/markdown

# Wenbi

A simple tool to make the video, audio, subtitle and video-url (especially youtube) content into a written markdown files with the ability to rewritten the oral expression into written ones, or translating the content into a target language by using LLM. 

Initally, this porject is just serving to my website [GCDFL](https://www.gcdfl.org/). We do a service to turn its lectures into a written files for easier further editing. 

Note: LLM can make mistakes and cannot be fully trusted. LLM can only be used for preliminary processing of data, some elementary work, and in this sense, LLM does greatly improve editing efficiency. 


### you can try the [demo](https://archive.gcdfl.org/), right now only remove the timestamps and joining the lines. 

## Features

- :100: Accept most popular audio, video, subtitle files and url--mainly using yt-dlp as input. 

- :100: Editing the files by using LLM to rewriting and translating the content into a readable written markdown files. 

- :100: Support input with multiple languages.

- :100: offer an commandline and gradio GUI with multiple options for further personal settings 

- :x: Right now are only support Ollama models, working on other models in OpenAi, Google and others. 


## Cons

- This project right now is main server to the language English, Chinese, Japanese. For other languages, trying to use a different Ollama models. 

## Install

### prerequest
- Install [Ollama](https://ollama.com/) and dowload a model. The default model for this project is qwen2.5. 

### method one 

pip install wenbi

:notice: you may nedd install llvmlite and numba first, then install wenbi. Of course, you need install on a virtue environment.

After install, you can simply using wenbi commandline. 

### method two from source

- install [rye](https://rye.astral.sh/)

### first step clone this repository

`
git clone https://github.com/Areopaguaworkshop/wenbi.git
` 

### second step 

```
cd wenbi 

mv pyproject.toml pyproject-bk.toml

rye init 

```

### third step

`
copy whole content of the pyproject-bk.toml into pyproject.toml
` 

Then run

`source .venv/bin/activate` 

`rye pin 3.12` 

`rye sync`

### four step

You can choose commandline or webGUI through gradio.

- gradio

`python main.py`

Then go to http://localhost:7860. 

- commandline 

'python cli.py --help'

usage: cli.py [-h] [--language LANGUAGE] [--llm LLM] [--multi-language] [--translate-lang TRANSLATE_LANG] [--output-dir OUTPUT_DIR] input

wenbi: Convert video, audio, url or subtitle files to CSV and written Markdown outputs.

positional arguments:
  input                 Path to input file or URL

options:
  -h, --help            show this help message and exit
  --language LANGUAGE   Transcribe Language (optional)
  --llm LLM             Large Language Model identifier (optional)
  --multi-language      Enable multi-language processing (default: False)
  --translate-lang TRANSLATE_LANG
                        Target translation language (default: Chinese)
  --output-dir OUTPUT_DIR
                        Output directory (optional)



Note: if you want to convert the audio file of multi-language, you should set multi-language as True. for commandline is --multi-language. you nedd a HUGGINGFACE_TOKEN in you environment. by `export HUGGINGFACE_TOKEN="you HUGGINGFACE_TOKEN here"`. 


Enjoy! 

### Buy me a Cofee. 

## License:
AI-Subtitle-Editor is licensed under the Apache License 2.0 found in the [LICENSE](https://github.com/Areopaguaworkshop/AI-Subtitle-Editor/blob/main/license.md) file in the root directory of this repository.

## Citation:
```@article{areopagus/wenbi
  title = {wenbi},
  author = {Yuan, Yongjia},
  year = {2024},
}

```

