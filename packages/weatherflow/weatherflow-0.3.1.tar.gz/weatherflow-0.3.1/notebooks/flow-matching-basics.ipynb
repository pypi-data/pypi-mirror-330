{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Matching for Weather Prediction: Fundamentals\n",
    "\n",
    "This notebook introduces the foundational concepts of flow matching and how they apply to weather prediction. We will:\n",
    "\n",
    "1. Understand the mathematical foundations of flow matching\n",
    "2. Implement a simple flow matching model\n",
    "3. Visualize flow fields and trajectory evolution\n",
    "4. Connect these concepts to weather prediction\n",
    "5. Explore physical constraints in flow matching\n",
    "\n",
    "Flow matching is a powerful approach for modeling complex dynamical systems like weather, as it allows us to learn continuous transformations between states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install WeatherFlow if needed\n",
    "try:\n",
    "    import weatherflow\n",
    "    print(f\"WeatherFlow version: {weatherflow.__version__}\")\n",
    "except ImportError:\n",
    "    !pip install -e ..\n",
    "    import weatherflow\n",
    "    print(f\"WeatherFlow installed, version: {weatherflow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress some warnings for cleaner output\n",
    "\n",
    "# Import specific WeatherFlow components\n",
    "from weatherflow.models.flow_matching import WeatherFlowMatch\n",
    "from weatherflow.utils import WeatherVisualizer\n",
    "\n",
    "# Set up matplotlib\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Flow Matching Theory\n",
    "\n",
    "Flow matching is a technique for learning continuous transformations between probability distributions. It's closely related to continuous normalizing flows and can be used to model complex dynamical systems like weather evolution.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Flow Fields**: Continuous vector fields that describe how a system evolves over time\n",
    "2. **Path Interpolation**: Creating smooth paths between source and target states\n",
    "3. **Vector Field Learning**: Learning velocity fields that can generate these paths\n",
    "4. **ODE Integration**: Using learned vector fields to generate new trajectories\n",
    "\n",
    "### Mathematical Foundation\n",
    "\n",
    "In flow matching, we learn a continuous-time flow that transforms a source distribution $p_0(\\mathbf{x})$ into a target distribution $p_1(\\mathbf{x})$. \n",
    "\n",
    "The key equation is:\n",
    "\n",
    "$$\\mathbf{v}(\\mathbf{x}_t, t) = \\frac{d\\mathbf{x}_t}{dt}$$\n",
    "\n",
    "Where $\\mathbf{v}(\\mathbf{x}_t, t)$ is the velocity field at point $\\mathbf{x}_t$ and time $t$.\n",
    "\n",
    "For straight-line paths between $\\mathbf{x}_0$ and $\\mathbf{x}_1$, the target velocity is simply:\n",
    "\n",
    "$$\\mathbf{v}_\\text{target}(\\mathbf{x}_t, t) = \\frac{\\mathbf{x}_1 - \\mathbf{x}_0}{1}$$\n",
    "\n",
    "The goal is to learn a neural network that can approximate this velocity field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Flow Matching Differs from Other Approaches\n",
    "\n",
    "Flow matching has several advantages for weather prediction:\n",
    "\n",
    "1. **Continuous Time**: Models weather as a continuous process, unlike discrete steps in many ML approaches\n",
    "2. **Physical Constraints**: Can incorporate physical laws directly into the flow field\n",
    "3. **Uncertainty Quantification**: Naturally models distributions over possible weather states\n",
    "4. **Flexible Integration**: Can use different numerical methods for different accuracy/speed trade-offs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple Example: 2D Toy Problem\n",
    "\n",
    "To build intuition, let's start with a simple 2D problem: learning a flow that transforms a Gaussian distribution into a mixture of Gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Function to generate data from a simple Gaussian\n",
    "def sample_gaussian(n_samples, mean=[0, 0], std=1.0):\n",
    "    return np.random.normal(mean, std, size=(n_samples, 2))\n",
    "\n",
    "# Function to generate data from a mixture of Gaussians\n",
    "def sample_mixture(n_samples, means=[[2, 2], [-2, 2], [0, -2]], std=0.5):\n",
    "    k = len(means)\n",
    "    # Randomly choose which Gaussian to sample from\n",
    "    indices = np.random.choice(k, size=n_samples)\n",
    "    samples = np.zeros((n_samples, 2))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        gaussian_idx = indices[i]\n",
    "        samples[i] = np.random.normal(means[gaussian_idx], std)\n",
    "        \n",
    "    return samples\n",
    "\n",
    "# Generate samples\n",
    "n_samples = 1000\n",
    "source_samples = sample_gaussian(n_samples)  # Simple Gaussian\n",
    "target_samples = sample_mixture(n_samples)   # Mixture of Gaussians\n",
    "\n",
    "# Plot the source and target distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Source distribution\n",
    "axes[0].scatter(source_samples[:, 0], source_samples[:, 1], alpha=0.5, s=10)\n",
    "axes[0].set_title('Source Distribution: Single Gaussian')\n",
    "axes[0].set_xlim(-4, 4)\n",
    "axes[0].set_ylim(-4, 4)\n",
    "axes[0].grid(True)\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "# Target distribution\n",
    "axes[1].scatter(target_samples[:, 0], target_samples[:, 1], alpha=0.5, s=10)\n",
    "axes[1].set_title('Target Distribution: Mixture of Gaussians')\n",
    "axes[1].set_xlim(-4, 4)\n",
    "axes[1].set_ylim(-4, 4)\n",
    "axes[1].grid(True)\n",
    "axes[1].set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()

# Visualize flow field for the weather-like data
def plot_weather_flow_field(model, time_val, grid_size=32):
    """Plot the weather flow field at a specific time."""
    # Create grid for visualization
    x = np.linspace(-1, 1, grid_size)
    y = np.linspace(-1, 1, grid_size)
    X, Y = np.meshgrid(x, y)
    grid_points = np.stack([X.flatten(), Y.flatten()], axis=1)
    
    # Convert to tensor
    grid_tensor = torch.tensor(grid_points, dtype=torch.float32).to(device)
    
    # Create time tensor
    t = torch.ones(grid_points.shape[0], device=device) * time_val
    
    # Get flow field
    with torch.no_grad():
        velocities = model(grid_tensor, t).cpu().numpy()
    
    # Reshape for plotting
    U = velocities[:, 0].reshape(grid_size, grid_size)
    V = velocities[:, 1].reshape(grid_size, grid_size)
    
    return X, Y, U, V

# Plot flow fields at different time steps
time_steps = [0.0, 0.25, 0.5, 0.75, 1.0]
fig, axes = plt.subplots(1, len(time_steps), figsize=(20, 4))

for i, t_val in enumerate(time_steps):
    X, Y, U, V = plot_weather_flow_field(weather_model, t_val)
    
    # Plot streamlines
    speed = np.sqrt(U**2 + V**2)
    axes[i].streamplot(X, Y, U, V, density=1.5, color=speed, cmap='viridis')
    axes[i].set_title(f"t = {t_val}")
    axes[i].set_aspect('equal')
    axes[i].grid(True)

plt.tight_layout()
plt.show()

# 5. Physics-Constrained Flow Matching

# Now let's incorporate physics constraints into our flow model
class PhysicsConstrainedFlow(nn.Module):
    def __init__(self, hidden_dim=64):
        super().__init__()
        
        # Same network architecture as before
        self.net = nn.Sequential(
            nn.Linear(2 + 1, hidden_dim),
            nn.SiLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.SiLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.SiLU(),
            nn.Linear(hidden_dim, 2)                       
        )
    
    def forward(self, x, t):
        """Compute velocity at point x and time t with physics constraints."""
        # Concatenate x and t
        if t.dim() == 1:
            t = t.unsqueeze(1)
        
        xt = torch.cat([x, t], dim=1)
        
        # Compute raw velocity
        v_raw = self.net(xt)
        
        # Apply physics constraints
        v_constrained = self._apply_divergence_free_constraint(v_raw, x)
        
        return v_constrained
    
    def _apply_divergence_free_constraint(self, v, x):
        """Apply divergence-free constraint to make the flow incompressible.
        
        For weather, this relates to conservation of mass.
        """
        # Simplified implementation for 2D case
        # In a real implementation, we would compute the curl of a potential function
        
        # For now, just normalize the vectors to demonstrate the concept
        v_norm = torch.norm(v, dim=1, keepdim=True)
        v_normalized = v / (v_norm + 1e-8)
        
        # Return normalized vectors (simplified physics constraint)
        return v_normalized * v_norm
    
    def compute_flow_loss(self, x0, x1, t):
        """Compute flow matching loss with physics regularization."""
        # Compute straight-line velocity target
        v_target = x1 - x0
        
        # Interpolate between x0 and x1 at time t
        x_t = x0 + t.unsqueeze(1) * (x1 - x0)
        
        # Predict velocity
        v_pred = self(x_t, t)
        
        # Compute MSE loss
        flow_loss = F.mse_loss(v_pred, v_target)
        
        # Add physics-based regularization
        physics_loss = self._compute_physics_loss(v_pred, x_t)
        
        # Total loss
        total_loss = flow_loss + 0.1 * physics_loss
        
        return total_loss
    
    def _compute_physics_loss(self, v, x):
        """Compute physics-based regularization loss.
        
        For weather, this would include terms for:
        - Divergence-free (continuity equation)
        - Energy conservation
        - Geostrophic balance
        etc.
        """
        # Simple physics loss: encourage smoothness of the vector field
        # In a real implementation, we would have more sophisticated terms
        
        # Calculate magnitude (for demonstration)
        v_norm = torch.norm(v, dim=1)
        
        # Penalize very large velocities (simplified energy constraint)
        energy_penalty = torch.mean((v_norm - 1.0)**2)
        
        return energy_penalty

# Train the physics-constrained model
physics_model = PhysicsConstrainedFlow(hidden_dim=64).to(device)
physics_optimizer = torch.optim.Adam(physics_model.parameters(), lr=1e-3)

# Training loop
n_epochs = 50
physics_losses = []

for epoch in tqdm(range(n_epochs)):
    epoch_loss = 0
    
    for x0, x1 in weather_dataloader:
        x0, x1 = x0.to(device), x1.to(device)
        
        # Generate random times between 0 and 1
        t = torch.rand(x0.size(0), device=device)
        
        # Compute loss
        loss = physics_model.compute_flow_loss(x0, x1, t)
        
        # Backward pass and optimize
        physics_optimizer.zero_grad()
        loss.backward()
        physics_optimizer.step()
        
        epoch_loss += loss.item() * x0.size(0)
    
    # Average loss for the epoch
    epoch_loss /= len(weather_dataset)
    physics_losses.append(epoch_loss)
    
    # Print progress
    if (epoch + 1) % 10 == 0:
        print(f"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss:.6f}")

# Compare flow fields from standard and physics-constrained models
fig, axes = plt.subplots(2, 3, figsize=(18, 12))

# Time points to visualize
vis_times = [0.0, 0.5, 1.0]

for i, t_val in enumerate(vis_times):
    # Standard model
    X, Y, U, V = plot_weather_flow_field(weather_model, t_val)
    speed = np.sqrt(U**2 + V**2)
    
    axes[0, i].streamplot(X, Y, U, V, density=1.5, color=speed, cmap='viridis')
    axes[0, i].set_title(f"Standard Model, t = {t_val}")
    axes[0, i].set_aspect('equal')
    axes[0, i].grid(True)
    
    # Physics-constrained model
    X, Y, U, V = plot_weather_flow_field(physics_model, t_val)
    speed = np.sqrt(U**2 + V**2)
    
    axes[1, i].streamplot(X, Y, U, V, density=1.5, color=speed, cmap='viridis')
    axes[1, i].set_title(f"Physics-Constrained, t = {t_val}")
    axes[1, i].set_aspect('equal')
    axes[1, i].grid(True)

plt.tight_layout()
plt.show()

# 6. Connection to the WeatherFlow Library

print("""
## WeatherFlow Library Implementation

The WeatherFlow library implements these concepts at scale for real weather data:

1. **WeatherFlowMatch Model**: Neural network for learning weather flow fields
   - Convolutional architecture for spatial structure
   - Time embedding for temporal dynamics
   - Physics-informed constraints for physical consistency

2. **ODE Integration**: Uses torchdiffeq for generating predictions
   - WeatherFlowODE class wraps the flow model with an ODE solver
   - Flexible solver methods (Runge-Kutta, Dopri5, etc.)
   - Adjustable tolerances for accuracy vs. speed trade-offs

3. **Spherical Geometry**: Accounts for Earth's spherical surface
   - Proper handling of coordinate systems
   - Accounting for convergence of meridians
   - Managing periodic boundary conditions

4. **Physics Constraints**: Incorporates atmospheric physics
   - Conservation of mass (divergence-free)
   - Energy conservation
   - Geostrophic balance
   - Coriolis effects

In the next notebooks, we'll apply these concepts to real ERA5 weather data.
""")

# Show an example of using the WeatherFlow library for a simple case
from weatherflow.models import WeatherFlowMatch

# Create a toy example input (batch_size=1, channels=2, height=16, width=32)
toy_input = torch.randn(1, 2, 16, 32).to(device)
time_points = torch.tensor([0.5]).to(device)

# Create model
model = WeatherFlowMatch(
    input_channels=2,
    hidden_dim=64,
    n_layers=3,
    physics_informed=True
).to(device)

# Forward pass
with torch.no_grad():
    velocity = model(toy_input, time_points)
    print(f"Input shape: {toy_input.shape}")
    print(f"Output velocity shape: {velocity.shape}")
    print(f"Velocity statistics: min={velocity.min().item():.4f}, max={velocity.max().item():.4f}, mean={velocity.mean().item():.4f}")

print("""
## Conclusion

In this notebook, we've explored the fundamentals of flow matching and how it applies to weather prediction:

1. We implemented a simple flow matching model for 2D distributions
2. We visualized flow fields and generated trajectories
3. We extended the approach to weather-like data
4. We incorporated physics constraints for more realistic flows
5. We connected these concepts to the WeatherFlow library

In the next notebook, we'll train a full WeatherFlowMatch model on real ERA5 data and evaluate its predictive performance.
""")
"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Creating Training Pairs for Flow Matching\n",
    "\n",
    "For flow matching, we need matching pairs of points from the source and target distributions. We'll use simple random pairing for this toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "source_tensor = torch.tensor(source_samples, dtype=torch.float32)\n",
    "target_tensor = torch.tensor(target_samples, dtype=torch.float32)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TensorDataset(source_tensor, target_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Let's visualize a few pairs of points\n",
    "n_vis = 10\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot all samples as background\n",
    "ax.scatter(source_samples[:, 0], source_samples[:, 1], alpha=0.2, s=10, color='blue', label='Source')\n",
    "ax.scatter(target_samples[:, 0], target_samples[:, 1], alpha=0.2, s=10, color='red', label='Target')\n",
    "\n",
    "# Plot a few pairs with connecting lines\n",
    "for i in range(n_vis):\n",
    "    ax.plot([source_samples[i, 0], target_samples[i, 0]], \n",
    "             [source_samples[i, 1], target_samples[i, 1]], \n",
    "             'k-', alpha=0.3)\n",
    "    \n",
    "ax.set_title('Matching Pairs for Flow Learning')\n",
    "ax.set_xlim(-4, 4)\n",
    "ax.set_ylim(-4, 4)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Simple Flow Matching Model\n",
    "\n",
    "Now, let's implement a simple flow matching model for this 2D problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFlowModel(nn.Module):\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Network architecture\n",
    "        self.net = nn.Sequential(\n",
    "            # Input: x and t (2+1=3 dimensions)\n",
    "            nn.Linear(2 + 1, hidden_dim),\n",
    "            nn.SiLU(),  # Smooth activation function\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            # Output: velocity vector (2 dimensions)\n",
    "            nn.Linear(hidden_dim, 2)                       \n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        \"\"\"Compute velocity at point x and time t.\"\"\"\n",
    "        # Concatenate x and t\n",
    "        if t.dim() == 1:\n",
    "            # Add channel dimension to t\n",
    "            t = t.unsqueeze(1)\n",
    "        \n",
    "        xt = torch.cat([x, t], dim=1)\n",
    "        \n",
    "        # Compute velocity\n",
    "        velocity = self.net(xt)  \n",
    "        return velocity\n",
    "    \n",
    "    def compute_flow_loss(self, x0, x1, t):\n",
    "        \"\"\"Compute flow matching loss.\"\"\"\n",
    "        # Compute straight-line velocity target\n",
    "        v_target = x1 - x0  # For t in [0, 1], velocity = displacement\n",
    "        \n",
    "        # Interpolate between x0 and x1 at time t\n",
    "        x_t = x0 + t.unsqueeze(1) * (x1 - x0)\n",
    "        \n",
    "        # Predict velocity\n",
    "        v_pred = self(x_t, t)\n",
    "        \n",
    "        # Compute MSE loss\n",
    "        loss = F.mse_loss(v_pred, v_target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = SimpleFlowModel(hidden_dim=64).to(device)\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 50\n",
    "losses = []\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for x0, x1 in dataloader:\n",
    "        x0, x1 = x0.to(device), x1.to(device)\n",
    "        \n",
    "        # Generate random times between 0 and 1\n",
    "        t = torch.rand(x0.size(0), device=device)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = model.compute_flow_loss(x0, x1, t)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item() * x0.size(0)\n",
    "    \n",
    "    # Average loss for the epoch\n",
    "    epoch_loss /= len(dataset)\n",
    "    losses.append(epoch_loss)\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss:.6f}\")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualize Learned Flow Field\n",
    "\n",
    "Now let's visualize the flow field that our model has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of points\n",
    "grid_size = 20\n",
    "x = np.linspace(-4, 4, grid_size)\n",
    "y = np.linspace(-4, 4, grid_size)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Visualize flow field at different time steps\n",
    "time_steps = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "fig, axes = plt.subplots(1, len(time_steps), figsize=(20, 4))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, t_val in enumerate(time_steps):\n",
    "        # Prepare grid points\n",
    "        grid_points = np.stack([X.flatten(), Y.flatten()], axis=1)\n",
    "        grid_tensor = torch.tensor(grid_points, dtype=torch.float32).to(device)\n",
    "        t = torch.ones(grid_points.shape[0], device=device) * t_val\n",
    "        \n",
    "        # Compute velocities\n",
    "        velocities = model(grid_tensor, t).cpu().numpy()\n",
    "        \n",
    "        # Reshape for plotting\n",
    "        U = velocities[:, 0].reshape(grid_size, grid_size)\n",
    "        V = velocities[:, 1].reshape(grid_size, grid_size)\n",
    "        \n",
    "        # Calculate velocity magnitude for coloring\n",
    "        speed = np.sqrt(U**2 + V**2)\n",
    "        \n",
    "        # Plot\n",
    "        axes[i].streamplot(X, Y, U, V, density=1.5, color=speed, cmap='viridis',\n",
    "                          linewidth=1, arrowsize=1.5)\n",
    "        axes[i].set_title(f\"t = {t_val}\")\n",
    "        axes[i].set_xlim(-4, 4)\n",
    "        axes[i].set_ylim(-4, 4)\n",
    "        axes[i].grid(True)\n",
    "        axes[i].set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Generate Trajectories using ODE Solver\n",
    "\n",
    "Now that we have a learned flow field, we can use an ODE solver to generate trajectories from the source to the target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ODE solver\n",
    "from t