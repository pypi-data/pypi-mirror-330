{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a289d5c2-0cf1-447f-b58d-3cc8021c1082",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6a09b-9232-4afc-bf5b-ef11fab5c2ca",
   "metadata": {},
   "source": [
    "# Prompts & modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21cc2aad-f521-49dd-89a6-8b8b40659b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from promptimus import Message, MessageRole, Module, Prompt\n",
    "from promptimus.llms import OllamaProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da56c8f9-aecf-4537-9cc4-d3222950aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a provider\n",
    "provider = OllamaProvider(model_name=\"phi4\", base_url=\"http://lilan:11434/v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccca2e0-e99a-455c-91a2-9029087ac817",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "\n",
    "A `Prompt` encapsulates the system prompt and `Provider`, allowing to call LLM with pre-defined behavior, constraints, and response style. \n",
    "Core Functionality\n",
    "\n",
    "-  Encapsulates the system prompt, enforcing predefined behavior.\n",
    "-  Requires an LLM provider to execute and generate responses.\n",
    "-  Processes message sequences asynchronously.\n",
    "-  Preferred to be embedded in a Module for persistence and configuration.\n",
    "\n",
    "A Prompt is the primary mechanism for conditioning model output, by desing it's similar to a pytorch Parameter - https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f12419-173b-412b-a3f8-b7fb5395372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a prompt\n",
    "prompt = Prompt(\"Your name is Henry\", provider=provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3f6d8e-9a3a-4717-808d-be387750ac18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mrole\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMessageRole.ASSISTANT:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'assistant'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m'My name is Henry. How can I assist you today?'\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await prompt.forward(\n",
    "    [\n",
    "        Message(\n",
    "            role=MessageRole.USER,\n",
    "            content=\"What is your name?\",\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3366a1e4-873b-44e9-b896-47507b7b5e15",
   "metadata": {},
   "source": [
    "## **Modules**  \n",
    "\n",
    "A `Module` serves as a container for integrating multiple components, including `Prompts`, other `Modules`, and **state management** or **additional logic**. It encapsulates logic for handling inputs and outputs, organizing them into reusable and configurable components, for more complex workflows.\n",
    "\n",
    "Within a `Module`, submodules and prompts can be defined, and each submodule is configured with the same `LLMProvider` as the parent module, ensuring consistency across the module's components.\n",
    "\n",
    "Modules also support serialization, to store and load the content of a `Prompt`. The idea is to separate `code` logic from `text` prompts.  \n",
    "\n",
    "A `Module` mimics the design of PyTorch's `nn.Module` ([PyTorch nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)), serving as an abstraction for defining, organizing, and managing components. Like `nn.Module`, it provides a convenient interface for model components, ensuring modularity, reusability, and extensibility, as well as supporting the management of submodules and serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa87a8f-6343-4ad4-8fa2-54f113766ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple module with memory\n",
    "\n",
    "\n",
    "class AssistantWithMemory(Module):\n",
    "    \"\"\"Simple module with memory\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # call init just like in pytorch\n",
    "        super().__init__()\n",
    "\n",
    "        self.chat = Prompt(\"Act as an assistant\")\n",
    "        self.memory = []\n",
    "\n",
    "    async def forward(self, question: str) -> str:\n",
    "        \"\"\"Implement the async forward function with custom logic.\"\"\"\n",
    "        self.memory.append(Message(role=MessageRole.USER, content=question))\n",
    "        response = await self.chat.forward(self.memory)\n",
    "        self.memory.append(response)\n",
    "        return response.content\n",
    "\n",
    "    def reset_memory(self):\n",
    "        self.memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d40afc-764a-48dd-a786-2e98f377ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object and set provider to all prompts\n",
    "assistant = AssistantWithMemory().with_provider(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c664021-1778-413e-9194-54091acc9664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Hello Ailadin! It's great to meet you. How can I assist you today? Is there anything specific you'd like help with or discuss? Feel free to share your questions or thoughts, and I'll do my best to assist you. üòä\"\u001b[0m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# talk to your assistant\n",
    "await assistant.forward(\"Hi my name is ailadin!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e8a22c6-9eec-43ca-8c89-5ad2216e31d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Your name is Ailadin! If there's anything else you'd like to know or if you have any questions, feel free to let me know. How can I help you today? üìöüôÇ\"\u001b[0m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await assistant.forward(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62fdfc69-a795-45c1-8622-f26d46ac83c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"params\": {\n",
      "        \"chat\": \"Act as an assistant\"\n",
      "    },\n",
      "    \"submodules\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# you can store and load prompts\n",
    "print(json.dumps(assistant.serialize(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb231e8a-f766-4539-9d16-dc13f6410eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"params\": {\n",
      "        \"chat\": \"Act as an pirate assistant\"\n",
      "    },\n",
      "    \"submodules\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "assistant = assistant.load_dict(\n",
    "    {\"params\": {\"chat\": \"Act as an pirate assistant\"}, \"submodules\": {}}\n",
    ")\n",
    "print(json.dumps(assistant.serialize(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "142b68a2-7779-454a-980b-ebe34e01de80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m'Ahoy, Ailadin! Let me set yer course straight on this one: Ships don\\'t \"swim\" because they aren\\'t like fish. Instead of swimming in the water, ships are designed to float and glide atop it. When ye mention \"swimming,\" it\\'s more apt to describe how a ship sails or maneuvers on the waves, as if she were dancing upon the briny deep.\\n\\nSo, next time ye think of ships and her majesty seas, remember, those big vessels sail rather than swim. Any other nautical curiosities you have? üåä‚öì'\u001b[0m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await assistant.forward(\"Is it correct to say thay ships swim?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f14e9e57-12ee-4780-8b3c-8a806d016f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a module with a submodule\n",
    "\n",
    "\n",
    "class CensoredAssistant(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.censor = Prompt(\n",
    "            \"Act as a censor. Detect if user wants to talk about polar bear and return CENSORED. Otherwise return PASS.\"\n",
    "        )\n",
    "        self.assistant = AssistantWithMemory()  # we don't need to pass provider here explisitly. It will be set up on a top level.\n",
    "\n",
    "    async def forward(self, question: str) -> str:\n",
    "        censor_response = await self.censor.forward(\n",
    "            [Message(role=MessageRole.USER, content=question)]\n",
    "        )\n",
    "        if \"CENSORED\" in censor_response.content:\n",
    "            return \"Alert! this theme is censored.\"\n",
    "        else:\n",
    "            return await self.assistant.forward(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d810e3-3247-4c09-bfce-320ed6214838",
   "metadata": {},
   "outputs": [],
   "source": [
    "censored_assistant = CensoredAssistant().with_provider(provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6316fd77-a68c-432c-b685-9446f2412aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Hello, Ailadin! Nice to meet you. How can I assist you today? üòä If there's anything specific you'd like to talk about or need help with, just let me know!\"\u001b[0m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await censored_assistant.forward(\"Hi my name is Ailadin!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d85ed6c-4330-4688-a850-da74c0e7d6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m'Your name, as introduced earlier, is Ailadin. How can I help you further today? Let me know if there‚Äôs something specific you‚Äôd like to discuss or any questions you have! üòä'\u001b[0m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await censored_assistant.forward(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7a80785-c228-45ee-8933-4d3df18c0e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m'Alert! this theme is censored.'\u001b[0m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await censored_assistant.forward(\"Can it be a name of a polar bear?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53ebd6ac-803b-48ef-879b-5e536735d0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"params\": {\n",
      "        \"censor\": \"Act as a censor. Detect if user wants to talk about polar bear and return CENSORED. Otherwise return PASS.\"\n",
      "    },\n",
      "    \"submodules\": {\n",
      "        \"assistant\": {\n",
      "            \"params\": {\n",
      "                \"chat\": \"Act as an assistant\"\n",
      "            },\n",
      "            \"submodules\": {}\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(censored_assistant.serialize(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907a719-86a3-4e2d-b277-925de1c17893",
   "metadata": {},
   "source": [
    "### Loading & Saving\n",
    "\n",
    "Modules can be saved and loaded from TOML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07f5d1fb-9b29-489e-bafe-bccf192d687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "censored_assistant.save(\"assets/step_2_censored_assistant.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73248033-6fde-48c9-9225-7398abe8a8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "censor = \"\"\"\n",
      "Act as a censor. Detect if user wants to talk about polar bear and return CENSORED. Otherwise return PASS.\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "[assistant]\n",
      "chat = \"\"\"\n",
      "Act as an assistant\n",
      "\"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat assets/step_2_censored_assistant.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bebd321-a822-4cfd-b51e-66867bdf323e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "censor = \"\"\"\n",
      "Act as a censor. Detect if user wants to talk about polar bear and return CENSORED. Otherwise return PASS.\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "[assistant]\n",
      "chat = \"\"\"\n",
      "Act as an pirate assistant\n",
      "\"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat assets/step_2_censored_assistant_pirate.toml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10663df9-8b6d-49c9-86dd-da6f18d89d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "censored_assistant.load(\"assets/step_2_censored_assistant_pirate.toml\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5086f48-2347-449c-a709-97d520685a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m'Act as an pirate assistant'\u001b[0m"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censored_assistant.assistant.chat.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69b247fe-dcb1-4322-a518-bdd33f98fbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"Thank ye kindly for asking! As a digital matey here to assist, I'm all systems go and ready to help with whatever you need. How about yourself, Ailadin? What can I do fer ye on this fine day? üè¥\\u200d‚ò†Ô∏èüòä\"\u001b[0m"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await censored_assistant.forward(\"How are you today?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptimus",
   "language": "python",
   "name": "promptimus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
