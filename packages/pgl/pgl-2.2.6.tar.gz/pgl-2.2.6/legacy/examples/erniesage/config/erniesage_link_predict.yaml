# Global Enviroment Settings 
#
# trainer config ------
task: "link_predict"
batch_size: 32
epochs: 30

# data config ------
graph_data: "./example_data/link_predict/graph_data.txt"
train_data: "./example_data/link_predict/train_data.txt"

graph_work_path: "./workdir"
sample_workers: 1
use_pyreader: true
input_type: "text"

# model config ------
samples: [10]
model_type: "ERNIESageV1"

max_seqlen: 40

num_layers: 1
hidden_size: 128
final_fc: true
final_l2_norm: true
loss_type: "global_hinge"
margin: 0.1
neg_type: "batch_neg"

# infer config ------
#infer_model: "./output/last"
infer_batch_size: 128

# ernie config ------
encoding: "utf8"
#ernie_name: "ernie-1.0"
ernie_name: "ernie-tiny" #tiny is 4x faster than ernie1.0
#ernie_name: "./ernie1.0_model" # 不可连外网时，也可以把ERNIE github上的模型拉取到本地来热启

# runconfig 
model_dir: "./output"
max_steps: 10000
save_steps: 100
log_steps: 1
max_ckpt: 1
skip_steps: 0
eval_steps: 10000
eval_max_steps: 1000000
run_steps: 0

# hparam
warmup_proportion:  0.1
weight_decay: 0.01
learning_rate: 0.00005
log_prefix: "training"
