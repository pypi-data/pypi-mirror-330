import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset
from typing import List, Tuple, Optional, Union


class TrunkData:
    """
    Trunk data class to handle data generated by the Trunk simulator.
    
    Stores simulation data with time, states, and inputs in a pandas DataFrame.
    Provides functionality to save as CSV and convert to PyTorch dataset.
    """
    def __init__(self, num_links_per_segment: int, num_segments: int, states: str = "pos", segments: Optional[Union[List, str]] = None, links: Optional[Union[List,str]] = None):
        """
        Initialize a TrunkData object.
        
        Args:
            num_links_per_segment: number of links in each segment
            num_segments: number of segments in the system
            states: states to be saved ("pos", "vel", "pos_vel")
            segments: segments to be included in the dataset, possibilities are "all", "tip" or a list of segment indices
            links: links to be included in the dataset, possibilities are "all" or a list of link indices. Segments and links cannot be specified at the same time.
        """
        num_links = num_links_per_segment * num_segments

        if segments is not None and links is not None:
            raise ValueError("Cannot specify both segments and links.")
        
        if links is not None:
            if links == "all":
                links = list(range(1, num_links + 1))
        else:
            if segments is None or segments == "tip":
                links = [num_links]
            elif segments == "all":
                links = list(range(num_links_per_segment, num_links+1, num_links_per_segment))
            else:
                links = [num_links_per_segment * segment for segment in segments]

        self.states = states
        self.links = links
        self.num_links = num_links
        self.num_segments = num_segments
        self.link_idx = [link - 1 for link in links]
        
        # Column name patterns
        self.time_col = "t"

        if self.states == "pos":
            self.state_cols = [f"{axis}{link}" for link in links for axis in ["x", "y", "z"]]
            self.state_new_cols = [f"{axis}{link}_new" for link in links for axis in ["x", "y", "z"]]
        elif self.states == "vel":
            self.state_cols = [f"{axis}{link}" for link in links for axis in ["vx", "vy", "vz"]]
            self.state_new_cols = [f"{axis}{link}_new" for link in links for axis in ["vx", "vy", "vz"]]
        elif self.states == "pos_vel":
            self.state_cols = [f"{axis}{link}" for link in links for axis in ["x", "y", "z", "vx", "vy", "vz"]]
            self.state_new_cols = [f"{axis}{link}_new" for link in links for axis in ["x", "y", "z", "vx", "vy", "vz"]]
        else:
            raise ValueError(f"Invalid states specification: {self.states}")

        # All control inputs are saved
        self.control_cols = [f"u{axis}{link}" for link in range(1, self.num_links + 1) for axis in ["x", "y"]]

        self.state_dim = len(self.state_cols)
        self.control_dim = len(self.control_cols)
        
        # Initialize an empty DataFrame
        self.dataframe = pd.DataFrame()
    
    def add_data(self, t: float, x: np.ndarray, u: np.ndarray, x_new: np.ndarray) -> None:
        """
        Add a single data point to the dataset.
        
        Args:
            t: Time value
            x: State vector of shape (num_links, 6)
            u: Input vector of shape (num_links, 2)
            x_new: Next state vector of shape (num_links, 6)
        """

        # Check dimensions
        assert x.shape == (self.num_links, 6), f"Expected state shape {(self.num_links, 6)}, got {x.shape}"
        assert u.shape == (self.num_segments, 2), f"Expected input shape {(self.num_segments, 2)}, got {u.shape}"
        assert x_new.shape == (self.num_links, 6), f"Expected next state shape {(self.num_links, 6)}, got {x_new.shape}"

        # Subselect the desired states
        if self.states == "pos":
            x = x[:, :3]
            x_new = x_new[:, :3]
        elif self.states == "vel":
            x = x[:, 3:]
            x_new = x_new[:, 3:]
        elif self.states == "pos_vel":
            pass

        # Subselect the desired links
        x = x[self.link_idx].flatten()
        u = u.flatten()  # all control inputs are saved
        x_new = x_new[self.link_idx].flatten()

        # Create a new row
        row_data = {self.time_col: t}
        
        # Add state and input data
        row_data.update(dict(zip(self.state_cols, x)))
        row_data.update(dict(zip(self.control_cols, u)))
        row_data.update(dict(zip(self.state_new_cols, x_new)))
            
        # Append the new row
        new_row = pd.DataFrame([row_data])
        self.dataframe = pd.concat([self.dataframe, new_row], ignore_index=True)

    def add_batch_data(self, t_batch: np.ndarray,
                      x_batch: np.ndarray,
                      u_batch: np.ndarray,
                      x_new_batch: np.ndarray) -> None:
        """
        Add a batch of data points to the dataset.
        
        Args:
            t_batch: Array of time values of shape (batch_size,)
            x_batch: Array of state vectors of shape (batch_size, num_links, 6 * num_links)
            u_batch: Array of input vectors of shape (batch_size, num_links, 2 * num_links)
            x_new_batch: Array of next state vectors of shape (batch_size, num_links, 6 * num_links)
        """
        # Expected shapes
        batch_size = len(t_batch)
        expected_x_shape = (batch_size, self.num_links, 6)
        expected_u_shape = (batch_size, self.num_links, 2)
        expected_x_new_shape = (batch_size, self.num_links, 6)
        
        # Check dimensions
        assert x_batch.shape == expected_x_shape, f"Expected x_batch shape {expected_x_shape}, got {x_batch.shape}"
        assert u_batch.shape == expected_u_shape, f"Expected u_batch shape {expected_u_shape}, got {u_batch.shape}"
        assert x_new_batch.shape == expected_x_new_shape, f"Expected x_new_batch shape {expected_x_new_shape}, got {x_new_batch.shape}"

        # Subselect the desired states
        if self.states == "pos":
            x_batch = x_batch[:, :, :3]
            x_new_batch = x_new_batch[:, :, :3]
        elif self.states == "vel":
            x_batch = x_batch[:, :, 3:]
            x_new_batch = x_new_batch[:, :, 3:]
        
        # Subselect the desired links
        x_batch = x_batch[:, self.link_idx].reshape(batch_size, -1)
        u_batch = u_batch.reshape(batch_size, -1)  # all control inputs are saved
        x_new_batch = x_new_batch[:, self.link_idx].reshape(batch_size, -1)

        # Create batch data
        batch_data = {self.time_col: t_batch}

        # Add data 
        for i, col in enumerate(self.state_cols):
            batch_data[col] = x_batch[:, i]
        for i, col in enumerate(self.control_cols):
            batch_data[col] = u_batch[:, i]
        for i, col in enumerate(self.state_new_cols):
            batch_data[col] = x_new_batch[:, i]

        # Create and append the new batch
        batch_df = pd.DataFrame(batch_data)
        self.dataframe = pd.concat([self.dataframe, batch_df], ignore_index=True)
    
    def save_to_csv(self, filename: str) -> None:
        """
        Save the data to a CSV file.
        
        Args:
            filename: Path to the CSV file to save
        """
        self.dataframe.to_csv(filename, index=False)

    def load_from_csv(self, filename: str) -> None:
        """
        Load data from a CSV file.
        
        Args:
            filename: Path to the CSV file to load
        """
        self.dataframe = pd.read_csv(filename)
        
        # Infer column types
        cols = list(self.dataframe.columns)
        if 't' in cols:
            self.time_col = 't'
            cols.remove('t')
        
        # Identify control columns first (assume they start with 'u')
        self.control_cols = [col for col in cols if col.startswith('u')]
        
        # Separate state and state_new columns (all non-control, non-time columns)
        remaining_cols = [col for col in cols if col not in self.control_cols]
        
        self.state_cols = [col for col in remaining_cols if not col.endswith('_new')]
        self.state_new_cols = [col for col in remaining_cols if col.endswith('_new')]
        
        # Sort columns to ensure consistent ordering
        self.state_cols.sort()
        self.state_new_cols.sort()
        self.control_cols.sort()
        
        self.state_dim = len(self.state_cols)
        self.control_dim = len(self.control_cols)
    
    def convert_to_torch_dataset(self, 
                                input_cols: Optional[List[str]] = None, 
                                output_cols: Optional[List[str]] = None) -> 'TrunkTorchDataset':
        """
        Convert to a PyTorch Dataset.
        
        Args:
            input_cols: List of column names to use as inputs
            output_cols: List of column names to use as outputs
            
        Returns:
            A TrunkTorchDataset instance
        """
        if input_cols is None:
            input_cols = self.state_cols + self.control_cols
        if output_cols is None:
            output_cols = self.state_new_cols
            
        return TrunkTorchDataset(self.dataframe, input_cols, output_cols)
    
    def get_data_at_time(self, t: float) -> np.ndarray:
        """
        Get the single row of data at a specific time.
        
        Args:
            t: Time value
            
        Returns:
            Vector with states, control and new states at the given time
        """
        # Find the closest time
        closest_idx = (self.dataframe[self.time_col] - t).abs().idxmin()
        return self.dataframe.loc[closest_idx, :].values
    
    def __len__(self) -> int:
        """Return the number of data points."""
        return len(self.dataframe)
    
    def __getitem__(self, idx):
        """Allow indexing the data directly."""
        return self.dataframe.iloc[idx]


class TrunkTorchDataset(Dataset):
    """PyTorch Dataset wrapper for TrunkData."""
    
    def __init__(self, dataframe: pd.DataFrame, 
                 input_cols: List[str],
                 output_cols: List[str]):
        """
        Initialize a PyTorch dataset from a pandas DataFrame.
        
        Args:
            dataframe: Source DataFrame
            input_cols: Column names to use as inputs
            output_cols: Column names to use as outputs
        """
        self.dataframe = dataframe
        self.input_cols = input_cols
        self.output_cols = output_cols
    
    def __len__(self) -> int:
        """Return the number of data points."""
        return len(self.dataframe)
    
    def __getitem__(self, idx) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Get a single data point.
        
        Args:
            idx: Index of the data point
            
        Returns:
            Tuple of (input_tensor, output_tensor)
        """
        if isinstance(idx, torch.Tensor):
            idx = idx.item()
            
        # Get input and output values
        inputs = self.dataframe.iloc[idx][self.input_cols].values
        outputs = self.dataframe.iloc[idx][self.output_cols].values
        
        # Convert to PyTorch tensors
        input_tensor = torch.tensor(inputs, dtype=torch.float32)
        output_tensor = torch.tensor(outputs, dtype=torch.float32)
        
        return input_tensor, output_tensor
