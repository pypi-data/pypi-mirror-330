# coding=utf-8
# *** WARNING: this file was generated by the Pulumi SDK Generator. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import copy
import warnings
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
from ... import _utilities
from ._enums import *

__all__ = [
    'GoogleCloudMlV1_AutomatedStoppingConfig_DecayCurveAutomatedStoppingConfigArgs',
    'GoogleCloudMlV1_AutomatedStoppingConfig_MedianAutomatedStoppingConfigArgs',
    'GoogleCloudMlV1_HyperparameterOutput_HyperparameterMetricArgs',
    'GoogleCloudMlV1_Measurement_MetricArgs',
    'GoogleCloudMlV1_StudyConfigParameterSpec_CategoricalValueSpecArgs',
    'GoogleCloudMlV1_StudyConfigParameterSpec_DiscreteValueSpecArgs',
    'GoogleCloudMlV1_StudyConfigParameterSpec_DoubleValueSpecArgs',
    'GoogleCloudMlV1_StudyConfigParameterSpec_IntegerValueSpecArgs',
    'GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentCategoricalValueSpecArgs',
    'GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentDiscreteValueSpecArgs',
    'GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentIntValueSpecArgs',
    'GoogleCloudMlV1_StudyConfig_MetricSpecArgs',
    'GoogleCloudMlV1_StudyConfig_ParameterSpecArgs',
    'GoogleCloudMlV1_Trial_ParameterArgs',
    'GoogleCloudMlV1__AcceleratorConfigArgs',
    'GoogleCloudMlV1__AutoScalingArgs',
    'GoogleCloudMlV1__AutomatedStoppingConfigArgs',
    'GoogleCloudMlV1__BuiltInAlgorithmOutputArgs',
    'GoogleCloudMlV1__ContainerPortArgs',
    'GoogleCloudMlV1__ContainerSpecArgs',
    'GoogleCloudMlV1__DiskConfigArgs',
    'GoogleCloudMlV1__EncryptionConfigArgs',
    'GoogleCloudMlV1__EnvVarArgs',
    'GoogleCloudMlV1__ExplanationConfigArgs',
    'GoogleCloudMlV1__HyperparameterOutputArgs',
    'GoogleCloudMlV1__HyperparameterSpecArgs',
    'GoogleCloudMlV1__IntegratedGradientsAttributionArgs',
    'GoogleCloudMlV1__ManualScalingArgs',
    'GoogleCloudMlV1__MeasurementArgs',
    'GoogleCloudMlV1__MetricSpecArgs',
    'GoogleCloudMlV1__ParameterSpecArgs',
    'GoogleCloudMlV1__PredictionInputArgs',
    'GoogleCloudMlV1__PredictionOutputArgs',
    'GoogleCloudMlV1__ReplicaConfigArgs',
    'GoogleCloudMlV1__RequestLoggingConfigArgs',
    'GoogleCloudMlV1__RouteMapArgs',
    'GoogleCloudMlV1__SampledShapleyAttributionArgs',
    'GoogleCloudMlV1__SchedulingArgs',
    'GoogleCloudMlV1__StudyConfigArgs',
    'GoogleCloudMlV1__TrainingInputArgs',
    'GoogleCloudMlV1__TrainingOutputArgs',
    'GoogleCloudMlV1__XraiAttributionArgs',
    'GoogleIamV1__AuditConfigArgs',
    'GoogleIamV1__AuditLogConfigArgs',
    'GoogleIamV1__BindingArgs',
    'GoogleType__ExprArgs',
]

@pulumi.input_type
class GoogleCloudMlV1_AutomatedStoppingConfig_DecayCurveAutomatedStoppingConfigArgs:
    def __init__(__self__, *,
                 use_elapsed_time: Optional[pulumi.Input[bool]] = None):
        """
        :param pulumi.Input[bool] use_elapsed_time: If true, measurement.elapsed_time is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.steps will be used as the x-axis.
        """
        if use_elapsed_time is not None:
            pulumi.set(__self__, "use_elapsed_time", use_elapsed_time)

    @property
    @pulumi.getter(name="useElapsedTime")
    def use_elapsed_time(self) -> Optional[pulumi.Input[bool]]:
        """
        If true, measurement.elapsed_time is used as the x-axis of each Trials Decay Curve. Otherwise, Measurement.steps will be used as the x-axis.
        """
        return pulumi.get(self, "use_elapsed_time")

    @use_elapsed_time.setter
    def use_elapsed_time(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "use_elapsed_time", value)


@pulumi.input_type
class GoogleCloudMlV1_AutomatedStoppingConfig_MedianAutomatedStoppingConfigArgs:
    def __init__(__self__, *,
                 use_elapsed_time: Optional[pulumi.Input[bool]] = None):
        """
        The median automated stopping rule stops a pending trial if the trial's best objective_value is strictly below the median 'performance' of all completed trials reported up to the trial's last measurement. Currently, 'performance' refers to the running average of the objective values reported by the trial in each measurement.
        :param pulumi.Input[bool] use_elapsed_time: If true, the median automated stopping rule applies to measurement.use_elapsed_time, which means the elapsed_time field of the current trial's latest measurement is used to compute the median objective value for each completed trial.
        """
        if use_elapsed_time is not None:
            pulumi.set(__self__, "use_elapsed_time", use_elapsed_time)

    @property
    @pulumi.getter(name="useElapsedTime")
    def use_elapsed_time(self) -> Optional[pulumi.Input[bool]]:
        """
        If true, the median automated stopping rule applies to measurement.use_elapsed_time, which means the elapsed_time field of the current trial's latest measurement is used to compute the median objective value for each completed trial.
        """
        return pulumi.get(self, "use_elapsed_time")

    @use_elapsed_time.setter
    def use_elapsed_time(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "use_elapsed_time", value)


@pulumi.input_type
class GoogleCloudMlV1_HyperparameterOutput_HyperparameterMetricArgs:
    def __init__(__self__, *,
                 objective_value: Optional[pulumi.Input[float]] = None,
                 training_step: Optional[pulumi.Input[str]] = None):
        """
        An observed value of a metric.
        :param pulumi.Input[float] objective_value: The objective value at this training step.
        :param pulumi.Input[str] training_step: The global training step for this metric.
        """
        if objective_value is not None:
            pulumi.set(__self__, "objective_value", objective_value)
        if training_step is not None:
            pulumi.set(__self__, "training_step", training_step)

    @property
    @pulumi.getter(name="objectiveValue")
    def objective_value(self) -> Optional[pulumi.Input[float]]:
        """
        The objective value at this training step.
        """
        return pulumi.get(self, "objective_value")

    @objective_value.setter
    def objective_value(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "objective_value", value)

    @property
    @pulumi.getter(name="trainingStep")
    def training_step(self) -> Optional[pulumi.Input[str]]:
        """
        The global training step for this metric.
        """
        return pulumi.get(self, "training_step")

    @training_step.setter
    def training_step(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "training_step", value)


@pulumi.input_type
class GoogleCloudMlV1_Measurement_MetricArgs:
    def __init__(__self__, *,
                 metric: pulumi.Input[str],
                 value: pulumi.Input[float]):
        """
        A message representing a metric in the measurement.
        :param pulumi.Input[str] metric: Metric name.
        :param pulumi.Input[float] value: The value for this metric.
        """
        pulumi.set(__self__, "metric", metric)
        pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def metric(self) -> pulumi.Input[str]:
        """
        Metric name.
        """
        return pulumi.get(self, "metric")

    @metric.setter
    def metric(self, value: pulumi.Input[str]):
        pulumi.set(self, "metric", value)

    @property
    @pulumi.getter
    def value(self) -> pulumi.Input[float]:
        """
        The value for this metric.
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: pulumi.Input[float]):
        pulumi.set(self, "value", value)


@pulumi.input_type
class GoogleCloudMlV1_StudyConfigParameterSpec_CategoricalValueSpecArgs:
    def __init__(__self__, *,
                 values: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[str]]] values: Must be specified if type is `CATEGORICAL`. The list of possible categories.
        """
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Must be specified if type is `CATEGORICAL`. The list of possible categories.
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "values", value)


@pulumi.input_type
class GoogleCloudMlV1_StudyConfigParameterSpec_DiscreteValueSpecArgs:
    def __init__(__self__, *,
                 values: Optional[pulumi.Input[Sequence[pulumi.Input[float]]]] = None):
        """
        :param pulumi.Input[Sequence[pulumi.Input[float]]] values: Must be specified if type is `DISCRETE`. A list of feasible points. The list should be in strictly increasing order. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
        """
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[float]]]]:
        """
        Must be specified if type is `DISCRETE`. A list of feasible points. The list should be in strictly increasing order. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[float]]]]):
        pulumi.set(self, "values", value)


@pulumi.input_type
class GoogleCloudMlV1_StudyConfigParameterSpec_DoubleValueSpecArgs:
    def __init__(__self__, *,
                 max_value: Optional[pulumi.Input[float]] = None,
                 min_value: Optional[pulumi.Input[float]] = None):
        """
        :param pulumi.Input[float] max_value: Must be specified if type is `DOUBLE`. Maximum value of the parameter.
        :param pulumi.Input[float] min_value: Must be specified if type is `DOUBLE`. Minimum value of the parameter.
        """
        if max_value is not None:
            pulumi.set(__self__, "max_value", max_value)
        if min_value is not None:
            pulumi.set(__self__, "min_value", min_value)

    @property
    @pulumi.getter(name="maxValue")
    def max_value(self) -> Optional[pulumi.Input[float]]:
        """
        Must be specified if type is `DOUBLE`. Maximum value of the parameter.
        """
        return pulumi.get(self, "max_value")

    @max_value.setter
    def max_value(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "max_value", value)

    @property
    @pulumi.getter(name="minValue")
    def min_value(self) -> Optional[pulumi.Input[float]]:
        """
        Must be specified if type is `DOUBLE`. Minimum value of the parameter.
        """
        return pulumi.get(self, "min_value")

    @min_value.setter
    def min_value(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "min_value", value)


@pulumi.input_type
class GoogleCloudMlV1_StudyConfigParameterSpec_IntegerValueSpecArgs:
    def __init__(__self__, *,
                 max_value: Optional[pulumi.Input[str]] = None,
                 min_value: Optional[pulumi.Input[str]] = None):
        """
        :param pulumi.Input[str] max_value: Must be specified if type is `INTEGER`. Maximum value of the parameter.
        :param pulumi.Input[str] min_value: Must be specified if type is `INTEGER`. Minimum value of the parameter.
        """
        if max_value is not None:
            pulumi.set(__self__, "max_value", max_value)
        if min_value is not None:
            pulumi.set(__self__, "min_value", min_value)

    @property
    @pulumi.getter(name="maxValue")
    def max_value(self) -> Optional[pulumi.Input[str]]:
        """
        Must be specified if type is `INTEGER`. Maximum value of the parameter.
        """
        return pulumi.get(self, "max_value")

    @max_value.setter
    def max_value(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "max_value", value)

    @property
    @pulumi.getter(name="minValue")
    def min_value(self) -> Optional[pulumi.Input[str]]:
        """
        Must be specified if type is `INTEGER`. Minimum value of the parameter.
        """
        return pulumi.get(self, "min_value")

    @min_value.setter
    def min_value(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "min_value", value)


@pulumi.input_type
class GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentCategoricalValueSpecArgs:
    def __init__(__self__, *,
                 values: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        """
        Represents the spec to match categorical values from parent parameter.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] values: Matches values of the parent parameter with type 'CATEGORICAL'. All values must exist in `categorical_value_spec` of parent parameter.
        """
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Matches values of the parent parameter with type 'CATEGORICAL'. All values must exist in `categorical_value_spec` of parent parameter.
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "values", value)


@pulumi.input_type
class GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentDiscreteValueSpecArgs:
    def __init__(__self__, *,
                 values: Optional[pulumi.Input[Sequence[pulumi.Input[float]]]] = None):
        """
        Represents the spec to match discrete values from parent parameter.
        :param pulumi.Input[Sequence[pulumi.Input[float]]] values: Matches values of the parent parameter with type 'DISCRETE'. All values must exist in `discrete_value_spec` of parent parameter.
        """
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[float]]]]:
        """
        Matches values of the parent parameter with type 'DISCRETE'. All values must exist in `discrete_value_spec` of parent parameter.
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[float]]]]):
        pulumi.set(self, "values", value)


@pulumi.input_type
class GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentIntValueSpecArgs:
    def __init__(__self__, *,
                 values: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None):
        """
        Represents the spec to match integer values from parent parameter.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] values: Matches values of the parent parameter with type 'INTEGER'. All values must lie in `integer_value_spec` of parent parameter.
        """
        if values is not None:
            pulumi.set(__self__, "values", values)

    @property
    @pulumi.getter
    def values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Matches values of the parent parameter with type 'INTEGER'. All values must lie in `integer_value_spec` of parent parameter.
        """
        return pulumi.get(self, "values")

    @values.setter
    def values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "values", value)


@pulumi.input_type
class GoogleCloudMlV1_StudyConfig_MetricSpecArgs:
    def __init__(__self__, *,
                 goal: pulumi.Input['GoogleCloudMlV1_StudyConfig_MetricSpecGoal'],
                 metric: pulumi.Input[str]):
        """
        Represents a metric to optimize.
        :param pulumi.Input['GoogleCloudMlV1_StudyConfig_MetricSpecGoal'] goal: The optimization goal of the metric.
        :param pulumi.Input[str] metric: The name of the metric.
        """
        pulumi.set(__self__, "goal", goal)
        pulumi.set(__self__, "metric", metric)

    @property
    @pulumi.getter
    def goal(self) -> pulumi.Input['GoogleCloudMlV1_StudyConfig_MetricSpecGoal']:
        """
        The optimization goal of the metric.
        """
        return pulumi.get(self, "goal")

    @goal.setter
    def goal(self, value: pulumi.Input['GoogleCloudMlV1_StudyConfig_MetricSpecGoal']):
        pulumi.set(self, "goal", value)

    @property
    @pulumi.getter
    def metric(self) -> pulumi.Input[str]:
        """
        The name of the metric.
        """
        return pulumi.get(self, "metric")

    @metric.setter
    def metric(self, value: pulumi.Input[str]):
        pulumi.set(self, "metric", value)


@pulumi.input_type
class GoogleCloudMlV1_StudyConfig_ParameterSpecArgs:
    def __init__(__self__, *,
                 parameter: pulumi.Input[str],
                 type: pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecType'],
                 categorical_value_spec: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_CategoricalValueSpecArgs']] = None,
                 child_parameter_specs: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecArgs']]]] = None,
                 discrete_value_spec: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_DiscreteValueSpecArgs']] = None,
                 double_value_spec: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_DoubleValueSpecArgs']] = None,
                 integer_value_spec: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_IntegerValueSpecArgs']] = None,
                 parent_categorical_values: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentCategoricalValueSpecArgs']] = None,
                 parent_discrete_values: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentDiscreteValueSpecArgs']] = None,
                 parent_int_values: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentIntValueSpecArgs']] = None,
                 scale_type: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecScaleType']] = None):
        """
        Represents a single parameter to optimize.
        :param pulumi.Input[str] parameter: The parameter name must be unique amongst all ParameterSpecs.
        :param pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecType'] type: The type of the parameter.
        :param pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_CategoricalValueSpecArgs'] categorical_value_spec: The value spec for a 'CATEGORICAL' parameter.
        :param pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecArgs']]] child_parameter_specs: A child node is active if the parameter's value matches the child node's matching_parent_values. If two items in child_parameter_specs have the same name, they must have disjoint matching_parent_values.
        :param pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_DiscreteValueSpecArgs'] discrete_value_spec: The value spec for a 'DISCRETE' parameter.
        :param pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_DoubleValueSpecArgs'] double_value_spec: The value spec for a 'DOUBLE' parameter.
        :param pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_IntegerValueSpecArgs'] integer_value_spec: The value spec for an 'INTEGER' parameter.
        :param pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecScaleType'] scale_type: How the parameter should be scaled. Leave unset for categorical parameters.
        """
        pulumi.set(__self__, "parameter", parameter)
        pulumi.set(__self__, "type", type)
        if categorical_value_spec is not None:
            pulumi.set(__self__, "categorical_value_spec", categorical_value_spec)
        if child_parameter_specs is not None:
            pulumi.set(__self__, "child_parameter_specs", child_parameter_specs)
        if discrete_value_spec is not None:
            pulumi.set(__self__, "discrete_value_spec", discrete_value_spec)
        if double_value_spec is not None:
            pulumi.set(__self__, "double_value_spec", double_value_spec)
        if integer_value_spec is not None:
            pulumi.set(__self__, "integer_value_spec", integer_value_spec)
        if parent_categorical_values is not None:
            pulumi.set(__self__, "parent_categorical_values", parent_categorical_values)
        if parent_discrete_values is not None:
            pulumi.set(__self__, "parent_discrete_values", parent_discrete_values)
        if parent_int_values is not None:
            pulumi.set(__self__, "parent_int_values", parent_int_values)
        if scale_type is not None:
            pulumi.set(__self__, "scale_type", scale_type)

    @property
    @pulumi.getter
    def parameter(self) -> pulumi.Input[str]:
        """
        The parameter name must be unique amongst all ParameterSpecs.
        """
        return pulumi.get(self, "parameter")

    @parameter.setter
    def parameter(self, value: pulumi.Input[str]):
        pulumi.set(self, "parameter", value)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecType']:
        """
        The type of the parameter.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecType']):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter(name="categoricalValueSpec")
    def categorical_value_spec(self) -> Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_CategoricalValueSpecArgs']]:
        """
        The value spec for a 'CATEGORICAL' parameter.
        """
        return pulumi.get(self, "categorical_value_spec")

    @categorical_value_spec.setter
    def categorical_value_spec(self, value: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_CategoricalValueSpecArgs']]):
        pulumi.set(self, "categorical_value_spec", value)

    @property
    @pulumi.getter(name="childParameterSpecs")
    def child_parameter_specs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecArgs']]]]:
        """
        A child node is active if the parameter's value matches the child node's matching_parent_values. If two items in child_parameter_specs have the same name, they must have disjoint matching_parent_values.
        """
        return pulumi.get(self, "child_parameter_specs")

    @child_parameter_specs.setter
    def child_parameter_specs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecArgs']]]]):
        pulumi.set(self, "child_parameter_specs", value)

    @property
    @pulumi.getter(name="discreteValueSpec")
    def discrete_value_spec(self) -> Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_DiscreteValueSpecArgs']]:
        """
        The value spec for a 'DISCRETE' parameter.
        """
        return pulumi.get(self, "discrete_value_spec")

    @discrete_value_spec.setter
    def discrete_value_spec(self, value: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_DiscreteValueSpecArgs']]):
        pulumi.set(self, "discrete_value_spec", value)

    @property
    @pulumi.getter(name="doubleValueSpec")
    def double_value_spec(self) -> Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_DoubleValueSpecArgs']]:
        """
        The value spec for a 'DOUBLE' parameter.
        """
        return pulumi.get(self, "double_value_spec")

    @double_value_spec.setter
    def double_value_spec(self, value: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_DoubleValueSpecArgs']]):
        pulumi.set(self, "double_value_spec", value)

    @property
    @pulumi.getter(name="integerValueSpec")
    def integer_value_spec(self) -> Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_IntegerValueSpecArgs']]:
        """
        The value spec for an 'INTEGER' parameter.
        """
        return pulumi.get(self, "integer_value_spec")

    @integer_value_spec.setter
    def integer_value_spec(self, value: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_IntegerValueSpecArgs']]):
        pulumi.set(self, "integer_value_spec", value)

    @property
    @pulumi.getter(name="parentCategoricalValues")
    def parent_categorical_values(self) -> Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentCategoricalValueSpecArgs']]:
        return pulumi.get(self, "parent_categorical_values")

    @parent_categorical_values.setter
    def parent_categorical_values(self, value: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentCategoricalValueSpecArgs']]):
        pulumi.set(self, "parent_categorical_values", value)

    @property
    @pulumi.getter(name="parentDiscreteValues")
    def parent_discrete_values(self) -> Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentDiscreteValueSpecArgs']]:
        return pulumi.get(self, "parent_discrete_values")

    @parent_discrete_values.setter
    def parent_discrete_values(self, value: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentDiscreteValueSpecArgs']]):
        pulumi.set(self, "parent_discrete_values", value)

    @property
    @pulumi.getter(name="parentIntValues")
    def parent_int_values(self) -> Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentIntValueSpecArgs']]:
        return pulumi.get(self, "parent_int_values")

    @parent_int_values.setter
    def parent_int_values(self, value: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfigParameterSpec_MatchingParentIntValueSpecArgs']]):
        pulumi.set(self, "parent_int_values", value)

    @property
    @pulumi.getter(name="scaleType")
    def scale_type(self) -> Optional[pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecScaleType']]:
        """
        How the parameter should be scaled. Leave unset for categorical parameters.
        """
        return pulumi.get(self, "scale_type")

    @scale_type.setter
    def scale_type(self, value: Optional[pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecScaleType']]):
        pulumi.set(self, "scale_type", value)


@pulumi.input_type
class GoogleCloudMlV1_Trial_ParameterArgs:
    def __init__(__self__, *,
                 float_value: Optional[pulumi.Input[float]] = None,
                 int_value: Optional[pulumi.Input[str]] = None,
                 parameter: Optional[pulumi.Input[str]] = None,
                 string_value: Optional[pulumi.Input[str]] = None):
        """
        A message representing a parameter to be tuned. Contains the name of the parameter and the suggested value to use for this trial.
        :param pulumi.Input[float] float_value: Must be set if ParameterType is DOUBLE or DISCRETE.
        :param pulumi.Input[str] int_value: Must be set if ParameterType is INTEGER
        :param pulumi.Input[str] parameter: The name of the parameter.
        :param pulumi.Input[str] string_value: Must be set if ParameterTypeis CATEGORICAL
        """
        if float_value is not None:
            pulumi.set(__self__, "float_value", float_value)
        if int_value is not None:
            pulumi.set(__self__, "int_value", int_value)
        if parameter is not None:
            pulumi.set(__self__, "parameter", parameter)
        if string_value is not None:
            pulumi.set(__self__, "string_value", string_value)

    @property
    @pulumi.getter(name="floatValue")
    def float_value(self) -> Optional[pulumi.Input[float]]:
        """
        Must be set if ParameterType is DOUBLE or DISCRETE.
        """
        return pulumi.get(self, "float_value")

    @float_value.setter
    def float_value(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "float_value", value)

    @property
    @pulumi.getter(name="intValue")
    def int_value(self) -> Optional[pulumi.Input[str]]:
        """
        Must be set if ParameterType is INTEGER
        """
        return pulumi.get(self, "int_value")

    @int_value.setter
    def int_value(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "int_value", value)

    @property
    @pulumi.getter
    def parameter(self) -> Optional[pulumi.Input[str]]:
        """
        The name of the parameter.
        """
        return pulumi.get(self, "parameter")

    @parameter.setter
    def parameter(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "parameter", value)

    @property
    @pulumi.getter(name="stringValue")
    def string_value(self) -> Optional[pulumi.Input[str]]:
        """
        Must be set if ParameterTypeis CATEGORICAL
        """
        return pulumi.get(self, "string_value")

    @string_value.setter
    def string_value(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "string_value", value)


@pulumi.input_type
class GoogleCloudMlV1__AcceleratorConfigArgs:
    def __init__(__self__, *,
                 count: Optional[pulumi.Input[str]] = None,
                 type: Optional[pulumi.Input['GoogleCloudMlV1__AcceleratorConfigType']] = None):
        """
        Represents a hardware accelerator request config. Note that the AcceleratorConfig can be used in both Jobs and Versions. Learn more about [accelerators for training](/ml-engine/docs/using-gpus) and [accelerators for online prediction](/ml-engine/docs/machine-types-online-prediction#gpus).
        :param pulumi.Input[str] count: The number of accelerators to attach to each machine running the job.
        :param pulumi.Input['GoogleCloudMlV1__AcceleratorConfigType'] type: The type of accelerator to use.
        """
        if count is not None:
            pulumi.set(__self__, "count", count)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def count(self) -> Optional[pulumi.Input[str]]:
        """
        The number of accelerators to attach to each machine running the job.
        """
        return pulumi.get(self, "count")

    @count.setter
    def count(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "count", value)

    @property
    @pulumi.getter
    def type(self) -> Optional[pulumi.Input['GoogleCloudMlV1__AcceleratorConfigType']]:
        """
        The type of accelerator to use.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: Optional[pulumi.Input['GoogleCloudMlV1__AcceleratorConfigType']]):
        pulumi.set(self, "type", value)


@pulumi.input_type
class GoogleCloudMlV1__AutoScalingArgs:
    def __init__(__self__, *,
                 max_nodes: Optional[pulumi.Input[int]] = None,
                 metrics: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__MetricSpecArgs']]]] = None,
                 min_nodes: Optional[pulumi.Input[int]] = None):
        """
        Options for automatically scaling a model.
        :param pulumi.Input[int] max_nodes: The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability.
        :param pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__MetricSpecArgs']]] metrics: MetricSpec contains the specifications to use to calculate the desired nodes count.
        :param pulumi.Input[int] min_nodes: Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least `rate` * `min_nodes` * number of hours since last billing cycle, where `rate` is the cost per node-hour as documented in the [pricing guide](/ml-engine/docs/pricing), even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least `min_nodes`. You will be charged for the time in which additional nodes are used. If `min_nodes` is not specified and AutoScaling is used with a [legacy (MLS1) machine type](/ml-engine/docs/machine-types-online-prediction), `min_nodes` defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If `min_nodes` is not specified and AutoScaling is used with a [Compute Engine (N1) machine type](/ml-engine/docs/machine-types-online-prediction), `min_nodes` defaults to 1. `min_nodes` must be at least 1 for use with a Compute Engine machine type. You can set `min_nodes` when creating the model version, and you can also update `min_nodes` for an existing version: update_body.json: { 'autoScaling': { 'minNodes': 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/*/models/*/versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json 
        """
        if max_nodes is not None:
            pulumi.set(__self__, "max_nodes", max_nodes)
        if metrics is not None:
            pulumi.set(__self__, "metrics", metrics)
        if min_nodes is not None:
            pulumi.set(__self__, "min_nodes", min_nodes)

    @property
    @pulumi.getter(name="maxNodes")
    def max_nodes(self) -> Optional[pulumi.Input[int]]:
        """
        The maximum number of nodes to scale this model under load. The actual value will depend on resource quota and availability.
        """
        return pulumi.get(self, "max_nodes")

    @max_nodes.setter
    def max_nodes(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_nodes", value)

    @property
    @pulumi.getter
    def metrics(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__MetricSpecArgs']]]]:
        """
        MetricSpec contains the specifications to use to calculate the desired nodes count.
        """
        return pulumi.get(self, "metrics")

    @metrics.setter
    def metrics(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__MetricSpecArgs']]]]):
        pulumi.set(self, "metrics", value)

    @property
    @pulumi.getter(name="minNodes")
    def min_nodes(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The minimum number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed. Therefore, the cost of operating this model will be at least `rate` * `min_nodes` * number of hours since last billing cycle, where `rate` is the cost per node-hour as documented in the [pricing guide](/ml-engine/docs/pricing), even if no predictions are performed. There is additional cost for each prediction performed. Unlike manual scaling, if the load gets too heavy for the nodes that are up, the service will automatically add nodes to handle the increased load as well as scale back as traffic drops, always maintaining at least `min_nodes`. You will be charged for the time in which additional nodes are used. If `min_nodes` is not specified and AutoScaling is used with a [legacy (MLS1) machine type](/ml-engine/docs/machine-types-online-prediction), `min_nodes` defaults to 0, in which case, when traffic to a model stops (and after a cool-down period), nodes will be shut down and no charges will be incurred until traffic to the model resumes. If `min_nodes` is not specified and AutoScaling is used with a [Compute Engine (N1) machine type](/ml-engine/docs/machine-types-online-prediction), `min_nodes` defaults to 1. `min_nodes` must be at least 1 for use with a Compute Engine machine type. You can set `min_nodes` when creating the model version, and you can also update `min_nodes` for an existing version: update_body.json: { 'autoScaling': { 'minNodes': 5 } } HTTP request: PATCH https://ml.googleapis.com/v1/{name=projects/*/models/*/versions/*}?update_mask=autoScaling.minNodes -d @./update_body.json 
        """
        return pulumi.get(self, "min_nodes")

    @min_nodes.setter
    def min_nodes(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "min_nodes", value)


@pulumi.input_type
class GoogleCloudMlV1__AutomatedStoppingConfigArgs:
    def __init__(__self__, *,
                 decay_curve_stopping_config: Optional[pulumi.Input['GoogleCloudMlV1_AutomatedStoppingConfig_DecayCurveAutomatedStoppingConfigArgs']] = None,
                 median_automated_stopping_config: Optional[pulumi.Input['GoogleCloudMlV1_AutomatedStoppingConfig_MedianAutomatedStoppingConfigArgs']] = None):
        """
        Configuration for Automated Early Stopping of Trials. If no implementation_config is set, automated early stopping will not be run.
        """
        if decay_curve_stopping_config is not None:
            pulumi.set(__self__, "decay_curve_stopping_config", decay_curve_stopping_config)
        if median_automated_stopping_config is not None:
            pulumi.set(__self__, "median_automated_stopping_config", median_automated_stopping_config)

    @property
    @pulumi.getter(name="decayCurveStoppingConfig")
    def decay_curve_stopping_config(self) -> Optional[pulumi.Input['GoogleCloudMlV1_AutomatedStoppingConfig_DecayCurveAutomatedStoppingConfigArgs']]:
        return pulumi.get(self, "decay_curve_stopping_config")

    @decay_curve_stopping_config.setter
    def decay_curve_stopping_config(self, value: Optional[pulumi.Input['GoogleCloudMlV1_AutomatedStoppingConfig_DecayCurveAutomatedStoppingConfigArgs']]):
        pulumi.set(self, "decay_curve_stopping_config", value)

    @property
    @pulumi.getter(name="medianAutomatedStoppingConfig")
    def median_automated_stopping_config(self) -> Optional[pulumi.Input['GoogleCloudMlV1_AutomatedStoppingConfig_MedianAutomatedStoppingConfigArgs']]:
        return pulumi.get(self, "median_automated_stopping_config")

    @median_automated_stopping_config.setter
    def median_automated_stopping_config(self, value: Optional[pulumi.Input['GoogleCloudMlV1_AutomatedStoppingConfig_MedianAutomatedStoppingConfigArgs']]):
        pulumi.set(self, "median_automated_stopping_config", value)


@pulumi.input_type
class GoogleCloudMlV1__BuiltInAlgorithmOutputArgs:
    def __init__(__self__, *,
                 framework: Optional[pulumi.Input[str]] = None,
                 model_path: Optional[pulumi.Input[str]] = None,
                 python_version: Optional[pulumi.Input[str]] = None,
                 runtime_version: Optional[pulumi.Input[str]] = None):
        """
        Represents output related to a built-in algorithm Job.
        :param pulumi.Input[str] framework: Framework on which the built-in algorithm was trained.
        :param pulumi.Input[str] model_path: The Cloud Storage path to the `model/` directory where the training job saves the trained model. Only set for successful jobs that don't use hyperparameter tuning.
        :param pulumi.Input[str] python_version: Python version on which the built-in algorithm was trained.
        :param pulumi.Input[str] runtime_version: AI Platform runtime version on which the built-in algorithm was trained.
        """
        if framework is not None:
            pulumi.set(__self__, "framework", framework)
        if model_path is not None:
            pulumi.set(__self__, "model_path", model_path)
        if python_version is not None:
            pulumi.set(__self__, "python_version", python_version)
        if runtime_version is not None:
            pulumi.set(__self__, "runtime_version", runtime_version)

    @property
    @pulumi.getter
    def framework(self) -> Optional[pulumi.Input[str]]:
        """
        Framework on which the built-in algorithm was trained.
        """
        return pulumi.get(self, "framework")

    @framework.setter
    def framework(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "framework", value)

    @property
    @pulumi.getter(name="modelPath")
    def model_path(self) -> Optional[pulumi.Input[str]]:
        """
        The Cloud Storage path to the `model/` directory where the training job saves the trained model. Only set for successful jobs that don't use hyperparameter tuning.
        """
        return pulumi.get(self, "model_path")

    @model_path.setter
    def model_path(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "model_path", value)

    @property
    @pulumi.getter(name="pythonVersion")
    def python_version(self) -> Optional[pulumi.Input[str]]:
        """
        Python version on which the built-in algorithm was trained.
        """
        return pulumi.get(self, "python_version")

    @python_version.setter
    def python_version(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "python_version", value)

    @property
    @pulumi.getter(name="runtimeVersion")
    def runtime_version(self) -> Optional[pulumi.Input[str]]:
        """
        AI Platform runtime version on which the built-in algorithm was trained.
        """
        return pulumi.get(self, "runtime_version")

    @runtime_version.setter
    def runtime_version(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "runtime_version", value)


@pulumi.input_type
class GoogleCloudMlV1__ContainerPortArgs:
    def __init__(__self__, *,
                 container_port: Optional[pulumi.Input[int]] = None):
        """
        Represents a network port in a single container. This message is a subset of the [Kubernetes ContainerPort v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#containerport-v1-core).
        :param pulumi.Input[int] container_port: Number of the port to expose on the container. This must be a valid port number: 0 < PORT_NUMBER < 65536.
        """
        if container_port is not None:
            pulumi.set(__self__, "container_port", container_port)

    @property
    @pulumi.getter(name="containerPort")
    def container_port(self) -> Optional[pulumi.Input[int]]:
        """
        Number of the port to expose on the container. This must be a valid port number: 0 < PORT_NUMBER < 65536.
        """
        return pulumi.get(self, "container_port")

    @container_port.setter
    def container_port(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "container_port", value)


@pulumi.input_type
class GoogleCloudMlV1__ContainerSpecArgs:
    def __init__(__self__, *,
                 args: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 command: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 env: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__EnvVarArgs']]]] = None,
                 image: Optional[pulumi.Input[str]] = None,
                 ports: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__ContainerPortArgs']]]] = None):
        """
        Specification of a custom container for serving predictions. This message is a subset of the [Kubernetes Container v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#container-v1-core).
        :param pulumi.Input[Sequence[pulumi.Input[str]]] args: Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `commmand` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the [Docker documentation about how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by AI Platform Prediction](/ai-platform/prediction/docs/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the [Kubernetes Containers v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#container-v1-core).
        :param pulumi.Input[Sequence[pulumi.Input[str]]] command: Immutable. Specifies the command that runs when the container starts. This overrides the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the [Docker documentation about how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by AI Platform Prediction](/ai-platform/prediction/docs/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the [Kubernetes Containers v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#container-v1-core).
        :param pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__EnvVarArgs']]] env: Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ```json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ] ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the [Kubernetes Containers v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#container-v1-core).
        :param pulumi.Input[str] image: URI of the Docker image to be used as the custom container for serving predictions. This URI must identify [an image in Artifact Registry](/artifact-registry/docs/overview) and begin with the hostname `{REGION}-docker.pkg.dev`, where `{REGION}` is replaced by the region that matches AI Platform Prediction [regional endpoint](/ai-platform/prediction/docs/regional-endpoints) that you are using. For example, if you are using the `us-central1-ml.googleapis.com` endpoint, then this URI must begin with `us-central1-docker.pkg.dev`. To use a custom container, the [AI Platform Google-managed service account](/ai-platform/prediction/docs/custom-service-account#default) must have permission to pull (read) the Docker image at this URI. The AI Platform Google-managed service account has the following format: `service-{PROJECT_NUMBER}@cloud-ml.google.com.iam.gserviceaccount.com` {PROJECT_NUMBER} is replaced by your Google Cloud project number. By default, this service account has necessary permissions to pull an Artifact Registry image in the same Google Cloud project where you are using AI Platform Prediction. In this case, no configuration is necessary. If you want to use an image from a different Google Cloud project, learn how to [grant the Artifact Registry Reader (roles/artifactregistry.reader) role for a repository](/artifact-registry/docs/access-control#grant-repo) to your projet's AI Platform Google-managed service account. To learn about the requirements for the Docker image itself, read [Custom container requirements](/ai-platform/prediction/docs/custom-container-requirements).
        :param pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__ContainerPortArgs']]] ports: Immutable. List of ports to expose from the container. AI Platform Prediction sends any prediction requests that it receives to the first port on this list. AI Platform Prediction also sends [liveness and health checks](/ai-platform/prediction/docs/custom-container-requirements#health) to this port. If you do not specify this field, it defaults to following value: ```json [ { "containerPort": 8080 } ] ``` AI Platform Prediction does not use ports other than the first one listed. This field corresponds to the `ports` field of the [Kubernetes Containers v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#container-v1-core).
        """
        if args is not None:
            pulumi.set(__self__, "args", args)
        if command is not None:
            pulumi.set(__self__, "command", command)
        if env is not None:
            pulumi.set(__self__, "env", env)
        if image is not None:
            pulumi.set(__self__, "image", image)
        if ports is not None:
            pulumi.set(__self__, "ports", ports)

    @property
    @pulumi.getter
    def args(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Immutable. Specifies arguments for the command that runs when the container starts. This overrides the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd). Specify this field as an array of executable and arguments, similar to a Docker `CMD`'s "default parameters" form. If you don't specify this field but do specify the command field, then the command from the `command` field runs without any additional arguments. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). If you don't specify this field and don't specify the `commmand` field, then the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#cmd) and `CMD` determine what runs based on their default behavior. See the [Docker documentation about how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). In this field, you can reference [environment variables set by AI Platform Prediction](/ai-platform/prediction/docs/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `args` field of the [Kubernetes Containers v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#container-v1-core).
        """
        return pulumi.get(self, "args")

    @args.setter
    def args(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "args", value)

    @property
    @pulumi.getter
    def command(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Immutable. Specifies the command that runs when the container starts. This overrides the container's [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#entrypoint). Specify this field as an array of executable and arguments, similar to a Docker `ENTRYPOINT`'s "exec" form, not its "shell" form. If you do not specify this field, then the container's `ENTRYPOINT` runs, in conjunction with the args field or the container's [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd), if either exists. If this field is not specified and the container does not have an `ENTRYPOINT`, then refer to the [Docker documentation about how `CMD` and `ENTRYPOINT` interact](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact). If you specify this field, then you can also specify the `args` field to provide additional arguments for this command. However, if you specify this field, then the container's `CMD` is ignored. See the [Kubernetes documentation about how the `command` and `args` fields interact with a container's `ENTRYPOINT` and `CMD`](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#notes). In this field, you can reference [environment variables set by AI Platform Prediction](/ai-platform/prediction/docs/custom-container-requirements#aip-variables) and environment variables set in the env field. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $( VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME) This field corresponds to the `command` field of the [Kubernetes Containers v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#container-v1-core).
        """
        return pulumi.get(self, "command")

    @command.setter
    def command(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "command", value)

    @property
    @pulumi.getter
    def env(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__EnvVarArgs']]]]:
        """
        Immutable. List of environment variables to set in the container. After the container starts running, code running in the container can read these environment variables. Additionally, the command and args fields can reference these variables. Later entries in this list can also reference earlier entries. For example, the following example sets the variable `VAR_2` to have the value `foo bar`: ```json [ { "name": "VAR_1", "value": "foo" }, { "name": "VAR_2", "value": "$(VAR_1) bar" } ] ``` If you switch the order of the variables in the example, then the expansion does not occur. This field corresponds to the `env` field of the [Kubernetes Containers v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#container-v1-core).
        """
        return pulumi.get(self, "env")

    @env.setter
    def env(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__EnvVarArgs']]]]):
        pulumi.set(self, "env", value)

    @property
    @pulumi.getter
    def image(self) -> Optional[pulumi.Input[str]]:
        """
        URI of the Docker image to be used as the custom container for serving predictions. This URI must identify [an image in Artifact Registry](/artifact-registry/docs/overview) and begin with the hostname `{REGION}-docker.pkg.dev`, where `{REGION}` is replaced by the region that matches AI Platform Prediction [regional endpoint](/ai-platform/prediction/docs/regional-endpoints) that you are using. For example, if you are using the `us-central1-ml.googleapis.com` endpoint, then this URI must begin with `us-central1-docker.pkg.dev`. To use a custom container, the [AI Platform Google-managed service account](/ai-platform/prediction/docs/custom-service-account#default) must have permission to pull (read) the Docker image at this URI. The AI Platform Google-managed service account has the following format: `service-{PROJECT_NUMBER}@cloud-ml.google.com.iam.gserviceaccount.com` {PROJECT_NUMBER} is replaced by your Google Cloud project number. By default, this service account has necessary permissions to pull an Artifact Registry image in the same Google Cloud project where you are using AI Platform Prediction. In this case, no configuration is necessary. If you want to use an image from a different Google Cloud project, learn how to [grant the Artifact Registry Reader (roles/artifactregistry.reader) role for a repository](/artifact-registry/docs/access-control#grant-repo) to your projet's AI Platform Google-managed service account. To learn about the requirements for the Docker image itself, read [Custom container requirements](/ai-platform/prediction/docs/custom-container-requirements).
        """
        return pulumi.get(self, "image")

    @image.setter
    def image(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "image", value)

    @property
    @pulumi.getter
    def ports(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__ContainerPortArgs']]]]:
        """
        Immutable. List of ports to expose from the container. AI Platform Prediction sends any prediction requests that it receives to the first port on this list. AI Platform Prediction also sends [liveness and health checks](/ai-platform/prediction/docs/custom-container-requirements#health) to this port. If you do not specify this field, it defaults to following value: ```json [ { "containerPort": 8080 } ] ``` AI Platform Prediction does not use ports other than the first one listed. This field corresponds to the `ports` field of the [Kubernetes Containers v1 core API](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#container-v1-core).
        """
        return pulumi.get(self, "ports")

    @ports.setter
    def ports(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__ContainerPortArgs']]]]):
        pulumi.set(self, "ports", value)


@pulumi.input_type
class GoogleCloudMlV1__DiskConfigArgs:
    def __init__(__self__, *,
                 boot_disk_size_gb: Optional[pulumi.Input[int]] = None,
                 boot_disk_type: Optional[pulumi.Input[str]] = None):
        """
        Represents the config of disk options.
        :param pulumi.Input[int] boot_disk_size_gb: Size in GB of the boot disk (default is 100GB).
        :param pulumi.Input[str] boot_disk_type: Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
        """
        if boot_disk_size_gb is not None:
            pulumi.set(__self__, "boot_disk_size_gb", boot_disk_size_gb)
        if boot_disk_type is not None:
            pulumi.set(__self__, "boot_disk_type", boot_disk_type)

    @property
    @pulumi.getter(name="bootDiskSizeGb")
    def boot_disk_size_gb(self) -> Optional[pulumi.Input[int]]:
        """
        Size in GB of the boot disk (default is 100GB).
        """
        return pulumi.get(self, "boot_disk_size_gb")

    @boot_disk_size_gb.setter
    def boot_disk_size_gb(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "boot_disk_size_gb", value)

    @property
    @pulumi.getter(name="bootDiskType")
    def boot_disk_type(self) -> Optional[pulumi.Input[str]]:
        """
        Type of the boot disk (default is "pd-ssd"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
        """
        return pulumi.get(self, "boot_disk_type")

    @boot_disk_type.setter
    def boot_disk_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "boot_disk_type", value)


@pulumi.input_type
class GoogleCloudMlV1__EncryptionConfigArgs:
    def __init__(__self__, *,
                 kms_key_name: Optional[pulumi.Input[str]] = None):
        """
        Represents a custom encryption key configuration that can be applied to a resource.
        :param pulumi.Input[str] kms_key_name: The Cloud KMS resource identifier of the customer-managed encryption key used to protect a resource, such as a training job. It has the following format: `projects/{PROJECT_ID}/locations/{REGION}/keyRings/{KEY_RING_NAME}/cryptoKeys/{KEY_NAME}`
        """
        if kms_key_name is not None:
            pulumi.set(__self__, "kms_key_name", kms_key_name)

    @property
    @pulumi.getter(name="kmsKeyName")
    def kms_key_name(self) -> Optional[pulumi.Input[str]]:
        """
        The Cloud KMS resource identifier of the customer-managed encryption key used to protect a resource, such as a training job. It has the following format: `projects/{PROJECT_ID}/locations/{REGION}/keyRings/{KEY_RING_NAME}/cryptoKeys/{KEY_NAME}`
        """
        return pulumi.get(self, "kms_key_name")

    @kms_key_name.setter
    def kms_key_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "kms_key_name", value)


@pulumi.input_type
class GoogleCloudMlV1__EnvVarArgs:
    def __init__(__self__, *,
                 name: Optional[pulumi.Input[str]] = None,
                 value: Optional[pulumi.Input[str]] = None):
        """
        Represents an environment variable to be made available in a container. This message is a subset of the [Kubernetes EnvVar v1 core specification](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#envvar-v1-core).
        :param pulumi.Input[str] name: Name of the environment variable. Must be a [valid C identifier](https://github.com/kubernetes/kubernetes/blob/v1.18.8/staging/src/k8s.io/apimachinery/pkg/util/validation/validation.go#L258) and must not begin with the prefix `AIP_`.
        :param pulumi.Input[str] value: Value of the environment variable. Defaults to an empty string. In this field, you can reference [environment variables set by AI Platform Prediction](/ai-platform/prediction/docs/custom-container-requirements#aip-variables) and environment variables set earlier in the same env field as where this message occurs. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $(VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME)
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input[str]]:
        """
        Name of the environment variable. Must be a [valid C identifier](https://github.com/kubernetes/kubernetes/blob/v1.18.8/staging/src/k8s.io/apimachinery/pkg/util/validation/validation.go#L258) and must not begin with the prefix `AIP_`.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter
    def value(self) -> Optional[pulumi.Input[str]]:
        """
        Value of the environment variable. Defaults to an empty string. In this field, you can reference [environment variables set by AI Platform Prediction](/ai-platform/prediction/docs/custom-container-requirements#aip-variables) and environment variables set earlier in the same env field as where this message occurs. You cannot reference environment variables set in the Docker image. In order for environment variables to be expanded, reference them by using the following syntax: $(VARIABLE_NAME) Note that this differs from Bash variable expansion, which does not use parentheses. If a variable cannot be resolved, the reference in the input string is used unchanged. To avoid variable expansion, you can escape this syntax with `$$`; for example: $$(VARIABLE_NAME)
        """
        return pulumi.get(self, "value")

    @value.setter
    def value(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "value", value)


@pulumi.input_type
class GoogleCloudMlV1__ExplanationConfigArgs:
    def __init__(__self__, *,
                 integrated_gradients_attribution: Optional[pulumi.Input['GoogleCloudMlV1__IntegratedGradientsAttributionArgs']] = None,
                 sampled_shapley_attribution: Optional[pulumi.Input['GoogleCloudMlV1__SampledShapleyAttributionArgs']] = None,
                 xrai_attribution: Optional[pulumi.Input['GoogleCloudMlV1__XraiAttributionArgs']] = None):
        """
        Message holding configuration options for explaining model predictions. There are three feature attribution methods supported for TensorFlow models: integrated gradients, sampled Shapley, and XRAI. [Learn more about feature attributions.](/ai-platform/prediction/docs/ai-explanations/overview)
        :param pulumi.Input['GoogleCloudMlV1__IntegratedGradientsAttributionArgs'] integrated_gradients_attribution: Attributes credit by computing the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
        :param pulumi.Input['GoogleCloudMlV1__SampledShapleyAttributionArgs'] sampled_shapley_attribution: An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.
        :param pulumi.Input['GoogleCloudMlV1__XraiAttributionArgs'] xrai_attribution: Attributes credit by computing the XRAI taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Currently only implemented for models with natural image inputs.
        """
        if integrated_gradients_attribution is not None:
            pulumi.set(__self__, "integrated_gradients_attribution", integrated_gradients_attribution)
        if sampled_shapley_attribution is not None:
            pulumi.set(__self__, "sampled_shapley_attribution", sampled_shapley_attribution)
        if xrai_attribution is not None:
            pulumi.set(__self__, "xrai_attribution", xrai_attribution)

    @property
    @pulumi.getter(name="integratedGradientsAttribution")
    def integrated_gradients_attribution(self) -> Optional[pulumi.Input['GoogleCloudMlV1__IntegratedGradientsAttributionArgs']]:
        """
        Attributes credit by computing the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
        """
        return pulumi.get(self, "integrated_gradients_attribution")

    @integrated_gradients_attribution.setter
    def integrated_gradients_attribution(self, value: Optional[pulumi.Input['GoogleCloudMlV1__IntegratedGradientsAttributionArgs']]):
        pulumi.set(self, "integrated_gradients_attribution", value)

    @property
    @pulumi.getter(name="sampledShapleyAttribution")
    def sampled_shapley_attribution(self) -> Optional[pulumi.Input['GoogleCloudMlV1__SampledShapleyAttributionArgs']]:
        """
        An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.
        """
        return pulumi.get(self, "sampled_shapley_attribution")

    @sampled_shapley_attribution.setter
    def sampled_shapley_attribution(self, value: Optional[pulumi.Input['GoogleCloudMlV1__SampledShapleyAttributionArgs']]):
        pulumi.set(self, "sampled_shapley_attribution", value)

    @property
    @pulumi.getter(name="xraiAttribution")
    def xrai_attribution(self) -> Optional[pulumi.Input['GoogleCloudMlV1__XraiAttributionArgs']]:
        """
        Attributes credit by computing the XRAI taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Currently only implemented for models with natural image inputs.
        """
        return pulumi.get(self, "xrai_attribution")

    @xrai_attribution.setter
    def xrai_attribution(self, value: Optional[pulumi.Input['GoogleCloudMlV1__XraiAttributionArgs']]):
        pulumi.set(self, "xrai_attribution", value)


@pulumi.input_type
class GoogleCloudMlV1__HyperparameterOutputArgs:
    def __init__(__self__, *,
                 all_metrics: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_HyperparameterOutput_HyperparameterMetricArgs']]]] = None,
                 built_in_algorithm_output: Optional[pulumi.Input['GoogleCloudMlV1__BuiltInAlgorithmOutputArgs']] = None,
                 final_metric: Optional[pulumi.Input['GoogleCloudMlV1_HyperparameterOutput_HyperparameterMetricArgs']] = None,
                 hyperparameters: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None,
                 is_trial_stopped_early: Optional[pulumi.Input[bool]] = None,
                 trial_id: Optional[pulumi.Input[str]] = None,
                 web_access_uris: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]] = None):
        """
        Represents the result of a single hyperparameter tuning trial from a training job. The TrainingOutput object that is returned on successful completion of a training job with hyperparameter tuning includes a list of HyperparameterOutput objects, one for each successful trial.
        :param pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_HyperparameterOutput_HyperparameterMetricArgs']]] all_metrics: All recorded object metrics for this trial. This field is not currently populated.
        :param pulumi.Input['GoogleCloudMlV1__BuiltInAlgorithmOutputArgs'] built_in_algorithm_output: Details related to built-in algorithms jobs. Only set for trials of built-in algorithms jobs that have succeeded.
        :param pulumi.Input['GoogleCloudMlV1_HyperparameterOutput_HyperparameterMetricArgs'] final_metric: The final objective metric seen for this trial.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] hyperparameters: The hyperparameters given to this trial.
        :param pulumi.Input[bool] is_trial_stopped_early: True if the trial is stopped early.
        :param pulumi.Input[str] trial_id: The trial id for these results.
        :param pulumi.Input[Mapping[str, pulumi.Input[str]]] web_access_uris: URIs for accessing [interactive shells](https://cloud.google.com/ai-platform/training/docs/monitor-debug-interactive-shell) (one URI for each training node). Only available if this trial is part of a hyperparameter tuning job and the job's training_input.enable_web_access is `true`. The keys are names of each node in the training job; for example, `master-replica-0` for the master node, `worker-replica-0` for the first worker, and `ps-replica-0` for the first parameter server. The values are the URIs for each node's interactive shell.
        """
        if all_metrics is not None:
            pulumi.set(__self__, "all_metrics", all_metrics)
        if built_in_algorithm_output is not None:
            pulumi.set(__self__, "built_in_algorithm_output", built_in_algorithm_output)
        if final_metric is not None:
            pulumi.set(__self__, "final_metric", final_metric)
        if hyperparameters is not None:
            pulumi.set(__self__, "hyperparameters", hyperparameters)
        if is_trial_stopped_early is not None:
            pulumi.set(__self__, "is_trial_stopped_early", is_trial_stopped_early)
        if trial_id is not None:
            pulumi.set(__self__, "trial_id", trial_id)
        if web_access_uris is not None:
            pulumi.set(__self__, "web_access_uris", web_access_uris)

    @property
    @pulumi.getter(name="allMetrics")
    def all_metrics(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_HyperparameterOutput_HyperparameterMetricArgs']]]]:
        """
        All recorded object metrics for this trial. This field is not currently populated.
        """
        return pulumi.get(self, "all_metrics")

    @all_metrics.setter
    def all_metrics(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_HyperparameterOutput_HyperparameterMetricArgs']]]]):
        pulumi.set(self, "all_metrics", value)

    @property
    @pulumi.getter(name="builtInAlgorithmOutput")
    def built_in_algorithm_output(self) -> Optional[pulumi.Input['GoogleCloudMlV1__BuiltInAlgorithmOutputArgs']]:
        """
        Details related to built-in algorithms jobs. Only set for trials of built-in algorithms jobs that have succeeded.
        """
        return pulumi.get(self, "built_in_algorithm_output")

    @built_in_algorithm_output.setter
    def built_in_algorithm_output(self, value: Optional[pulumi.Input['GoogleCloudMlV1__BuiltInAlgorithmOutputArgs']]):
        pulumi.set(self, "built_in_algorithm_output", value)

    @property
    @pulumi.getter(name="finalMetric")
    def final_metric(self) -> Optional[pulumi.Input['GoogleCloudMlV1_HyperparameterOutput_HyperparameterMetricArgs']]:
        """
        The final objective metric seen for this trial.
        """
        return pulumi.get(self, "final_metric")

    @final_metric.setter
    def final_metric(self, value: Optional[pulumi.Input['GoogleCloudMlV1_HyperparameterOutput_HyperparameterMetricArgs']]):
        pulumi.set(self, "final_metric", value)

    @property
    @pulumi.getter
    def hyperparameters(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        The hyperparameters given to this trial.
        """
        return pulumi.get(self, "hyperparameters")

    @hyperparameters.setter
    def hyperparameters(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "hyperparameters", value)

    @property
    @pulumi.getter(name="isTrialStoppedEarly")
    def is_trial_stopped_early(self) -> Optional[pulumi.Input[bool]]:
        """
        True if the trial is stopped early.
        """
        return pulumi.get(self, "is_trial_stopped_early")

    @is_trial_stopped_early.setter
    def is_trial_stopped_early(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "is_trial_stopped_early", value)

    @property
    @pulumi.getter(name="trialId")
    def trial_id(self) -> Optional[pulumi.Input[str]]:
        """
        The trial id for these results.
        """
        return pulumi.get(self, "trial_id")

    @trial_id.setter
    def trial_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "trial_id", value)

    @property
    @pulumi.getter(name="webAccessUris")
    def web_access_uris(self) -> Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]:
        """
        URIs for accessing [interactive shells](https://cloud.google.com/ai-platform/training/docs/monitor-debug-interactive-shell) (one URI for each training node). Only available if this trial is part of a hyperparameter tuning job and the job's training_input.enable_web_access is `true`. The keys are names of each node in the training job; for example, `master-replica-0` for the master node, `worker-replica-0` for the first worker, and `ps-replica-0` for the first parameter server. The values are the URIs for each node's interactive shell.
        """
        return pulumi.get(self, "web_access_uris")

    @web_access_uris.setter
    def web_access_uris(self, value: Optional[pulumi.Input[Mapping[str, pulumi.Input[str]]]]):
        pulumi.set(self, "web_access_uris", value)


@pulumi.input_type
class GoogleCloudMlV1__HyperparameterSpecArgs:
    def __init__(__self__, *,
                 goal: pulumi.Input['GoogleCloudMlV1__HyperparameterSpecGoal'],
                 params: pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__ParameterSpecArgs']]],
                 algorithm: Optional[pulumi.Input['GoogleCloudMlV1__HyperparameterSpecAlgorithm']] = None,
                 enable_trial_early_stopping: Optional[pulumi.Input[bool]] = None,
                 hyperparameter_metric_tag: Optional[pulumi.Input[str]] = None,
                 max_failed_trials: Optional[pulumi.Input[int]] = None,
                 max_parallel_trials: Optional[pulumi.Input[int]] = None,
                 max_trials: Optional[pulumi.Input[int]] = None,
                 resume_previous_job_id: Optional[pulumi.Input[str]] = None):
        """
        Represents a set of hyperparameters to optimize.
        :param pulumi.Input['GoogleCloudMlV1__HyperparameterSpecGoal'] goal: The type of goal to use for tuning. Available types are `MAXIMIZE` and `MINIMIZE`. Defaults to `MAXIMIZE`.
        :param pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__ParameterSpecArgs']]] params: The set of parameters to tune.
        :param pulumi.Input['GoogleCloudMlV1__HyperparameterSpecAlgorithm'] algorithm: Optional. The search algorithm specified for the hyperparameter tuning job. Uses the default AI Platform hyperparameter tuning algorithm if unspecified.
        :param pulumi.Input[bool] enable_trial_early_stopping: Optional. Indicates if the hyperparameter tuning job enables auto trial early stopping.
        :param pulumi.Input[str] hyperparameter_metric_tag: Optional. The TensorFlow summary tag name to use for optimizing trials. For current versions of TensorFlow, this tag name should exactly match what is shown in TensorBoard, including all scopes. For versions of TensorFlow prior to 0.12, this should be only the tag passed to tf.Summary. By default, "training/hptuning/metric" will be used.
        :param pulumi.Input[int] max_failed_trials: Optional. The number of failed trials that need to be seen before failing the hyperparameter tuning job. You can specify this field to override the default failing criteria for AI Platform hyperparameter tuning jobs. Defaults to zero, which means the service decides when a hyperparameter job should fail.
        :param pulumi.Input[int] max_parallel_trials: Optional. The number of training trials to run concurrently. You can reduce the time it takes to perform hyperparameter tuning by adding trials in parallel. However, each trail only benefits from the information gained in completed trials. That means that a trial does not get access to the results of trials running at the same time, which could reduce the quality of the overall optimization. Each trial will use the same scale tier and machine types. Defaults to one.
        :param pulumi.Input[int] max_trials: Optional. How many training trials should be attempted to optimize the specified hyperparameters. Defaults to one.
        :param pulumi.Input[str] resume_previous_job_id: Optional. The prior hyperparameter tuning job id that users hope to continue with. The job id will be used to find the corresponding vizier study guid and resume the study.
        """
        pulumi.set(__self__, "goal", goal)
        pulumi.set(__self__, "params", params)
        if algorithm is not None:
            pulumi.set(__self__, "algorithm", algorithm)
        if enable_trial_early_stopping is not None:
            pulumi.set(__self__, "enable_trial_early_stopping", enable_trial_early_stopping)
        if hyperparameter_metric_tag is not None:
            pulumi.set(__self__, "hyperparameter_metric_tag", hyperparameter_metric_tag)
        if max_failed_trials is not None:
            pulumi.set(__self__, "max_failed_trials", max_failed_trials)
        if max_parallel_trials is not None:
            pulumi.set(__self__, "max_parallel_trials", max_parallel_trials)
        if max_trials is not None:
            pulumi.set(__self__, "max_trials", max_trials)
        if resume_previous_job_id is not None:
            pulumi.set(__self__, "resume_previous_job_id", resume_previous_job_id)

    @property
    @pulumi.getter
    def goal(self) -> pulumi.Input['GoogleCloudMlV1__HyperparameterSpecGoal']:
        """
        The type of goal to use for tuning. Available types are `MAXIMIZE` and `MINIMIZE`. Defaults to `MAXIMIZE`.
        """
        return pulumi.get(self, "goal")

    @goal.setter
    def goal(self, value: pulumi.Input['GoogleCloudMlV1__HyperparameterSpecGoal']):
        pulumi.set(self, "goal", value)

    @property
    @pulumi.getter
    def params(self) -> pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__ParameterSpecArgs']]]:
        """
        The set of parameters to tune.
        """
        return pulumi.get(self, "params")

    @params.setter
    def params(self, value: pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__ParameterSpecArgs']]]):
        pulumi.set(self, "params", value)

    @property
    @pulumi.getter
    def algorithm(self) -> Optional[pulumi.Input['GoogleCloudMlV1__HyperparameterSpecAlgorithm']]:
        """
        Optional. The search algorithm specified for the hyperparameter tuning job. Uses the default AI Platform hyperparameter tuning algorithm if unspecified.
        """
        return pulumi.get(self, "algorithm")

    @algorithm.setter
    def algorithm(self, value: Optional[pulumi.Input['GoogleCloudMlV1__HyperparameterSpecAlgorithm']]):
        pulumi.set(self, "algorithm", value)

    @property
    @pulumi.getter(name="enableTrialEarlyStopping")
    def enable_trial_early_stopping(self) -> Optional[pulumi.Input[bool]]:
        """
        Optional. Indicates if the hyperparameter tuning job enables auto trial early stopping.
        """
        return pulumi.get(self, "enable_trial_early_stopping")

    @enable_trial_early_stopping.setter
    def enable_trial_early_stopping(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_trial_early_stopping", value)

    @property
    @pulumi.getter(name="hyperparameterMetricTag")
    def hyperparameter_metric_tag(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The TensorFlow summary tag name to use for optimizing trials. For current versions of TensorFlow, this tag name should exactly match what is shown in TensorBoard, including all scopes. For versions of TensorFlow prior to 0.12, this should be only the tag passed to tf.Summary. By default, "training/hptuning/metric" will be used.
        """
        return pulumi.get(self, "hyperparameter_metric_tag")

    @hyperparameter_metric_tag.setter
    def hyperparameter_metric_tag(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "hyperparameter_metric_tag", value)

    @property
    @pulumi.getter(name="maxFailedTrials")
    def max_failed_trials(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The number of failed trials that need to be seen before failing the hyperparameter tuning job. You can specify this field to override the default failing criteria for AI Platform hyperparameter tuning jobs. Defaults to zero, which means the service decides when a hyperparameter job should fail.
        """
        return pulumi.get(self, "max_failed_trials")

    @max_failed_trials.setter
    def max_failed_trials(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_failed_trials", value)

    @property
    @pulumi.getter(name="maxParallelTrials")
    def max_parallel_trials(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. The number of training trials to run concurrently. You can reduce the time it takes to perform hyperparameter tuning by adding trials in parallel. However, each trail only benefits from the information gained in completed trials. That means that a trial does not get access to the results of trials running at the same time, which could reduce the quality of the overall optimization. Each trial will use the same scale tier and machine types. Defaults to one.
        """
        return pulumi.get(self, "max_parallel_trials")

    @max_parallel_trials.setter
    def max_parallel_trials(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_parallel_trials", value)

    @property
    @pulumi.getter(name="maxTrials")
    def max_trials(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. How many training trials should be attempted to optimize the specified hyperparameters. Defaults to one.
        """
        return pulumi.get(self, "max_trials")

    @max_trials.setter
    def max_trials(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "max_trials", value)

    @property
    @pulumi.getter(name="resumePreviousJobId")
    def resume_previous_job_id(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The prior hyperparameter tuning job id that users hope to continue with. The job id will be used to find the corresponding vizier study guid and resume the study.
        """
        return pulumi.get(self, "resume_previous_job_id")

    @resume_previous_job_id.setter
    def resume_previous_job_id(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "resume_previous_job_id", value)


@pulumi.input_type
class GoogleCloudMlV1__IntegratedGradientsAttributionArgs:
    def __init__(__self__, *,
                 num_integral_steps: Optional[pulumi.Input[int]] = None):
        """
        Attributes credit by computing the Aumann-Shapley value taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1703.01365
        :param pulumi.Input[int] num_integral_steps: Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range.
        """
        if num_integral_steps is not None:
            pulumi.set(__self__, "num_integral_steps", num_integral_steps)

    @property
    @pulumi.getter(name="numIntegralSteps")
    def num_integral_steps(self) -> Optional[pulumi.Input[int]]:
        """
        Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range.
        """
        return pulumi.get(self, "num_integral_steps")

    @num_integral_steps.setter
    def num_integral_steps(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "num_integral_steps", value)


@pulumi.input_type
class GoogleCloudMlV1__ManualScalingArgs:
    def __init__(__self__, *,
                 nodes: Optional[pulumi.Input[int]] = None):
        """
        Options for manually scaling a model.
        :param pulumi.Input[int] nodes: The number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed, so the cost of operating this model will be proportional to `nodes` * number of hours since last billing cycle plus the cost for each prediction performed.
        """
        if nodes is not None:
            pulumi.set(__self__, "nodes", nodes)

    @property
    @pulumi.getter
    def nodes(self) -> Optional[pulumi.Input[int]]:
        """
        The number of nodes to allocate for this model. These nodes are always up, starting from the time the model is deployed, so the cost of operating this model will be proportional to `nodes` * number of hours since last billing cycle plus the cost for each prediction performed.
        """
        return pulumi.get(self, "nodes")

    @nodes.setter
    def nodes(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "nodes", value)


@pulumi.input_type
class GoogleCloudMlV1__MeasurementArgs:
    def __init__(__self__, *,
                 metrics: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_Measurement_MetricArgs']]]] = None,
                 step_count: Optional[pulumi.Input[str]] = None):
        """
        A message representing a measurement.
        :param pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_Measurement_MetricArgs']]] metrics: Provides a list of metrics that act as inputs into the objective function.
        :param pulumi.Input[str] step_count: The number of steps a machine learning model has been trained for. Must be non-negative.
        """
        if metrics is not None:
            pulumi.set(__self__, "metrics", metrics)
        if step_count is not None:
            pulumi.set(__self__, "step_count", step_count)

    @property
    @pulumi.getter
    def metrics(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_Measurement_MetricArgs']]]]:
        """
        Provides a list of metrics that act as inputs into the objective function.
        """
        return pulumi.get(self, "metrics")

    @metrics.setter
    def metrics(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_Measurement_MetricArgs']]]]):
        pulumi.set(self, "metrics", value)

    @property
    @pulumi.getter(name="stepCount")
    def step_count(self) -> Optional[pulumi.Input[str]]:
        """
        The number of steps a machine learning model has been trained for. Must be non-negative.
        """
        return pulumi.get(self, "step_count")

    @step_count.setter
    def step_count(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "step_count", value)


@pulumi.input_type
class GoogleCloudMlV1__MetricSpecArgs:
    def __init__(__self__, *,
                 name: Optional[pulumi.Input['GoogleCloudMlV1__MetricSpecName']] = None,
                 target: Optional[pulumi.Input[int]] = None):
        """
        MetricSpec contains the specifications to use to calculate the desired nodes count when autoscaling is enabled.
        :param pulumi.Input['GoogleCloudMlV1__MetricSpecName'] name: metric name.
        :param pulumi.Input[int] target: Target specifies the target value for the given metric; once real metric deviates from the threshold by a certain percentage, the node count changes.
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if target is not None:
            pulumi.set(__self__, "target", target)

    @property
    @pulumi.getter
    def name(self) -> Optional[pulumi.Input['GoogleCloudMlV1__MetricSpecName']]:
        """
        metric name.
        """
        return pulumi.get(self, "name")

    @name.setter
    def name(self, value: Optional[pulumi.Input['GoogleCloudMlV1__MetricSpecName']]):
        pulumi.set(self, "name", value)

    @property
    @pulumi.getter
    def target(self) -> Optional[pulumi.Input[int]]:
        """
        Target specifies the target value for the given metric; once real metric deviates from the threshold by a certain percentage, the node count changes.
        """
        return pulumi.get(self, "target")

    @target.setter
    def target(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "target", value)


@pulumi.input_type
class GoogleCloudMlV1__ParameterSpecArgs:
    def __init__(__self__, *,
                 parameter_name: pulumi.Input[str],
                 type: pulumi.Input['GoogleCloudMlV1__ParameterSpecType'],
                 categorical_values: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 discrete_values: Optional[pulumi.Input[Sequence[pulumi.Input[float]]]] = None,
                 max_value: Optional[pulumi.Input[float]] = None,
                 min_value: Optional[pulumi.Input[float]] = None,
                 scale_type: Optional[pulumi.Input['GoogleCloudMlV1__ParameterSpecScaleType']] = None):
        """
        Represents a single hyperparameter to optimize.
        :param pulumi.Input[str] parameter_name: The parameter name must be unique amongst all ParameterConfigs in a HyperparameterSpec message. E.g., "learning_rate".
        :param pulumi.Input['GoogleCloudMlV1__ParameterSpecType'] type: The type of the parameter.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] categorical_values: Required if type is `CATEGORICAL`. The list of possible categories.
        :param pulumi.Input[Sequence[pulumi.Input[float]]] discrete_values: Required if type is `DISCRETE`. A list of feasible points. The list should be in strictly increasing order. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
        :param pulumi.Input[float] max_value: Required if type is `DOUBLE` or `INTEGER`. This field should be unset if type is `CATEGORICAL`. This value should be integers if type is `INTEGER`.
        :param pulumi.Input[float] min_value: Required if type is `DOUBLE` or `INTEGER`. This field should be unset if type is `CATEGORICAL`. This value should be integers if type is INTEGER.
        :param pulumi.Input['GoogleCloudMlV1__ParameterSpecScaleType'] scale_type: Optional. How the parameter should be scaled to the hypercube. Leave unset for categorical parameters. Some kind of scaling is strongly recommended for real or integral parameters (e.g., `UNIT_LINEAR_SCALE`).
        """
        pulumi.set(__self__, "parameter_name", parameter_name)
        pulumi.set(__self__, "type", type)
        if categorical_values is not None:
            pulumi.set(__self__, "categorical_values", categorical_values)
        if discrete_values is not None:
            pulumi.set(__self__, "discrete_values", discrete_values)
        if max_value is not None:
            pulumi.set(__self__, "max_value", max_value)
        if min_value is not None:
            pulumi.set(__self__, "min_value", min_value)
        if scale_type is not None:
            pulumi.set(__self__, "scale_type", scale_type)

    @property
    @pulumi.getter(name="parameterName")
    def parameter_name(self) -> pulumi.Input[str]:
        """
        The parameter name must be unique amongst all ParameterConfigs in a HyperparameterSpec message. E.g., "learning_rate".
        """
        return pulumi.get(self, "parameter_name")

    @parameter_name.setter
    def parameter_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "parameter_name", value)

    @property
    @pulumi.getter
    def type(self) -> pulumi.Input['GoogleCloudMlV1__ParameterSpecType']:
        """
        The type of the parameter.
        """
        return pulumi.get(self, "type")

    @type.setter
    def type(self, value: pulumi.Input['GoogleCloudMlV1__ParameterSpecType']):
        pulumi.set(self, "type", value)

    @property
    @pulumi.getter(name="categoricalValues")
    def categorical_values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Required if type is `CATEGORICAL`. The list of possible categories.
        """
        return pulumi.get(self, "categorical_values")

    @categorical_values.setter
    def categorical_values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "categorical_values", value)

    @property
    @pulumi.getter(name="discreteValues")
    def discrete_values(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[float]]]]:
        """
        Required if type is `DISCRETE`. A list of feasible points. The list should be in strictly increasing order. For instance, this parameter might have possible settings of 1.5, 2.5, and 4.0. This list should not contain more than 1,000 values.
        """
        return pulumi.get(self, "discrete_values")

    @discrete_values.setter
    def discrete_values(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[float]]]]):
        pulumi.set(self, "discrete_values", value)

    @property
    @pulumi.getter(name="maxValue")
    def max_value(self) -> Optional[pulumi.Input[float]]:
        """
        Required if type is `DOUBLE` or `INTEGER`. This field should be unset if type is `CATEGORICAL`. This value should be integers if type is `INTEGER`.
        """
        return pulumi.get(self, "max_value")

    @max_value.setter
    def max_value(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "max_value", value)

    @property
    @pulumi.getter(name="minValue")
    def min_value(self) -> Optional[pulumi.Input[float]]:
        """
        Required if type is `DOUBLE` or `INTEGER`. This field should be unset if type is `CATEGORICAL`. This value should be integers if type is INTEGER.
        """
        return pulumi.get(self, "min_value")

    @min_value.setter
    def min_value(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "min_value", value)

    @property
    @pulumi.getter(name="scaleType")
    def scale_type(self) -> Optional[pulumi.Input['GoogleCloudMlV1__ParameterSpecScaleType']]:
        """
        Optional. How the parameter should be scaled to the hypercube. Leave unset for categorical parameters. Some kind of scaling is strongly recommended for real or integral parameters (e.g., `UNIT_LINEAR_SCALE`).
        """
        return pulumi.get(self, "scale_type")

    @scale_type.setter
    def scale_type(self, value: Optional[pulumi.Input['GoogleCloudMlV1__ParameterSpecScaleType']]):
        pulumi.set(self, "scale_type", value)


@pulumi.input_type
class GoogleCloudMlV1__PredictionInputArgs:
    def __init__(__self__, *,
                 data_format: pulumi.Input['GoogleCloudMlV1__PredictionInputDataFormat'],
                 input_paths: pulumi.Input[Sequence[pulumi.Input[str]]],
                 output_path: pulumi.Input[str],
                 region: pulumi.Input[str],
                 batch_size: Optional[pulumi.Input[str]] = None,
                 max_worker_count: Optional[pulumi.Input[str]] = None,
                 model_name: Optional[pulumi.Input[str]] = None,
                 output_data_format: Optional[pulumi.Input['GoogleCloudMlV1__PredictionInputOutputDataFormat']] = None,
                 runtime_version: Optional[pulumi.Input[str]] = None,
                 signature_name: Optional[pulumi.Input[str]] = None,
                 uri: Optional[pulumi.Input[str]] = None,
                 version_name: Optional[pulumi.Input[str]] = None):
        """
        Represents input parameters for a prediction job.
        :param pulumi.Input['GoogleCloudMlV1__PredictionInputDataFormat'] data_format: The format of the input data files.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] input_paths: The Cloud Storage location of the input data files. May contain wildcards.
        :param pulumi.Input[str] output_path: The output Google Cloud Storage location.
        :param pulumi.Input[str] region: The Google Compute Engine region to run the prediction job in. See the available regions for AI Platform services.
        :param pulumi.Input[str] batch_size: Optional. Number of records per batch, defaults to 64. The service will buffer batch_size number of records in memory before invoking one Tensorflow prediction call internally. So take the record size and memory available into consideration when setting this parameter.
        :param pulumi.Input[str] max_worker_count: Optional. The maximum number of workers to be used for parallel processing. Defaults to 10 if not specified.
        :param pulumi.Input[str] model_name: Use this field if you want to use the default version for the specified model. The string must use the following format: `"projects/YOUR_PROJECT/models/YOUR_MODEL"`
        :param pulumi.Input['GoogleCloudMlV1__PredictionInputOutputDataFormat'] output_data_format: Optional. Format of the output data files, defaults to JSON.
        :param pulumi.Input[str] runtime_version: Optional. The AI Platform runtime version to use for this batch prediction. If not set, AI Platform will pick the runtime version used during the CreateVersion request for this model version, or choose the latest stable version when model version information is not available such as when the model is specified by uri.
        :param pulumi.Input[str] signature_name: Optional. The name of the signature defined in the SavedModel to use for this job. Please refer to [SavedModel](https://tensorflow.github.io/serving/serving_basic.html) for information about how to use signatures. Defaults to [DEFAULT_SERVING_SIGNATURE_DEF_KEY](https://www.tensorflow.org/api_docs/python/tf/saved_model/signature_constants) , which is "serving_default".
        :param pulumi.Input[str] uri: Use this field if you want to specify a Google Cloud Storage path for the model to use.
        :param pulumi.Input[str] version_name: Use this field if you want to specify a version of the model to use. The string is formatted the same way as `model_version`, with the addition of the version information: `"projects/YOUR_PROJECT/models/YOUR_MODEL/versions/YOUR_VERSION"`
        """
        pulumi.set(__self__, "data_format", data_format)
        pulumi.set(__self__, "input_paths", input_paths)
        pulumi.set(__self__, "output_path", output_path)
        pulumi.set(__self__, "region", region)
        if batch_size is not None:
            pulumi.set(__self__, "batch_size", batch_size)
        if max_worker_count is not None:
            pulumi.set(__self__, "max_worker_count", max_worker_count)
        if model_name is not None:
            pulumi.set(__self__, "model_name", model_name)
        if output_data_format is not None:
            pulumi.set(__self__, "output_data_format", output_data_format)
        if runtime_version is not None:
            pulumi.set(__self__, "runtime_version", runtime_version)
        if signature_name is not None:
            pulumi.set(__self__, "signature_name", signature_name)
        if uri is not None:
            pulumi.set(__self__, "uri", uri)
        if version_name is not None:
            pulumi.set(__self__, "version_name", version_name)

    @property
    @pulumi.getter(name="dataFormat")
    def data_format(self) -> pulumi.Input['GoogleCloudMlV1__PredictionInputDataFormat']:
        """
        The format of the input data files.
        """
        return pulumi.get(self, "data_format")

    @data_format.setter
    def data_format(self, value: pulumi.Input['GoogleCloudMlV1__PredictionInputDataFormat']):
        pulumi.set(self, "data_format", value)

    @property
    @pulumi.getter(name="inputPaths")
    def input_paths(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        The Cloud Storage location of the input data files. May contain wildcards.
        """
        return pulumi.get(self, "input_paths")

    @input_paths.setter
    def input_paths(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "input_paths", value)

    @property
    @pulumi.getter(name="outputPath")
    def output_path(self) -> pulumi.Input[str]:
        """
        The output Google Cloud Storage location.
        """
        return pulumi.get(self, "output_path")

    @output_path.setter
    def output_path(self, value: pulumi.Input[str]):
        pulumi.set(self, "output_path", value)

    @property
    @pulumi.getter
    def region(self) -> pulumi.Input[str]:
        """
        The Google Compute Engine region to run the prediction job in. See the available regions for AI Platform services.
        """
        return pulumi.get(self, "region")

    @region.setter
    def region(self, value: pulumi.Input[str]):
        pulumi.set(self, "region", value)

    @property
    @pulumi.getter(name="batchSize")
    def batch_size(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. Number of records per batch, defaults to 64. The service will buffer batch_size number of records in memory before invoking one Tensorflow prediction call internally. So take the record size and memory available into consideration when setting this parameter.
        """
        return pulumi.get(self, "batch_size")

    @batch_size.setter
    def batch_size(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "batch_size", value)

    @property
    @pulumi.getter(name="maxWorkerCount")
    def max_worker_count(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The maximum number of workers to be used for parallel processing. Defaults to 10 if not specified.
        """
        return pulumi.get(self, "max_worker_count")

    @max_worker_count.setter
    def max_worker_count(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "max_worker_count", value)

    @property
    @pulumi.getter(name="modelName")
    def model_name(self) -> Optional[pulumi.Input[str]]:
        """
        Use this field if you want to use the default version for the specified model. The string must use the following format: `"projects/YOUR_PROJECT/models/YOUR_MODEL"`
        """
        return pulumi.get(self, "model_name")

    @model_name.setter
    def model_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "model_name", value)

    @property
    @pulumi.getter(name="outputDataFormat")
    def output_data_format(self) -> Optional[pulumi.Input['GoogleCloudMlV1__PredictionInputOutputDataFormat']]:
        """
        Optional. Format of the output data files, defaults to JSON.
        """
        return pulumi.get(self, "output_data_format")

    @output_data_format.setter
    def output_data_format(self, value: Optional[pulumi.Input['GoogleCloudMlV1__PredictionInputOutputDataFormat']]):
        pulumi.set(self, "output_data_format", value)

    @property
    @pulumi.getter(name="runtimeVersion")
    def runtime_version(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The AI Platform runtime version to use for this batch prediction. If not set, AI Platform will pick the runtime version used during the CreateVersion request for this model version, or choose the latest stable version when model version information is not available such as when the model is specified by uri.
        """
        return pulumi.get(self, "runtime_version")

    @runtime_version.setter
    def runtime_version(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "runtime_version", value)

    @property
    @pulumi.getter(name="signatureName")
    def signature_name(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The name of the signature defined in the SavedModel to use for this job. Please refer to [SavedModel](https://tensorflow.github.io/serving/serving_basic.html) for information about how to use signatures. Defaults to [DEFAULT_SERVING_SIGNATURE_DEF_KEY](https://www.tensorflow.org/api_docs/python/tf/saved_model/signature_constants) , which is "serving_default".
        """
        return pulumi.get(self, "signature_name")

    @signature_name.setter
    def signature_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "signature_name", value)

    @property
    @pulumi.getter
    def uri(self) -> Optional[pulumi.Input[str]]:
        """
        Use this field if you want to specify a Google Cloud Storage path for the model to use.
        """
        return pulumi.get(self, "uri")

    @uri.setter
    def uri(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "uri", value)

    @property
    @pulumi.getter(name="versionName")
    def version_name(self) -> Optional[pulumi.Input[str]]:
        """
        Use this field if you want to specify a version of the model to use. The string is formatted the same way as `model_version`, with the addition of the version information: `"projects/YOUR_PROJECT/models/YOUR_MODEL/versions/YOUR_VERSION"`
        """
        return pulumi.get(self, "version_name")

    @version_name.setter
    def version_name(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "version_name", value)


@pulumi.input_type
class GoogleCloudMlV1__PredictionOutputArgs:
    def __init__(__self__, *,
                 error_count: Optional[pulumi.Input[str]] = None,
                 node_hours: Optional[pulumi.Input[float]] = None,
                 output_path: Optional[pulumi.Input[str]] = None,
                 prediction_count: Optional[pulumi.Input[str]] = None):
        """
        Represents results of a prediction job.
        :param pulumi.Input[str] error_count: The number of data instances which resulted in errors.
        :param pulumi.Input[float] node_hours: Node hours used by the batch prediction job.
        :param pulumi.Input[str] output_path: The output Google Cloud Storage location provided at the job creation time.
        :param pulumi.Input[str] prediction_count: The number of generated predictions.
        """
        if error_count is not None:
            pulumi.set(__self__, "error_count", error_count)
        if node_hours is not None:
            pulumi.set(__self__, "node_hours", node_hours)
        if output_path is not None:
            pulumi.set(__self__, "output_path", output_path)
        if prediction_count is not None:
            pulumi.set(__self__, "prediction_count", prediction_count)

    @property
    @pulumi.getter(name="errorCount")
    def error_count(self) -> Optional[pulumi.Input[str]]:
        """
        The number of data instances which resulted in errors.
        """
        return pulumi.get(self, "error_count")

    @error_count.setter
    def error_count(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "error_count", value)

    @property
    @pulumi.getter(name="nodeHours")
    def node_hours(self) -> Optional[pulumi.Input[float]]:
        """
        Node hours used by the batch prediction job.
        """
        return pulumi.get(self, "node_hours")

    @node_hours.setter
    def node_hours(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "node_hours", value)

    @property
    @pulumi.getter(name="outputPath")
    def output_path(self) -> Optional[pulumi.Input[str]]:
        """
        The output Google Cloud Storage location provided at the job creation time.
        """
        return pulumi.get(self, "output_path")

    @output_path.setter
    def output_path(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "output_path", value)

    @property
    @pulumi.getter(name="predictionCount")
    def prediction_count(self) -> Optional[pulumi.Input[str]]:
        """
        The number of generated predictions.
        """
        return pulumi.get(self, "prediction_count")

    @prediction_count.setter
    def prediction_count(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "prediction_count", value)


@pulumi.input_type
class GoogleCloudMlV1__ReplicaConfigArgs:
    def __init__(__self__, *,
                 accelerator_config: Optional[pulumi.Input['GoogleCloudMlV1__AcceleratorConfigArgs']] = None,
                 container_args: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 container_command: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 disk_config: Optional[pulumi.Input['GoogleCloudMlV1__DiskConfigArgs']] = None,
                 image_uri: Optional[pulumi.Input[str]] = None,
                 tpu_tf_version: Optional[pulumi.Input[str]] = None):
        """
        Represents the configuration for a replica in a cluster.
        :param pulumi.Input['GoogleCloudMlV1__AcceleratorConfigArgs'] accelerator_config: Represents the type and number of accelerators used by the replica. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu)
        :param pulumi.Input[Sequence[pulumi.Input[str]]] container_args: Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] container_command: The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time.
        :param pulumi.Input['GoogleCloudMlV1__DiskConfigArgs'] disk_config: Represents the configuration of disk options.
        :param pulumi.Input[str] image_uri: The Docker image to run on the replica. This image must be in Container Registry. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
        :param pulumi.Input[str] tpu_tf_version: The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a [runtime version that currently supports training with TPUs](/ml-engine/docs/tensorflow/runtime-version-list#tpu-support). Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different [patch version](https://www.tensorflow.org/guide/version_compat#semantic_versioning_20). In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow `1.x.y`, specify `1.x`.
        """
        if accelerator_config is not None:
            pulumi.set(__self__, "accelerator_config", accelerator_config)
        if container_args is not None:
            pulumi.set(__self__, "container_args", container_args)
        if container_command is not None:
            pulumi.set(__self__, "container_command", container_command)
        if disk_config is not None:
            pulumi.set(__self__, "disk_config", disk_config)
        if image_uri is not None:
            pulumi.set(__self__, "image_uri", image_uri)
        if tpu_tf_version is not None:
            pulumi.set(__self__, "tpu_tf_version", tpu_tf_version)

    @property
    @pulumi.getter(name="acceleratorConfig")
    def accelerator_config(self) -> Optional[pulumi.Input['GoogleCloudMlV1__AcceleratorConfigArgs']]:
        """
        Represents the type and number of accelerators used by the replica. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu)
        """
        return pulumi.get(self, "accelerator_config")

    @accelerator_config.setter
    def accelerator_config(self, value: Optional[pulumi.Input['GoogleCloudMlV1__AcceleratorConfigArgs']]):
        pulumi.set(self, "accelerator_config", value)

    @property
    @pulumi.getter(name="containerArgs")
    def container_args(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Arguments to the entrypoint command. The following rules apply for container_command and container_args: - If you do not supply command or args: The defaults defined in the Docker image are used. - If you supply a command but no args: The default EntryPoint and the default Cmd defined in the Docker image are ignored. Your command is run without any arguments. - If you supply only args: The default Entrypoint defined in the Docker image is run with the args that you supplied. - If you supply a command and args: The default Entrypoint and the default Cmd defined in the Docker image are ignored. Your command is run with your args. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time.
        """
        return pulumi.get(self, "container_args")

    @container_args.setter
    def container_args(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "container_args", value)

    @property
    @pulumi.getter(name="containerCommand")
    def container_command(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        The command with which the replica's custom container is run. If provided, it will override default ENTRYPOINT of the docker image. If not provided, the docker image's ENTRYPOINT is used. It cannot be set if custom container image is not provided. Note that this field and [TrainingInput.args] are mutually exclusive, i.e., both cannot be set at the same time.
        """
        return pulumi.get(self, "container_command")

    @container_command.setter
    def container_command(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "container_command", value)

    @property
    @pulumi.getter(name="diskConfig")
    def disk_config(self) -> Optional[pulumi.Input['GoogleCloudMlV1__DiskConfigArgs']]:
        """
        Represents the configuration of disk options.
        """
        return pulumi.get(self, "disk_config")

    @disk_config.setter
    def disk_config(self, value: Optional[pulumi.Input['GoogleCloudMlV1__DiskConfigArgs']]):
        pulumi.set(self, "disk_config", value)

    @property
    @pulumi.getter(name="imageUri")
    def image_uri(self) -> Optional[pulumi.Input[str]]:
        """
        The Docker image to run on the replica. This image must be in Container Registry. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
        """
        return pulumi.get(self, "image_uri")

    @image_uri.setter
    def image_uri(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "image_uri", value)

    @property
    @pulumi.getter(name="tpuTfVersion")
    def tpu_tf_version(self) -> Optional[pulumi.Input[str]]:
        """
        The AI Platform runtime version that includes a TensorFlow version matching the one used in the custom container. This field is required if the replica is a TPU worker that uses a custom container. Otherwise, do not specify this field. This must be a [runtime version that currently supports training with TPUs](/ml-engine/docs/tensorflow/runtime-version-list#tpu-support). Note that the version of TensorFlow included in a runtime version may differ from the numbering of the runtime version itself, because it may have a different [patch version](https://www.tensorflow.org/guide/version_compat#semantic_versioning_20). In this field, you must specify the runtime version (TensorFlow minor version). For example, if your custom container runs TensorFlow `1.x.y`, specify `1.x`.
        """
        return pulumi.get(self, "tpu_tf_version")

    @tpu_tf_version.setter
    def tpu_tf_version(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "tpu_tf_version", value)


@pulumi.input_type
class GoogleCloudMlV1__RequestLoggingConfigArgs:
    def __init__(__self__, *,
                 bigquery_table_name: pulumi.Input[str],
                 sampling_percentage: Optional[pulumi.Input[float]] = None):
        """
        Configuration for logging request-response pairs to a BigQuery table. Online prediction requests to a model version and the responses to these requests are converted to raw strings and saved to the specified BigQuery table. Logging is constrained by [BigQuery quotas and limits](/bigquery/quotas). If your project exceeds BigQuery quotas or limits, AI Platform Prediction does not log request-response pairs, but it continues to serve predictions. If you are using [continuous evaluation](/ml-engine/docs/continuous-evaluation/), you do not need to specify this configuration manually. Setting up continuous evaluation automatically enables logging of request-response pairs.
        :param pulumi.Input[str] bigquery_table_name: Fully qualified BigQuery table name in the following format: " project_id.dataset_name.table_name" The specified table must already exist, and the "Cloud ML Service Agent" for your project must have permission to write to it. The table must have the following [schema](/bigquery/docs/schemas): Field nameType Mode model STRING REQUIRED model_version STRING REQUIRED time TIMESTAMP REQUIRED raw_data STRING REQUIRED raw_prediction STRING NULLABLE groundtruth STRING NULLABLE 
        :param pulumi.Input[float] sampling_percentage: Percentage of requests to be logged, expressed as a fraction from 0 to 1. For example, if you want to log 10% of requests, enter `0.1`. The sampling window is the lifetime of the model version. Defaults to 0.
        """
        pulumi.set(__self__, "bigquery_table_name", bigquery_table_name)
        if sampling_percentage is not None:
            pulumi.set(__self__, "sampling_percentage", sampling_percentage)

    @property
    @pulumi.getter(name="bigqueryTableName")
    def bigquery_table_name(self) -> pulumi.Input[str]:
        """
        Fully qualified BigQuery table name in the following format: " project_id.dataset_name.table_name" The specified table must already exist, and the "Cloud ML Service Agent" for your project must have permission to write to it. The table must have the following [schema](/bigquery/docs/schemas): Field nameType Mode model STRING REQUIRED model_version STRING REQUIRED time TIMESTAMP REQUIRED raw_data STRING REQUIRED raw_prediction STRING NULLABLE groundtruth STRING NULLABLE 
        """
        return pulumi.get(self, "bigquery_table_name")

    @bigquery_table_name.setter
    def bigquery_table_name(self, value: pulumi.Input[str]):
        pulumi.set(self, "bigquery_table_name", value)

    @property
    @pulumi.getter(name="samplingPercentage")
    def sampling_percentage(self) -> Optional[pulumi.Input[float]]:
        """
        Percentage of requests to be logged, expressed as a fraction from 0 to 1. For example, if you want to log 10% of requests, enter `0.1`. The sampling window is the lifetime of the model version. Defaults to 0.
        """
        return pulumi.get(self, "sampling_percentage")

    @sampling_percentage.setter
    def sampling_percentage(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "sampling_percentage", value)


@pulumi.input_type
class GoogleCloudMlV1__RouteMapArgs:
    def __init__(__self__, *,
                 health: Optional[pulumi.Input[str]] = None,
                 predict: Optional[pulumi.Input[str]] = None):
        """
        Specifies HTTP paths served by a custom container. AI Platform Prediction sends requests to these paths on the container; the custom container must run an HTTP server that responds to these requests with appropriate responses. Read [Custom container requirements](/ai-platform/prediction/docs/custom-container-requirements) for details on how to create your container image to meet these requirements.
        :param pulumi.Input[str] health: HTTP path on the container to send health checkss to. AI Platform Prediction intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](/ai-platform/prediction/docs/custom-container-requirements#checks). For example, if you set this field to `/bar`, then AI Platform Prediction intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/ MODEL/versions/VERSION The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the "projects/PROJECT_ID/models/" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the "projects/PROJECT_ID /models/MODEL/versions/" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create.
        :param pulumi.Input[str] predict: HTTP path on the container to send prediction requests to. AI Platform Prediction forwards requests sent using projects.predict to this path on the container's IP address and port. AI Platform Prediction then returns the container's response in the API response. For example, if you set this field to `/foo`, then when AI Platform Prediction receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/MODEL/versions/VERSION:predict The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the "projects/PROJECT_ID/models/" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the "projects/PROJECT_ID/models/MODEL/versions/" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create.
        """
        if health is not None:
            pulumi.set(__self__, "health", health)
        if predict is not None:
            pulumi.set(__self__, "predict", predict)

    @property
    @pulumi.getter
    def health(self) -> Optional[pulumi.Input[str]]:
        """
        HTTP path on the container to send health checkss to. AI Platform Prediction intermittently sends GET requests to this path on the container's IP address and port to check that the container is healthy. Read more about [health checks](/ai-platform/prediction/docs/custom-container-requirements#checks). For example, if you set this field to `/bar`, then AI Platform Prediction intermittently sends a GET request to the `/bar` path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/ MODEL/versions/VERSION The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the "projects/PROJECT_ID/models/" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the "projects/PROJECT_ID /models/MODEL/versions/" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create.
        """
        return pulumi.get(self, "health")

    @health.setter
    def health(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "health", value)

    @property
    @pulumi.getter
    def predict(self) -> Optional[pulumi.Input[str]]:
        """
        HTTP path on the container to send prediction requests to. AI Platform Prediction forwards requests sent using projects.predict to this path on the container's IP address and port. AI Platform Prediction then returns the container's response in the API response. For example, if you set this field to `/foo`, then when AI Platform Prediction receives a prediction request, it forwards the request body in a POST request to the `/foo` path on the port of your container specified by the first value of Version.container.ports. If you don't specify this field, it defaults to the following value: /v1/models/MODEL/versions/VERSION:predict The placeholders in this value are replaced as follows: * MODEL: The name of the parent Model. This does not include the "projects/PROJECT_ID/models/" prefix that the API returns in output; it is the bare model name, as provided to projects.models.create. * VERSION: The name of the model version. This does not include the "projects/PROJECT_ID/models/MODEL/versions/" prefix that the API returns in output; it is the bare version name, as provided to projects.models.versions.create.
        """
        return pulumi.get(self, "predict")

    @predict.setter
    def predict(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "predict", value)


@pulumi.input_type
class GoogleCloudMlV1__SampledShapleyAttributionArgs:
    def __init__(__self__, *,
                 num_paths: Optional[pulumi.Input[int]] = None):
        """
        An attribution method that approximates Shapley values for features that contribute to the label being predicted. A sampling strategy is used to approximate the value rather than considering all subsets of features.
        :param pulumi.Input[int] num_paths: The number of feature permutations to consider when approximating the Shapley values.
        """
        if num_paths is not None:
            pulumi.set(__self__, "num_paths", num_paths)

    @property
    @pulumi.getter(name="numPaths")
    def num_paths(self) -> Optional[pulumi.Input[int]]:
        """
        The number of feature permutations to consider when approximating the Shapley values.
        """
        return pulumi.get(self, "num_paths")

    @num_paths.setter
    def num_paths(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "num_paths", value)


@pulumi.input_type
class GoogleCloudMlV1__SchedulingArgs:
    def __init__(__self__, *,
                 max_running_time: Optional[pulumi.Input[str]] = None,
                 max_wait_time: Optional[pulumi.Input[str]] = None,
                 priority: Optional[pulumi.Input[int]] = None):
        """
        All parameters related to scheduling of training jobs.
        :param pulumi.Input[str] max_running_time: Optional. The maximum job running time, expressed in seconds. The field can contain up to nine fractional digits, terminated by `s`. If not specified, this field defaults to `604800s` (seven days). If the training job is still running after this duration, AI Platform Training cancels it. The duration is measured from when the job enters the `RUNNING` state; therefore it does not overlap with the duration limited by Scheduling.max_wait_time. For example, if you want to ensure your job runs for no more than 2 hours, set this field to `7200s` (2 hours * 60 minutes / hour * 60 seconds / minute). If you submit your training job using the `gcloud` tool, you can [specify this field in a `config.yaml` file](/ai-platform/training/docs/training-jobs#formatting_your_configuration_parameters). For example: ```yaml trainingInput: scheduling: maxRunningTime: 7200s ```
        :param pulumi.Input[str] max_wait_time: Optional. The maximum job wait time, expressed in seconds. The field can contain up to nine fractional digits, terminated by `s`. If not specified, there is no limit to the wait time. The minimum for this field is `1800s` (30 minutes). If the training job has not entered the `RUNNING` state after this duration, AI Platform Training cancels it. After the job begins running, it can no longer be cancelled due to the maximum wait time. Therefore the duration limited by this field does not overlap with the duration limited by Scheduling.max_running_time. For example, if the job temporarily stops running and retries due to a [VM restart](/ai-platform/training/docs/overview#restarts), this cannot lead to a maximum wait time cancellation. However, independently of this constraint, AI Platform Training might stop a job if there are too many retries due to exhausted resources in a region. The following example describes how you might use this field: To cancel your job if it doesn't start running within 1 hour, set this field to `3600s` (1 hour * 60 minutes / hour * 60 seconds / minute). If the job is still in the `QUEUED` or `PREPARING` state after an hour of waiting, AI Platform Training cancels the job. If you submit your training job using the `gcloud` tool, you can [specify this field in a `config.yaml` file](/ai-platform/training/docs/training-jobs#formatting_your_configuration_parameters). For example: ```yaml trainingInput: scheduling: maxWaitTime: 3600s ```
        :param pulumi.Input[int] priority: Optional. Job scheduling will be based on this priority, which in the range [0, 1000]. The bigger the number, the higher the priority. Default to 0 if not set. If there are multiple jobs requesting same type of accelerators, the high priority job will be scheduled prior to ones with low priority.
        """
        if max_running_time is not None:
            pulumi.set(__self__, "max_running_time", max_running_time)
        if max_wait_time is not None:
            pulumi.set(__self__, "max_wait_time", max_wait_time)
        if priority is not None:
            pulumi.set(__self__, "priority", priority)

    @property
    @pulumi.getter(name="maxRunningTime")
    def max_running_time(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The maximum job running time, expressed in seconds. The field can contain up to nine fractional digits, terminated by `s`. If not specified, this field defaults to `604800s` (seven days). If the training job is still running after this duration, AI Platform Training cancels it. The duration is measured from when the job enters the `RUNNING` state; therefore it does not overlap with the duration limited by Scheduling.max_wait_time. For example, if you want to ensure your job runs for no more than 2 hours, set this field to `7200s` (2 hours * 60 minutes / hour * 60 seconds / minute). If you submit your training job using the `gcloud` tool, you can [specify this field in a `config.yaml` file](/ai-platform/training/docs/training-jobs#formatting_your_configuration_parameters). For example: ```yaml trainingInput: scheduling: maxRunningTime: 7200s ```
        """
        return pulumi.get(self, "max_running_time")

    @max_running_time.setter
    def max_running_time(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "max_running_time", value)

    @property
    @pulumi.getter(name="maxWaitTime")
    def max_wait_time(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The maximum job wait time, expressed in seconds. The field can contain up to nine fractional digits, terminated by `s`. If not specified, there is no limit to the wait time. The minimum for this field is `1800s` (30 minutes). If the training job has not entered the `RUNNING` state after this duration, AI Platform Training cancels it. After the job begins running, it can no longer be cancelled due to the maximum wait time. Therefore the duration limited by this field does not overlap with the duration limited by Scheduling.max_running_time. For example, if the job temporarily stops running and retries due to a [VM restart](/ai-platform/training/docs/overview#restarts), this cannot lead to a maximum wait time cancellation. However, independently of this constraint, AI Platform Training might stop a job if there are too many retries due to exhausted resources in a region. The following example describes how you might use this field: To cancel your job if it doesn't start running within 1 hour, set this field to `3600s` (1 hour * 60 minutes / hour * 60 seconds / minute). If the job is still in the `QUEUED` or `PREPARING` state after an hour of waiting, AI Platform Training cancels the job. If you submit your training job using the `gcloud` tool, you can [specify this field in a `config.yaml` file](/ai-platform/training/docs/training-jobs#formatting_your_configuration_parameters). For example: ```yaml trainingInput: scheduling: maxWaitTime: 3600s ```
        """
        return pulumi.get(self, "max_wait_time")

    @max_wait_time.setter
    def max_wait_time(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "max_wait_time", value)

    @property
    @pulumi.getter
    def priority(self) -> Optional[pulumi.Input[int]]:
        """
        Optional. Job scheduling will be based on this priority, which in the range [0, 1000]. The bigger the number, the higher the priority. Default to 0 if not set. If there are multiple jobs requesting same type of accelerators, the high priority job will be scheduled prior to ones with low priority.
        """
        return pulumi.get(self, "priority")

    @priority.setter
    def priority(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "priority", value)


@pulumi.input_type
class GoogleCloudMlV1__StudyConfigArgs:
    def __init__(__self__, *,
                 parameters: pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecArgs']]],
                 algorithm: Optional[pulumi.Input['GoogleCloudMlV1__StudyConfigAlgorithm']] = None,
                 automated_stopping_config: Optional[pulumi.Input['GoogleCloudMlV1__AutomatedStoppingConfigArgs']] = None,
                 metrics: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_StudyConfig_MetricSpecArgs']]]] = None):
        """
        Represents configuration of a study.
        :param pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecArgs']]] parameters: The set of parameters to tune.
        :param pulumi.Input['GoogleCloudMlV1__StudyConfigAlgorithm'] algorithm: The search algorithm specified for the study.
        :param pulumi.Input['GoogleCloudMlV1__AutomatedStoppingConfigArgs'] automated_stopping_config: Configuration for automated stopping of unpromising Trials.
        :param pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_StudyConfig_MetricSpecArgs']]] metrics: Metric specs for the study.
        """
        pulumi.set(__self__, "parameters", parameters)
        if algorithm is not None:
            pulumi.set(__self__, "algorithm", algorithm)
        if automated_stopping_config is not None:
            pulumi.set(__self__, "automated_stopping_config", automated_stopping_config)
        if metrics is not None:
            pulumi.set(__self__, "metrics", metrics)

    @property
    @pulumi.getter
    def parameters(self) -> pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecArgs']]]:
        """
        The set of parameters to tune.
        """
        return pulumi.get(self, "parameters")

    @parameters.setter
    def parameters(self, value: pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_StudyConfig_ParameterSpecArgs']]]):
        pulumi.set(self, "parameters", value)

    @property
    @pulumi.getter
    def algorithm(self) -> Optional[pulumi.Input['GoogleCloudMlV1__StudyConfigAlgorithm']]:
        """
        The search algorithm specified for the study.
        """
        return pulumi.get(self, "algorithm")

    @algorithm.setter
    def algorithm(self, value: Optional[pulumi.Input['GoogleCloudMlV1__StudyConfigAlgorithm']]):
        pulumi.set(self, "algorithm", value)

    @property
    @pulumi.getter(name="automatedStoppingConfig")
    def automated_stopping_config(self) -> Optional[pulumi.Input['GoogleCloudMlV1__AutomatedStoppingConfigArgs']]:
        """
        Configuration for automated stopping of unpromising Trials.
        """
        return pulumi.get(self, "automated_stopping_config")

    @automated_stopping_config.setter
    def automated_stopping_config(self, value: Optional[pulumi.Input['GoogleCloudMlV1__AutomatedStoppingConfigArgs']]):
        pulumi.set(self, "automated_stopping_config", value)

    @property
    @pulumi.getter
    def metrics(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_StudyConfig_MetricSpecArgs']]]]:
        """
        Metric specs for the study.
        """
        return pulumi.get(self, "metrics")

    @metrics.setter
    def metrics(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1_StudyConfig_MetricSpecArgs']]]]):
        pulumi.set(self, "metrics", value)


@pulumi.input_type
class GoogleCloudMlV1__TrainingInputArgs:
    def __init__(__self__, *,
                 package_uris: pulumi.Input[Sequence[pulumi.Input[str]]],
                 python_module: pulumi.Input[str],
                 region: pulumi.Input[str],
                 scale_tier: pulumi.Input['GoogleCloudMlV1__TrainingInputScaleTier'],
                 args: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 enable_web_access: Optional[pulumi.Input[bool]] = None,
                 encryption_config: Optional[pulumi.Input['GoogleCloudMlV1__EncryptionConfigArgs']] = None,
                 evaluator_config: Optional[pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs']] = None,
                 evaluator_count: Optional[pulumi.Input[str]] = None,
                 evaluator_type: Optional[pulumi.Input[str]] = None,
                 hyperparameters: Optional[pulumi.Input['GoogleCloudMlV1__HyperparameterSpecArgs']] = None,
                 job_dir: Optional[pulumi.Input[str]] = None,
                 master_config: Optional[pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs']] = None,
                 master_type: Optional[pulumi.Input[str]] = None,
                 network: Optional[pulumi.Input[str]] = None,
                 parameter_server_config: Optional[pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs']] = None,
                 parameter_server_count: Optional[pulumi.Input[str]] = None,
                 parameter_server_type: Optional[pulumi.Input[str]] = None,
                 python_version: Optional[pulumi.Input[str]] = None,
                 runtime_version: Optional[pulumi.Input[str]] = None,
                 scheduling: Optional[pulumi.Input['GoogleCloudMlV1__SchedulingArgs']] = None,
                 service_account: Optional[pulumi.Input[str]] = None,
                 use_chief_in_tf_config: Optional[pulumi.Input[bool]] = None,
                 worker_config: Optional[pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs']] = None,
                 worker_count: Optional[pulumi.Input[str]] = None,
                 worker_type: Optional[pulumi.Input[str]] = None):
        """
        Represents input parameters for a training job. When using the gcloud command to submit your training job, you can specify the input parameters as command-line arguments and/or in a YAML configuration file referenced from the --config command-line argument. For details, see the guide to [submitting a training job](/ai-platform/training/docs/training-jobs).
        :param pulumi.Input[Sequence[pulumi.Input[str]]] package_uris: The Google Cloud Storage location of the packages with the training program and any additional dependencies. The maximum number of package URIs is 100.
        :param pulumi.Input[str] python_module: The Python module name to run after installing the packages.
        :param pulumi.Input[str] region: The region to run the training job in. See the [available regions](/ai-platform/training/docs/regions) for AI Platform Training.
        :param pulumi.Input['GoogleCloudMlV1__TrainingInputScaleTier'] scale_tier: Specifies the machine types, the number of replicas for workers and parameter servers.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] args: Optional. Command-line arguments passed to the training application when it starts. If your job uses a custom container, then the arguments are passed to the container's `ENTRYPOINT` command.
        :param pulumi.Input[bool] enable_web_access: Optional. Whether you want AI Platform Training to enable [interactive shell access](https://cloud.google.com/ai-platform/training/docs/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by TrainingOutput.web_access_uris or HyperparameterOutput.web_access_uris (within TrainingOutput.trials).
        :param pulumi.Input['GoogleCloudMlV1__EncryptionConfigArgs'] encryption_config: Optional. Options for using customer-managed encryption keys (CMEK) to protect resources created by a training job, instead of using Google's default encryption. If this is set, then all resources created by the training job will be encrypted with the customer-managed encryption key that you specify. [Learn how and when to use CMEK with AI Platform Training](/ai-platform/training/docs/cmek).
        :param pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs'] evaluator_config: Optional. The configuration for evaluators. You should only set `evaluatorConfig.acceleratorConfig` if `evaluatorType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `evaluatorConfig.imageUri` only if you build a custom image for your evaluator. If `evaluatorConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
        :param pulumi.Input[str] evaluator_count: Optional. The number of evaluator replicas to use for the training job. Each replica in the cluster will be of the type specified in `evaluator_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `evaluator_type`. The default value is zero.
        :param pulumi.Input[str] evaluator_type: Optional. Specifies the type of virtual machine to use for your training job's evaluator nodes. The supported values are the same as those described in the entry for `masterType`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when `scaleTier` is set to `CUSTOM` and `evaluatorCount` is greater than zero.
        :param pulumi.Input['GoogleCloudMlV1__HyperparameterSpecArgs'] hyperparameters: Optional. The set of Hyperparameters to tune.
        :param pulumi.Input[str] job_dir: Optional. A Google Cloud Storage path in which to store training outputs and other data needed for training. This path is passed to your TensorFlow program as the '--job-dir' command-line argument. The benefit of specifying this field is that Cloud ML validates the path for use in training.
        :param pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs'] master_config: Optional. The configuration for your master worker. You should only set `masterConfig.acceleratorConfig` if `masterType` is set to a Compute Engine machine type. Learn about [restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `masterConfig.imageUri` only if you build a custom image. Only one of `masterConfig.imageUri` and `runtimeVersion` should be set. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
        :param pulumi.Input[str] master_type: Optional. Specifies the type of virtual machine to use for your training job's master worker. You must specify this field when `scaleTier` is set to `CUSTOM`. You can use certain Compute Engine machine types directly in this field. See the [list of compatible Compute Engine machine types](/ai-platform/training/docs/machine-types#compute-engine-machine-types). Alternatively, you can use the certain legacy machine types in this field. See the [list of legacy machine types](/ai-platform/training/docs/machine-types#legacy-machine-types). Finally, if you want to use a TPU for training, specify `cloud_tpu` in this field. Learn more about the [special configuration options for training with TPUs](/ai-platform/training/docs/using-tpus#configuring_a_custom_tpu_machine).
        :param pulumi.Input[str] network: Optional. The full name of the [Compute Engine network](/vpc/docs/vpc) to which the Job is peered. For example, `projects/12345/global/networks/myVPC`. The format of this field is `projects/{project}/global/networks/{network}`, where {project} is a project number (like `12345`) and {network} is network name. Private services access must already be configured for the network. If left unspecified, the Job is not peered with any network. [Learn about using VPC Network Peering.](/ai-platform/training/docs/vpc-peering).
        :param pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs'] parameter_server_config: Optional. The configuration for parameter servers. You should only set `parameterServerConfig.acceleratorConfig` if `parameterServerType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `parameterServerConfig.imageUri` only if you build a custom image for your parameter server. If `parameterServerConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
        :param pulumi.Input[str] parameter_server_count: Optional. The number of parameter server replicas to use for the training job. Each replica in the cluster will be of the type specified in `parameter_server_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `parameter_server_type`. The default value is zero.
        :param pulumi.Input[str] parameter_server_type: Optional. Specifies the type of virtual machine to use for your training job's parameter server. The supported values are the same as those described in the entry for `master_type`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when `scaleTier` is set to `CUSTOM` and `parameter_server_count` is greater than zero.
        :param pulumi.Input[str] python_version: Optional. The version of Python used in training. You must either specify this field or specify `masterConfig.imageUri`. The following Python versions are available: * Python '3.7' is available when `runtime_version` is set to '1.15' or later. * Python '3.5' is available when `runtime_version` is set to a version from '1.4' to '1.14'. * Python '2.7' is available when `runtime_version` is set to '1.15' or earlier. Read more about the Python versions available for [each runtime version](/ml-engine/docs/runtime-version-list).
        :param pulumi.Input[str] runtime_version: Optional. The AI Platform runtime version to use for training. You must either specify this field or specify `masterConfig.imageUri`. For more information, see the [runtime version list](/ai-platform/training/docs/runtime-version-list) and learn [how to manage runtime versions](/ai-platform/training/docs/versioning).
        :param pulumi.Input['GoogleCloudMlV1__SchedulingArgs'] scheduling: Optional. Scheduling options for a training job.
        :param pulumi.Input[str] service_account: Optional. The email address of a service account to use when running the training appplication. You must have the `iam.serviceAccounts.actAs` permission for the specified service account. In addition, the AI Platform Training Google-managed service account must have the `roles/iam.serviceAccountAdmin` role for the specified service account. [Learn more about configuring a service account.](/ai-platform/training/docs/custom-service-account) If not specified, the AI Platform Training Google-managed service account is used by default.
        :param pulumi.Input[bool] use_chief_in_tf_config: Optional. Use `chief` instead of `master` in the `TF_CONFIG` environment variable when training with a custom container. Defaults to `false`. [Learn more about this field.](/ai-platform/training/docs/distributed-training-details#chief-versus-master) This field has no effect for training jobs that don't use a custom container.
        :param pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs'] worker_config: Optional. The configuration for workers. You should only set `workerConfig.acceleratorConfig` if `workerType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `workerConfig.imageUri` only if you build a custom image for your worker. If `workerConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
        :param pulumi.Input[str] worker_count: Optional. The number of worker replicas to use for the training job. Each replica in the cluster will be of the type specified in `worker_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `worker_type`. The default value is zero.
        :param pulumi.Input[str] worker_type: Optional. Specifies the type of virtual machine to use for your training job's worker nodes. The supported values are the same as those described in the entry for `masterType`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. If you use `cloud_tpu` for this value, see special instructions for [configuring a custom TPU machine](/ml-engine/docs/tensorflow/using-tpus#configuring_a_custom_tpu_machine). This value must be present when `scaleTier` is set to `CUSTOM` and `workerCount` is greater than zero.
        """
        pulumi.set(__self__, "package_uris", package_uris)
        pulumi.set(__self__, "python_module", python_module)
        pulumi.set(__self__, "region", region)
        pulumi.set(__self__, "scale_tier", scale_tier)
        if args is not None:
            pulumi.set(__self__, "args", args)
        if enable_web_access is not None:
            pulumi.set(__self__, "enable_web_access", enable_web_access)
        if encryption_config is not None:
            pulumi.set(__self__, "encryption_config", encryption_config)
        if evaluator_config is not None:
            pulumi.set(__self__, "evaluator_config", evaluator_config)
        if evaluator_count is not None:
            pulumi.set(__self__, "evaluator_count", evaluator_count)
        if evaluator_type is not None:
            pulumi.set(__self__, "evaluator_type", evaluator_type)
        if hyperparameters is not None:
            pulumi.set(__self__, "hyperparameters", hyperparameters)
        if job_dir is not None:
            pulumi.set(__self__, "job_dir", job_dir)
        if master_config is not None:
            pulumi.set(__self__, "master_config", master_config)
        if master_type is not None:
            pulumi.set(__self__, "master_type", master_type)
        if network is not None:
            pulumi.set(__self__, "network", network)
        if parameter_server_config is not None:
            pulumi.set(__self__, "parameter_server_config", parameter_server_config)
        if parameter_server_count is not None:
            pulumi.set(__self__, "parameter_server_count", parameter_server_count)
        if parameter_server_type is not None:
            pulumi.set(__self__, "parameter_server_type", parameter_server_type)
        if python_version is not None:
            pulumi.set(__self__, "python_version", python_version)
        if runtime_version is not None:
            pulumi.set(__self__, "runtime_version", runtime_version)
        if scheduling is not None:
            pulumi.set(__self__, "scheduling", scheduling)
        if service_account is not None:
            pulumi.set(__self__, "service_account", service_account)
        if use_chief_in_tf_config is not None:
            pulumi.set(__self__, "use_chief_in_tf_config", use_chief_in_tf_config)
        if worker_config is not None:
            pulumi.set(__self__, "worker_config", worker_config)
        if worker_count is not None:
            pulumi.set(__self__, "worker_count", worker_count)
        if worker_type is not None:
            pulumi.set(__self__, "worker_type", worker_type)

    @property
    @pulumi.getter(name="packageUris")
    def package_uris(self) -> pulumi.Input[Sequence[pulumi.Input[str]]]:
        """
        The Google Cloud Storage location of the packages with the training program and any additional dependencies. The maximum number of package URIs is 100.
        """
        return pulumi.get(self, "package_uris")

    @package_uris.setter
    def package_uris(self, value: pulumi.Input[Sequence[pulumi.Input[str]]]):
        pulumi.set(self, "package_uris", value)

    @property
    @pulumi.getter(name="pythonModule")
    def python_module(self) -> pulumi.Input[str]:
        """
        The Python module name to run after installing the packages.
        """
        return pulumi.get(self, "python_module")

    @python_module.setter
    def python_module(self, value: pulumi.Input[str]):
        pulumi.set(self, "python_module", value)

    @property
    @pulumi.getter
    def region(self) -> pulumi.Input[str]:
        """
        The region to run the training job in. See the [available regions](/ai-platform/training/docs/regions) for AI Platform Training.
        """
        return pulumi.get(self, "region")

    @region.setter
    def region(self, value: pulumi.Input[str]):
        pulumi.set(self, "region", value)

    @property
    @pulumi.getter(name="scaleTier")
    def scale_tier(self) -> pulumi.Input['GoogleCloudMlV1__TrainingInputScaleTier']:
        """
        Specifies the machine types, the number of replicas for workers and parameter servers.
        """
        return pulumi.get(self, "scale_tier")

    @scale_tier.setter
    def scale_tier(self, value: pulumi.Input['GoogleCloudMlV1__TrainingInputScaleTier']):
        pulumi.set(self, "scale_tier", value)

    @property
    @pulumi.getter
    def args(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Optional. Command-line arguments passed to the training application when it starts. If your job uses a custom container, then the arguments are passed to the container's `ENTRYPOINT` command.
        """
        return pulumi.get(self, "args")

    @args.setter
    def args(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "args", value)

    @property
    @pulumi.getter(name="enableWebAccess")
    def enable_web_access(self) -> Optional[pulumi.Input[bool]]:
        """
        Optional. Whether you want AI Platform Training to enable [interactive shell access](https://cloud.google.com/ai-platform/training/docs/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by TrainingOutput.web_access_uris or HyperparameterOutput.web_access_uris (within TrainingOutput.trials).
        """
        return pulumi.get(self, "enable_web_access")

    @enable_web_access.setter
    def enable_web_access(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "enable_web_access", value)

    @property
    @pulumi.getter(name="encryptionConfig")
    def encryption_config(self) -> Optional[pulumi.Input['GoogleCloudMlV1__EncryptionConfigArgs']]:
        """
        Optional. Options for using customer-managed encryption keys (CMEK) to protect resources created by a training job, instead of using Google's default encryption. If this is set, then all resources created by the training job will be encrypted with the customer-managed encryption key that you specify. [Learn how and when to use CMEK with AI Platform Training](/ai-platform/training/docs/cmek).
        """
        return pulumi.get(self, "encryption_config")

    @encryption_config.setter
    def encryption_config(self, value: Optional[pulumi.Input['GoogleCloudMlV1__EncryptionConfigArgs']]):
        pulumi.set(self, "encryption_config", value)

    @property
    @pulumi.getter(name="evaluatorConfig")
    def evaluator_config(self) -> Optional[pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs']]:
        """
        Optional. The configuration for evaluators. You should only set `evaluatorConfig.acceleratorConfig` if `evaluatorType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `evaluatorConfig.imageUri` only if you build a custom image for your evaluator. If `evaluatorConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
        """
        return pulumi.get(self, "evaluator_config")

    @evaluator_config.setter
    def evaluator_config(self, value: Optional[pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs']]):
        pulumi.set(self, "evaluator_config", value)

    @property
    @pulumi.getter(name="evaluatorCount")
    def evaluator_count(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The number of evaluator replicas to use for the training job. Each replica in the cluster will be of the type specified in `evaluator_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `evaluator_type`. The default value is zero.
        """
        return pulumi.get(self, "evaluator_count")

    @evaluator_count.setter
    def evaluator_count(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "evaluator_count", value)

    @property
    @pulumi.getter(name="evaluatorType")
    def evaluator_type(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. Specifies the type of virtual machine to use for your training job's evaluator nodes. The supported values are the same as those described in the entry for `masterType`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when `scaleTier` is set to `CUSTOM` and `evaluatorCount` is greater than zero.
        """
        return pulumi.get(self, "evaluator_type")

    @evaluator_type.setter
    def evaluator_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "evaluator_type", value)

    @property
    @pulumi.getter
    def hyperparameters(self) -> Optional[pulumi.Input['GoogleCloudMlV1__HyperparameterSpecArgs']]:
        """
        Optional. The set of Hyperparameters to tune.
        """
        return pulumi.get(self, "hyperparameters")

    @hyperparameters.setter
    def hyperparameters(self, value: Optional[pulumi.Input['GoogleCloudMlV1__HyperparameterSpecArgs']]):
        pulumi.set(self, "hyperparameters", value)

    @property
    @pulumi.getter(name="jobDir")
    def job_dir(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. A Google Cloud Storage path in which to store training outputs and other data needed for training. This path is passed to your TensorFlow program as the '--job-dir' command-line argument. The benefit of specifying this field is that Cloud ML validates the path for use in training.
        """
        return pulumi.get(self, "job_dir")

    @job_dir.setter
    def job_dir(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "job_dir", value)

    @property
    @pulumi.getter(name="masterConfig")
    def master_config(self) -> Optional[pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs']]:
        """
        Optional. The configuration for your master worker. You should only set `masterConfig.acceleratorConfig` if `masterType` is set to a Compute Engine machine type. Learn about [restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `masterConfig.imageUri` only if you build a custom image. Only one of `masterConfig.imageUri` and `runtimeVersion` should be set. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
        """
        return pulumi.get(self, "master_config")

    @master_config.setter
    def master_config(self, value: Optional[pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs']]):
        pulumi.set(self, "master_config", value)

    @property
    @pulumi.getter(name="masterType")
    def master_type(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. Specifies the type of virtual machine to use for your training job's master worker. You must specify this field when `scaleTier` is set to `CUSTOM`. You can use certain Compute Engine machine types directly in this field. See the [list of compatible Compute Engine machine types](/ai-platform/training/docs/machine-types#compute-engine-machine-types). Alternatively, you can use the certain legacy machine types in this field. See the [list of legacy machine types](/ai-platform/training/docs/machine-types#legacy-machine-types). Finally, if you want to use a TPU for training, specify `cloud_tpu` in this field. Learn more about the [special configuration options for training with TPUs](/ai-platform/training/docs/using-tpus#configuring_a_custom_tpu_machine).
        """
        return pulumi.get(self, "master_type")

    @master_type.setter
    def master_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "master_type", value)

    @property
    @pulumi.getter
    def network(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The full name of the [Compute Engine network](/vpc/docs/vpc) to which the Job is peered. For example, `projects/12345/global/networks/myVPC`. The format of this field is `projects/{project}/global/networks/{network}`, where {project} is a project number (like `12345`) and {network} is network name. Private services access must already be configured for the network. If left unspecified, the Job is not peered with any network. [Learn about using VPC Network Peering.](/ai-platform/training/docs/vpc-peering).
        """
        return pulumi.get(self, "network")

    @network.setter
    def network(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "network", value)

    @property
    @pulumi.getter(name="parameterServerConfig")
    def parameter_server_config(self) -> Optional[pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs']]:
        """
        Optional. The configuration for parameter servers. You should only set `parameterServerConfig.acceleratorConfig` if `parameterServerType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `parameterServerConfig.imageUri` only if you build a custom image for your parameter server. If `parameterServerConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
        """
        return pulumi.get(self, "parameter_server_config")

    @parameter_server_config.setter
    def parameter_server_config(self, value: Optional[pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs']]):
        pulumi.set(self, "parameter_server_config", value)

    @property
    @pulumi.getter(name="parameterServerCount")
    def parameter_server_count(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The number of parameter server replicas to use for the training job. Each replica in the cluster will be of the type specified in `parameter_server_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `parameter_server_type`. The default value is zero.
        """
        return pulumi.get(self, "parameter_server_count")

    @parameter_server_count.setter
    def parameter_server_count(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "parameter_server_count", value)

    @property
    @pulumi.getter(name="parameterServerType")
    def parameter_server_type(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. Specifies the type of virtual machine to use for your training job's parameter server. The supported values are the same as those described in the entry for `master_type`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. This value must be present when `scaleTier` is set to `CUSTOM` and `parameter_server_count` is greater than zero.
        """
        return pulumi.get(self, "parameter_server_type")

    @parameter_server_type.setter
    def parameter_server_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "parameter_server_type", value)

    @property
    @pulumi.getter(name="pythonVersion")
    def python_version(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The version of Python used in training. You must either specify this field or specify `masterConfig.imageUri`. The following Python versions are available: * Python '3.7' is available when `runtime_version` is set to '1.15' or later. * Python '3.5' is available when `runtime_version` is set to a version from '1.4' to '1.14'. * Python '2.7' is available when `runtime_version` is set to '1.15' or earlier. Read more about the Python versions available for [each runtime version](/ml-engine/docs/runtime-version-list).
        """
        return pulumi.get(self, "python_version")

    @python_version.setter
    def python_version(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "python_version", value)

    @property
    @pulumi.getter(name="runtimeVersion")
    def runtime_version(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The AI Platform runtime version to use for training. You must either specify this field or specify `masterConfig.imageUri`. For more information, see the [runtime version list](/ai-platform/training/docs/runtime-version-list) and learn [how to manage runtime versions](/ai-platform/training/docs/versioning).
        """
        return pulumi.get(self, "runtime_version")

    @runtime_version.setter
    def runtime_version(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "runtime_version", value)

    @property
    @pulumi.getter
    def scheduling(self) -> Optional[pulumi.Input['GoogleCloudMlV1__SchedulingArgs']]:
        """
        Optional. Scheduling options for a training job.
        """
        return pulumi.get(self, "scheduling")

    @scheduling.setter
    def scheduling(self, value: Optional[pulumi.Input['GoogleCloudMlV1__SchedulingArgs']]):
        pulumi.set(self, "scheduling", value)

    @property
    @pulumi.getter(name="serviceAccount")
    def service_account(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The email address of a service account to use when running the training appplication. You must have the `iam.serviceAccounts.actAs` permission for the specified service account. In addition, the AI Platform Training Google-managed service account must have the `roles/iam.serviceAccountAdmin` role for the specified service account. [Learn more about configuring a service account.](/ai-platform/training/docs/custom-service-account) If not specified, the AI Platform Training Google-managed service account is used by default.
        """
        return pulumi.get(self, "service_account")

    @service_account.setter
    def service_account(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "service_account", value)

    @property
    @pulumi.getter(name="useChiefInTfConfig")
    def use_chief_in_tf_config(self) -> Optional[pulumi.Input[bool]]:
        """
        Optional. Use `chief` instead of `master` in the `TF_CONFIG` environment variable when training with a custom container. Defaults to `false`. [Learn more about this field.](/ai-platform/training/docs/distributed-training-details#chief-versus-master) This field has no effect for training jobs that don't use a custom container.
        """
        return pulumi.get(self, "use_chief_in_tf_config")

    @use_chief_in_tf_config.setter
    def use_chief_in_tf_config(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "use_chief_in_tf_config", value)

    @property
    @pulumi.getter(name="workerConfig")
    def worker_config(self) -> Optional[pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs']]:
        """
        Optional. The configuration for workers. You should only set `workerConfig.acceleratorConfig` if `workerType` is set to a Compute Engine machine type. [Learn about restrictions on accelerator configurations for training.](/ai-platform/training/docs/using-gpus#compute-engine-machine-types-with-gpu) Set `workerConfig.imageUri` only if you build a custom image for your worker. If `workerConfig.imageUri` has not been set, AI Platform uses the value of `masterConfig.imageUri`. Learn more about [configuring custom containers](/ai-platform/training/docs/distributed-training-containers).
        """
        return pulumi.get(self, "worker_config")

    @worker_config.setter
    def worker_config(self, value: Optional[pulumi.Input['GoogleCloudMlV1__ReplicaConfigArgs']]):
        pulumi.set(self, "worker_config", value)

    @property
    @pulumi.getter(name="workerCount")
    def worker_count(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. The number of worker replicas to use for the training job. Each replica in the cluster will be of the type specified in `worker_type`. This value can only be used when `scale_tier` is set to `CUSTOM`. If you set this value, you must also set `worker_type`. The default value is zero.
        """
        return pulumi.get(self, "worker_count")

    @worker_count.setter
    def worker_count(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "worker_count", value)

    @property
    @pulumi.getter(name="workerType")
    def worker_type(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. Specifies the type of virtual machine to use for your training job's worker nodes. The supported values are the same as those described in the entry for `masterType`. This value must be consistent with the category of machine type that `masterType` uses. In other words, both must be Compute Engine machine types or both must be legacy machine types. If you use `cloud_tpu` for this value, see special instructions for [configuring a custom TPU machine](/ml-engine/docs/tensorflow/using-tpus#configuring_a_custom_tpu_machine). This value must be present when `scaleTier` is set to `CUSTOM` and `workerCount` is greater than zero.
        """
        return pulumi.get(self, "worker_type")

    @worker_type.setter
    def worker_type(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "worker_type", value)


@pulumi.input_type
class GoogleCloudMlV1__TrainingOutputArgs:
    def __init__(__self__, *,
                 built_in_algorithm_output: Optional[pulumi.Input['GoogleCloudMlV1__BuiltInAlgorithmOutputArgs']] = None,
                 completed_trial_count: Optional[pulumi.Input[str]] = None,
                 consumed_ml_units: Optional[pulumi.Input[float]] = None,
                 hyperparameter_metric_tag: Optional[pulumi.Input[str]] = None,
                 is_built_in_algorithm_job: Optional[pulumi.Input[bool]] = None,
                 is_hyperparameter_tuning_job: Optional[pulumi.Input[bool]] = None,
                 trials: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__HyperparameterOutputArgs']]]] = None):
        """
        Represents results of a training job. Output only.
        :param pulumi.Input['GoogleCloudMlV1__BuiltInAlgorithmOutputArgs'] built_in_algorithm_output: Details related to built-in algorithms jobs. Only set for built-in algorithms jobs.
        :param pulumi.Input[str] completed_trial_count: The number of hyperparameter tuning trials that completed successfully. Only set for hyperparameter tuning jobs.
        :param pulumi.Input[float] consumed_ml_units: The amount of ML units consumed by the job.
        :param pulumi.Input[str] hyperparameter_metric_tag: The TensorFlow summary tag name used for optimizing hyperparameter tuning trials. See [`HyperparameterSpec.hyperparameterMetricTag`](#HyperparameterSpec.FIELDS.hyperparameter_metric_tag) for more information. Only set for hyperparameter tuning jobs.
        :param pulumi.Input[bool] is_built_in_algorithm_job: Whether this job is a built-in Algorithm job.
        :param pulumi.Input[bool] is_hyperparameter_tuning_job: Whether this job is a hyperparameter tuning job.
        :param pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__HyperparameterOutputArgs']]] trials: Results for individual Hyperparameter trials. Only set for hyperparameter tuning jobs.
        """
        if built_in_algorithm_output is not None:
            pulumi.set(__self__, "built_in_algorithm_output", built_in_algorithm_output)
        if completed_trial_count is not None:
            pulumi.set(__self__, "completed_trial_count", completed_trial_count)
        if consumed_ml_units is not None:
            pulumi.set(__self__, "consumed_ml_units", consumed_ml_units)
        if hyperparameter_metric_tag is not None:
            pulumi.set(__self__, "hyperparameter_metric_tag", hyperparameter_metric_tag)
        if is_built_in_algorithm_job is not None:
            pulumi.set(__self__, "is_built_in_algorithm_job", is_built_in_algorithm_job)
        if is_hyperparameter_tuning_job is not None:
            pulumi.set(__self__, "is_hyperparameter_tuning_job", is_hyperparameter_tuning_job)
        if trials is not None:
            pulumi.set(__self__, "trials", trials)

    @property
    @pulumi.getter(name="builtInAlgorithmOutput")
    def built_in_algorithm_output(self) -> Optional[pulumi.Input['GoogleCloudMlV1__BuiltInAlgorithmOutputArgs']]:
        """
        Details related to built-in algorithms jobs. Only set for built-in algorithms jobs.
        """
        return pulumi.get(self, "built_in_algorithm_output")

    @built_in_algorithm_output.setter
    def built_in_algorithm_output(self, value: Optional[pulumi.Input['GoogleCloudMlV1__BuiltInAlgorithmOutputArgs']]):
        pulumi.set(self, "built_in_algorithm_output", value)

    @property
    @pulumi.getter(name="completedTrialCount")
    def completed_trial_count(self) -> Optional[pulumi.Input[str]]:
        """
        The number of hyperparameter tuning trials that completed successfully. Only set for hyperparameter tuning jobs.
        """
        return pulumi.get(self, "completed_trial_count")

    @completed_trial_count.setter
    def completed_trial_count(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "completed_trial_count", value)

    @property
    @pulumi.getter(name="consumedMLUnits")
    def consumed_ml_units(self) -> Optional[pulumi.Input[float]]:
        """
        The amount of ML units consumed by the job.
        """
        return pulumi.get(self, "consumed_ml_units")

    @consumed_ml_units.setter
    def consumed_ml_units(self, value: Optional[pulumi.Input[float]]):
        pulumi.set(self, "consumed_ml_units", value)

    @property
    @pulumi.getter(name="hyperparameterMetricTag")
    def hyperparameter_metric_tag(self) -> Optional[pulumi.Input[str]]:
        """
        The TensorFlow summary tag name used for optimizing hyperparameter tuning trials. See [`HyperparameterSpec.hyperparameterMetricTag`](#HyperparameterSpec.FIELDS.hyperparameter_metric_tag) for more information. Only set for hyperparameter tuning jobs.
        """
        return pulumi.get(self, "hyperparameter_metric_tag")

    @hyperparameter_metric_tag.setter
    def hyperparameter_metric_tag(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "hyperparameter_metric_tag", value)

    @property
    @pulumi.getter(name="isBuiltInAlgorithmJob")
    def is_built_in_algorithm_job(self) -> Optional[pulumi.Input[bool]]:
        """
        Whether this job is a built-in Algorithm job.
        """
        return pulumi.get(self, "is_built_in_algorithm_job")

    @is_built_in_algorithm_job.setter
    def is_built_in_algorithm_job(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "is_built_in_algorithm_job", value)

    @property
    @pulumi.getter(name="isHyperparameterTuningJob")
    def is_hyperparameter_tuning_job(self) -> Optional[pulumi.Input[bool]]:
        """
        Whether this job is a hyperparameter tuning job.
        """
        return pulumi.get(self, "is_hyperparameter_tuning_job")

    @is_hyperparameter_tuning_job.setter
    def is_hyperparameter_tuning_job(self, value: Optional[pulumi.Input[bool]]):
        pulumi.set(self, "is_hyperparameter_tuning_job", value)

    @property
    @pulumi.getter
    def trials(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__HyperparameterOutputArgs']]]]:
        """
        Results for individual Hyperparameter trials. Only set for hyperparameter tuning jobs.
        """
        return pulumi.get(self, "trials")

    @trials.setter
    def trials(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleCloudMlV1__HyperparameterOutputArgs']]]]):
        pulumi.set(self, "trials", value)


@pulumi.input_type
class GoogleCloudMlV1__XraiAttributionArgs:
    def __init__(__self__, *,
                 num_integral_steps: Optional[pulumi.Input[int]] = None):
        """
        Attributes credit by computing the XRAI taking advantage of the model's fully differentiable structure. Refer to this paper for more details: https://arxiv.org/abs/1906.02825 Currently only implemented for models with natural image inputs.
        :param pulumi.Input[int] num_integral_steps: Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range.
        """
        if num_integral_steps is not None:
            pulumi.set(__self__, "num_integral_steps", num_integral_steps)

    @property
    @pulumi.getter(name="numIntegralSteps")
    def num_integral_steps(self) -> Optional[pulumi.Input[int]]:
        """
        Number of steps for approximating the path integral. A good value to start is 50 and gradually increase until the sum to diff property is met within the desired error range.
        """
        return pulumi.get(self, "num_integral_steps")

    @num_integral_steps.setter
    def num_integral_steps(self, value: Optional[pulumi.Input[int]]):
        pulumi.set(self, "num_integral_steps", value)


@pulumi.input_type
class GoogleIamV1__AuditConfigArgs:
    def __init__(__self__, *,
                 audit_log_configs: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleIamV1__AuditLogConfigArgs']]]] = None,
                 service: Optional[pulumi.Input[str]] = None):
        """
        Specifies the audit configuration for a service. The configuration determines which permission types are logged, and what identities, if any, are exempted from logging. An AuditConfig must have one or more AuditLogConfigs. If there are AuditConfigs for both `allServices` and a specific service, the union of the two AuditConfigs is used for that service: the log_types specified in each AuditConfig are enabled, and the exempted_members in each AuditLogConfig are exempted. Example Policy with multiple AuditConfigs: { "audit_configs": [ { "service": "allServices", "audit_log_configs": [ { "log_type": "DATA_READ", "exempted_members": [ "user:jose@example.com" ] }, { "log_type": "DATA_WRITE" }, { "log_type": "ADMIN_READ" } ] }, { "service": "sampleservice.googleapis.com", "audit_log_configs": [ { "log_type": "DATA_READ" }, { "log_type": "DATA_WRITE", "exempted_members": [ "user:aliya@example.com" ] } ] } ] } For sampleservice, this policy enables DATA_READ, DATA_WRITE and ADMIN_READ logging. It also exempts `jose@example.com` from DATA_READ logging, and `aliya@example.com` from DATA_WRITE logging.
        :param pulumi.Input[Sequence[pulumi.Input['GoogleIamV1__AuditLogConfigArgs']]] audit_log_configs: The configuration for logging of each type of permission.
        :param pulumi.Input[str] service: Specifies a service that will be enabled for audit logging. For example, `storage.googleapis.com`, `cloudsql.googleapis.com`. `allServices` is a special value that covers all services.
        """
        if audit_log_configs is not None:
            pulumi.set(__self__, "audit_log_configs", audit_log_configs)
        if service is not None:
            pulumi.set(__self__, "service", service)

    @property
    @pulumi.getter(name="auditLogConfigs")
    def audit_log_configs(self) -> Optional[pulumi.Input[Sequence[pulumi.Input['GoogleIamV1__AuditLogConfigArgs']]]]:
        """
        The configuration for logging of each type of permission.
        """
        return pulumi.get(self, "audit_log_configs")

    @audit_log_configs.setter
    def audit_log_configs(self, value: Optional[pulumi.Input[Sequence[pulumi.Input['GoogleIamV1__AuditLogConfigArgs']]]]):
        pulumi.set(self, "audit_log_configs", value)

    @property
    @pulumi.getter
    def service(self) -> Optional[pulumi.Input[str]]:
        """
        Specifies a service that will be enabled for audit logging. For example, `storage.googleapis.com`, `cloudsql.googleapis.com`. `allServices` is a special value that covers all services.
        """
        return pulumi.get(self, "service")

    @service.setter
    def service(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "service", value)


@pulumi.input_type
class GoogleIamV1__AuditLogConfigArgs:
    def __init__(__self__, *,
                 exempted_members: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 log_type: Optional[pulumi.Input['GoogleIamV1__AuditLogConfigLogType']] = None):
        """
        Provides the configuration for logging a type of permissions. Example: { "audit_log_configs": [ { "log_type": "DATA_READ", "exempted_members": [ "user:jose@example.com" ] }, { "log_type": "DATA_WRITE" } ] } This enables 'DATA_READ' and 'DATA_WRITE' logging, while exempting jose@example.com from DATA_READ logging.
        :param pulumi.Input[Sequence[pulumi.Input[str]]] exempted_members: Specifies the identities that do not cause logging for this type of permission. Follows the same format of Binding.members.
        :param pulumi.Input['GoogleIamV1__AuditLogConfigLogType'] log_type: The log type that this config enables.
        """
        if exempted_members is not None:
            pulumi.set(__self__, "exempted_members", exempted_members)
        if log_type is not None:
            pulumi.set(__self__, "log_type", log_type)

    @property
    @pulumi.getter(name="exemptedMembers")
    def exempted_members(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Specifies the identities that do not cause logging for this type of permission. Follows the same format of Binding.members.
        """
        return pulumi.get(self, "exempted_members")

    @exempted_members.setter
    def exempted_members(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "exempted_members", value)

    @property
    @pulumi.getter(name="logType")
    def log_type(self) -> Optional[pulumi.Input['GoogleIamV1__AuditLogConfigLogType']]:
        """
        The log type that this config enables.
        """
        return pulumi.get(self, "log_type")

    @log_type.setter
    def log_type(self, value: Optional[pulumi.Input['GoogleIamV1__AuditLogConfigLogType']]):
        pulumi.set(self, "log_type", value)


@pulumi.input_type
class GoogleIamV1__BindingArgs:
    def __init__(__self__, *,
                 condition: Optional[pulumi.Input['GoogleType__ExprArgs']] = None,
                 members: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]] = None,
                 role: Optional[pulumi.Input[str]] = None):
        """
        Associates `members`, or principals, with a `role`.
        :param pulumi.Input['GoogleType__ExprArgs'] condition: The condition that is associated with this binding. If the condition evaluates to `true`, then this binding applies to the current request. If the condition evaluates to `false`, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the principals in this binding. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
        :param pulumi.Input[Sequence[pulumi.Input[str]]] members: Specifies the principals requesting access for a Google Cloud resource. `members` can have the following values: * `allUsers`: A special identifier that represents anyone who is on the internet; with or without a Google account. * `allAuthenticatedUsers`: A special identifier that represents anyone who is authenticated with a Google account or a service account. Does not include identities that come from external identity providers (IdPs) through identity federation. * `user:{emailid}`: An email address that represents a specific Google account. For example, `alice@example.com` . * `serviceAccount:{emailid}`: An email address that represents a Google service account. For example, `my-other-app@appspot.gserviceaccount.com`. * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An identifier for a [Kubernetes service account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts). For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. * `group:{emailid}`: An email address that represents a Google group. For example, `admins@example.com`. * `domain:{domain}`: The G Suite domain (primary) that represents all the users of that domain. For example, `google.com` or `example.com`. * `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a user that has been recently deleted. For example, `alice@example.com?uid=123456789012345678901`. If the user is recovered, this value reverts to `user:{emailid}` and the recovered user retains the role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If the service account is undeleted, this value reverts to `serviceAccount:{emailid}` and the undeleted service account retains the role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, `admins@example.com?uid=123456789012345678901`. If the group is recovered, this value reverts to `group:{emailid}` and the recovered group retains the role in the binding.
        :param pulumi.Input[str] role: Role that is assigned to the list of `members`, or principals. For example, `roles/viewer`, `roles/editor`, or `roles/owner`.
        """
        if condition is not None:
            pulumi.set(__self__, "condition", condition)
        if members is not None:
            pulumi.set(__self__, "members", members)
        if role is not None:
            pulumi.set(__self__, "role", role)

    @property
    @pulumi.getter
    def condition(self) -> Optional[pulumi.Input['GoogleType__ExprArgs']]:
        """
        The condition that is associated with this binding. If the condition evaluates to `true`, then this binding applies to the current request. If the condition evaluates to `false`, then this binding does not apply to the current request. However, a different role binding might grant the same role to one or more of the principals in this binding. To learn which resources support conditions in their IAM policies, see the [IAM documentation](https://cloud.google.com/iam/help/conditions/resource-policies).
        """
        return pulumi.get(self, "condition")

    @condition.setter
    def condition(self, value: Optional[pulumi.Input['GoogleType__ExprArgs']]):
        pulumi.set(self, "condition", value)

    @property
    @pulumi.getter
    def members(self) -> Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]:
        """
        Specifies the principals requesting access for a Google Cloud resource. `members` can have the following values: * `allUsers`: A special identifier that represents anyone who is on the internet; with or without a Google account. * `allAuthenticatedUsers`: A special identifier that represents anyone who is authenticated with a Google account or a service account. Does not include identities that come from external identity providers (IdPs) through identity federation. * `user:{emailid}`: An email address that represents a specific Google account. For example, `alice@example.com` . * `serviceAccount:{emailid}`: An email address that represents a Google service account. For example, `my-other-app@appspot.gserviceaccount.com`. * `serviceAccount:{projectid}.svc.id.goog[{namespace}/{kubernetes-sa}]`: An identifier for a [Kubernetes service account](https://cloud.google.com/kubernetes-engine/docs/how-to/kubernetes-service-accounts). For example, `my-project.svc.id.goog[my-namespace/my-kubernetes-sa]`. * `group:{emailid}`: An email address that represents a Google group. For example, `admins@example.com`. * `domain:{domain}`: The G Suite domain (primary) that represents all the users of that domain. For example, `google.com` or `example.com`. * `deleted:user:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a user that has been recently deleted. For example, `alice@example.com?uid=123456789012345678901`. If the user is recovered, this value reverts to `user:{emailid}` and the recovered user retains the role in the binding. * `deleted:serviceAccount:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a service account that has been recently deleted. For example, `my-other-app@appspot.gserviceaccount.com?uid=123456789012345678901`. If the service account is undeleted, this value reverts to `serviceAccount:{emailid}` and the undeleted service account retains the role in the binding. * `deleted:group:{emailid}?uid={uniqueid}`: An email address (plus unique identifier) representing a Google group that has been recently deleted. For example, `admins@example.com?uid=123456789012345678901`. If the group is recovered, this value reverts to `group:{emailid}` and the recovered group retains the role in the binding.
        """
        return pulumi.get(self, "members")

    @members.setter
    def members(self, value: Optional[pulumi.Input[Sequence[pulumi.Input[str]]]]):
        pulumi.set(self, "members", value)

    @property
    @pulumi.getter
    def role(self) -> Optional[pulumi.Input[str]]:
        """
        Role that is assigned to the list of `members`, or principals. For example, `roles/viewer`, `roles/editor`, or `roles/owner`.
        """
        return pulumi.get(self, "role")

    @role.setter
    def role(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "role", value)


@pulumi.input_type
class GoogleType__ExprArgs:
    def __init__(__self__, *,
                 description: Optional[pulumi.Input[str]] = None,
                 expression: Optional[pulumi.Input[str]] = None,
                 location: Optional[pulumi.Input[str]] = None,
                 title: Optional[pulumi.Input[str]] = None):
        """
        Represents a textual expression in the Common Expression Language (CEL) syntax. CEL is a C-like expression language. The syntax and semantics of CEL are documented at https://github.com/google/cel-spec. Example (Comparison): title: "Summary size limit" description: "Determines if a summary is less than 100 chars" expression: "document.summary.size() < 100" Example (Equality): title: "Requestor is owner" description: "Determines if requestor is the document owner" expression: "document.owner == request.auth.claims.email" Example (Logic): title: "Public documents" description: "Determine whether the document should be publicly visible" expression: "document.type != 'private' && document.type != 'internal'" Example (Data Manipulation): title: "Notification string" description: "Create a notification string with a timestamp." expression: "'New message received at ' + string(document.create_time)" The exact variables and functions that may be referenced within an expression are determined by the service that evaluates it. See the service documentation for additional information.
        :param pulumi.Input[str] description: Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
        :param pulumi.Input[str] expression: Textual representation of an expression in Common Expression Language syntax.
        :param pulumi.Input[str] location: Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
        :param pulumi.Input[str] title: Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
        """
        if description is not None:
            pulumi.set(__self__, "description", description)
        if expression is not None:
            pulumi.set(__self__, "expression", expression)
        if location is not None:
            pulumi.set(__self__, "location", location)
        if title is not None:
            pulumi.set(__self__, "title", title)

    @property
    @pulumi.getter
    def description(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. Description of the expression. This is a longer text which describes the expression, e.g. when hovered over it in a UI.
        """
        return pulumi.get(self, "description")

    @description.setter
    def description(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "description", value)

    @property
    @pulumi.getter
    def expression(self) -> Optional[pulumi.Input[str]]:
        """
        Textual representation of an expression in Common Expression Language syntax.
        """
        return pulumi.get(self, "expression")

    @expression.setter
    def expression(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "expression", value)

    @property
    @pulumi.getter
    def location(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. String indicating the location of the expression for error reporting, e.g. a file name and a position in the file.
        """
        return pulumi.get(self, "location")

    @location.setter
    def location(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "location", value)

    @property
    @pulumi.getter
    def title(self) -> Optional[pulumi.Input[str]]:
        """
        Optional. Title for the expression, i.e. a short string describing its purpose. This can be used e.g. in UIs which allow to enter the expression.
        """
        return pulumi.get(self, "title")

    @title.setter
    def title(self, value: Optional[pulumi.Input[str]]):
        pulumi.set(self, "title", value)


