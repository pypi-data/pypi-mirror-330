Metadata-Version: 2.2
Name: sentiframe
Version: 0.1.0
Summary: A flexible framework for scraping and analyzing YouTube comments
Home-page: https://github.com/ayushrawat220804/sentiframe
Author: Ayush Rawat
Author-email: ayushrawat220804@gmail.com
Project-URL: Bug Reports, https://github.com/ayushrawat220804/sentiframe/issues
Project-URL: Source, https://github.com/ayushrawat220804/sentiframe
Project-URL: Documentation, https://github.com/ayushrawat220804/sentiframe#readme
Keywords: youtube,comments,analysis,sentiment,api
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Topic :: Internet :: WWW/HTTP
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: google-api-python-client>=2.108.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: pandas>=1.3.0
Provides-Extra: web
Requires-Dist: streamlit>=1.29.0; extra == "web"
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: black>=22.0.0; extra == "dev"
Requires-Dist: isort>=5.0.0; extra == "dev"
Requires-Dist: flake8>=4.0.0; extra == "dev"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: project-url
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# Sentiframe

A flexible framework for scraping and analyzing YouTube comments. This framework provides an easy-to-use interface for fetching comments and metadata from YouTube videos.

## Features

- Easy-to-use API for fetching YouTube comments
- Support for various YouTube URL formats (standard, shorts, embedded)
- Fetch video metadata (title, views, likes, etc.)
- Configurable comment limit
- Built-in error handling
- Extensible base scraper class for adding more platforms

## Installation

You can install the package using pip:

```bash
pip install sentiframe
```

For web interface support, install with web extras:
```bash
pip install sentiframe[web]
```

## Setup

1. Get a YouTube Data API key:
   - Go to [Google Cloud Console](https://console.cloud.google.com/)
   - Create a new project or select an existing one
   - Enable the YouTube Data API v3
   - Create credentials (API key)
   - Copy the API key

2. Set up your API key:
   - Create a `.env` file in your project root
   - Add your API key:
     ```
     YOUTUBE_API_KEY=your_api_key_here
     ```
   - Or provide it directly when initializing the scraper

## Usage

### Basic Usage

```python
from sentiframe import YouTubeScraper

# Initialize the scraper
scraper = YouTubeScraper()  # Will use API key from .env
# Or provide API key directly:
# scraper = YouTubeScraper(api_key="your_api_key_here")

# Analyze a video
video_url = "https://www.youtube.com/watch?v=dQw4w9WgXcQ"
result = scraper.analyze_video(video_url, max_comments=50)

# Access metadata
print(f"Title: {result['metadata']['title']}")
print(f"Views: {result['metadata']['view_count']}")

# Access comments
for comment in result['comments']:
    print(f"Author: {comment['author']}")
    print(f"Text: {comment['text']}")
```

### Advanced Usage

```python
# Fetch metadata only
video_id = scraper.extract_id(video_url)
metadata = scraper.fetch_metadata(video_id)

# Fetch comments only
comments = scraper.fetch_comments(video_id, max_results=100)

# Clear stored data
scraper.clear()
```

## Extending the Framework

You can create your own scrapers by inheriting from the `BaseScraper` class:

```python
from sentiframe import BaseScraper

class MyCustomScraper(BaseScraper):
    def extract_id(self, url):
        # Implement ID extraction
        pass
        
    def fetch_comments(self, content_id, max_results=100):
        # Implement comment fetching
        pass
        
    def fetch_metadata(self, content_id):
        # Implement metadata fetching
        pass
```

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the LICENSE file for details. 
