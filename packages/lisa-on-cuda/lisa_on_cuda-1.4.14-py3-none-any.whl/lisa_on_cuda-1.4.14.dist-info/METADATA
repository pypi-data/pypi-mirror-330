Metadata-Version: 2.3
Name: lisa-on-cuda
Version: 1.4.14
Summary: LISA (Reasoning Segmentation via Large Language Model) on cuda, now with huggingface ZeroGPU support!
License: Apache 2.0
Author: alessandro trinca tornidor
Author-email: alessandro@trinca.tornidor.com
Requires-Python: >=3.10,<3.12
Classifier: License :: Other/Proprietary License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Dist: asgi-correlation-id (>=4.3.4,<5.0.0)
Requires-Dist: bitsandbytes (==0.43.0)
Requires-Dist: einops (>=0.8.0,<0.9.0)
Requires-Dist: fastapi (>=0.115.6,<0.116.0)
Requires-Dist: markdown2 (>=2.5.2,<3.0.0)
Requires-Dist: nh3 (>=0.2.18,<0.3.0)
Requires-Dist: numpy (==1.25.2) ; python_version == "3.10"
Requires-Dist: numpy (>=1.26,<2.0) ; python_version == "3.11"
Requires-Dist: openai (>=1.35.12,<2.0.0)
Requires-Dist: opencv-python-headless (>=4.10.0.84,<5.0.0.0)
Requires-Dist: packaging (>=24.1,<25.0)
Requires-Dist: peft-patched (==0.9.3)
Requires-Dist: pycocotools (>=2.0.8,<3.0.0)
Requires-Dist: requests (>=2.32.3,<3.0.0)
Requires-Dist: samgis-core (==3.0.17)
Requires-Dist: scipy (>=1.14.0,<2.0.0)
Requires-Dist: sentencepiece (>=0.2.0,<0.3.0)
Requires-Dist: shortuuid (>=1.0.13,<2.0.0)
Requires-Dist: spaces (==0.30.2)
Requires-Dist: torch (==2.4.0)
Requires-Dist: torchvision (==0.19.0)
Requires-Dist: tqdm (>=4.66.4,<5.0.0)
Requires-Dist: transformers-backport (==4.31.2)
Requires-Dist: uvicorn (>=0.34.0,<0.35.0)
Project-URL: Demo, https://huggingface.co/spaces/aletrn/lisa-on-cuda/
Project-URL: Source, https://huggingface.co/spaces/aletrn/lisa-on-cuda/
Description-Content-Type: text/markdown

---
title: lisa + gradio + fastapi + CUDA
emoji: âš¡
colorFrom: red
colorTo: purple
sdk: gradio
sdk_version: 5.9.1
app_file: app.py
pinned: true
---

# LISA (Reasoning Segmentation via Large Language Model) on cuda, now with huggingface ZeroGPU support!

## Exec jupyter on the remote server with port forwarding on localhost

1. checkout repo, install venv with jupyter
2. port forwarding in localhost wiht private key: `ssh -i /path/to/private_key name@endpoint.com -L 8889:localhost:8889 -N -f`
3. start the jupyter-lab server
4. connect to page in localhost

## Commands to work on remote virtual machines (e.g. SaturnCloud) after clone and git lfs install

```bash
cd ~/workspace/lisa-on-cuda/
rm -rf lisa_venv 
python3 -m venv lisa_venv
ln -s lisa_venv/ venv
source  venv/bin/activate
pip --version
which python
python -m pip install pip wheel --upgrade
python -m pip install pytest pytest-cov jupyterlab
python -m pip install -r requirements.txt
nohup jupyter-lab &
tail -F nohup.out
```

# Jupyterlab Howto

To run the `test.ipynb` notebook you should already:
- cloned project https://huggingface.co/spaces/aletrn/lisa-on-cuda with active git lfs
- created and activated a virtualenv
- installed jupyterlab dependencies from requirements_jupyter.txt
- installed dependencies from requirements.txt

## Hardware requirements for local usage

- an nvidia gpu with 10 or 12GB of memory (a T4 should suffice)
- at least 16GB of system ram

## Hardware requirements on huggingface ZeroGPU

Right now (July 2024) huggingface let use ZeroGPU Nvidia A100 GPUs.

[![Gradio](https://img.shields.io/badge/Gradio-Online%20Demo-blue)](http://103.170.5.190:7860/)
[![Open in OpenXLab](https://cdn-static.openxlab.org.cn/app-center/openxlab_app.svg)](https://openxlab.org.cn/apps/detail/openxlab-app/LISA)

See [LISA](https://github.com/dvlab-research/LISA) for details on the original project.
Note that the authors don't keep the project updated anymore.

## Dependencies and HuggingFace demos with Gradio SDK

HuggingFace demos based on Gradio SDK (you need that to use ZeroGPU hardware) needs updated requirements.txt.
You can keep your requirements.txt in sync with the dependencies installed in the project using this python 
command (from samgis-core):

```bash
python -m samgis_core.utilities.update_requirements_txt --req_no_version_path requirements_no_versions.txt --req_output_path requirements.txt
```

About the parameters:

- input argument `--req_no_version_path` is a file with the dependencies package list without version declared
- output argument `--req_output_path` is the output requirements.txt

This command simply freeze the installed packages and filter it using the dependencies package list from the input argument.
If you need to modify the `requirements_no_versions.txt` file, avoid inserting

- `python` (this is required only by `poetry`)
- `gradio`, `gradio-client` (installed directly by HuggingFace, selecting the version in header section of the README.md file)
- `spaces` (installed directly by HuggingFace, version selected connected by the gradio version)

In case of doubt check the HuggingFace container log for the correct `spaces` package version.

