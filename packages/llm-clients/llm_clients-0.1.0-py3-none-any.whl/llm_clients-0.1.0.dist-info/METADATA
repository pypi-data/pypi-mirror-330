Metadata-Version: 2.4
Name: llm-clients
Version: 0.1.0
Summary: UNIX-style command line utilities for working with Large Language Models
Author-email: PsychArch <psycharch@github.com>
License-Expression: MIT
License-File: LICENSE
Keywords: ai,clients,llm,prompt,tools,unix
Classifier: Development Status :: 3 - Alpha
Classifier: Environment :: Console
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Utilities
Requires-Python: >=3.8
Requires-Dist: aiohttp>=3.8.0
Requires-Dist: anthropic>=0.5.0
Requires-Dist: click>=8.0.0
Requires-Dist: google-genai
Requires-Dist: openai>=1.0.0
Requires-Dist: pyyaml>=6.0.0
Requires-Dist: rich>=13.0.0
Requires-Dist: tencentcloud-sdk-python-common>=3.0.1000
Requires-Dist: tencentcloud-sdk-python-lkeap>=3.0.1000
Requires-Dist: tencentcloud-sdk-python>=3.0.1000
Requires-Dist: xmltodict>=0.13.0
Provides-Extra: dev
Requires-Dist: pytest-asyncio>=0.23.0; extra == 'dev'
Requires-Dist: pytest>=7.0.0; extra == 'dev'
Description-Content-Type: text/markdown

# LLM Clients

A command-line interface for working with Large Language Models, providing utilities for prompts, tools, and LLM API calls.

## Features

- Command-line interface for interacting with various LLM providers (OpenAI, Anthropic, SambaNova, OpenRouter)
- Composable prompt management
- Tool integration for enhanced LLM capabilities:
  - File operations (read/write with XML tags)
  - Search and replace (with regex and line range support)
  - Calculator (for arithmetic operations)
  - History management (for conversation context)
  - Instruction templates
- Configuration management for API keys and settings
- Rich terminal output formatting

## Installation

1. Clone the repository:
```bash
pipx install llm-clients

llm config init
# Manually edit ~/.config/llm-clients/config.yaml
# Or, 
llm config set openai.api_key YOUR_API_KEY
llm config set siliconflow.api_key YOUR_API_KEY
```

```bash
# Use the default model
git diff | llm run "Write a commit message" | xargs -I{} git commit -m {}

# Programming
llm run -t file "Establish a python chat box using OpenAI API, saving to chat.py."
llm run -f chat.py "Add comments for the code."

# Chat box
while true; do
  read -p "Enter your message (type '/exit' to quit): " user_input
  if [ "$user_input" = "/exit" ]; then
    break
  fi
  llm run -H chat.log "$user_input"
done
```


## License

MIT License 